// ⳃⳃⳃ - Ⲅⲉⲛⲉⲣⲁⲧⲉⲇ ⲃⲩ ⲂⲒⲂⲈⲈⲤ
// Ⲥⲟⲩⲣⲥⲉ: attention.vibee
// Ⲃⲉⲣⲥⲓⲟⲛ: 1.0.0

Ⲙ ⲀⲀⲀⲀ

// Ⲥⲣⲉⲁⲧⲓⲟⲛ Ⲡⲁⲧⲧⲉⲣⲛ
Ⲕ ⲔⲔⲂⲦ: Ⲥ = "QKV_Tensors"
Ⲕ ⲀⲦⲦⲈ: Ⲥ = "AttentionMechanism"
Ⲕ ⲀⲦⲦⲈ: Ⲥ = "AttentionOutput"

// compute_attention
// Ⲅⲓⲃⲉⲛ: Q, K, V тензоры
// Ⲱⲏⲉⲛ: Forward pass
// Ⲧⲏⲉⲛ: Attention output
Ⲫ ⲔⲞⲘⲠ() -> Ⲱ {
  ⲂⲌ Ⲱ
}

// flash_forward
// Ⲅⲓⲃⲉⲛ: Q, K, V + block_size
// Ⲱⲏⲉⲛ: Flash Attention
// Ⲧⲏⲉⲛ: Output с O(n) памятью
Ⲫ ⲪⲖⲀⲤ() -> Ⲱ {
  ⲂⲌ Ⲱ
}

// multi_head
// Ⲅⲓⲃⲉⲛ: Input + num_heads
// Ⲱⲏⲉⲛ: Multi-head attention
// Ⲧⲏⲉⲛ: Concatenated heads output
Ⲫ ⲘⲨⲖⲦ() -> Ⲱ {
  ⲂⲌ Ⲱ
}

Ⲉ {ⲔⲞⲘⲠ, ⲪⲖⲀⲤ, ⲘⲨⲖⲦ }
