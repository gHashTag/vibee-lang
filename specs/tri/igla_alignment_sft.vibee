# iGLA Alignment SFT
# Supervised Fine-Tuning
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_alignment_sft
version: "1.0.0"
language: zig
module: igla_alignment_sft

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  SFTConfig:
    fields:
      dataset: String
      format: String
      max_length: Int
      packing: Bool
      num_epochs: Int

  SFTSample:
    fields:
      instruction: String
      input: String
      output: String
      system: Option<String>

  SFTDataset:
    fields:
      samples: List<SFTSample>
      total_tokens: Int
      avg_length: Float

  SFTMetrics:
    fields:
      train_loss: Float
      instruction_following: Float
      format_compliance: Float
      helpfulness: Float

behaviors:
  - name: load_sft_data
    given: "Dataset path"
    when: "Loading"
    then: "Alpaca/ShareGPT format loaded"

  - name: format_prompt
    given: "Sample"
    when: "Formatting"
    then: "Chat template applied"

  - name: pack_sequences
    given: "Samples"
    when: "Packing"
    then: "Multiple samples per sequence"

  - name: train_sft
    given: "Formatted data"
    when: "SFT training"
    then: "Instruction-tuned model"

  - name: evaluate_following
    given: "Test prompts"
    when: "Evaluation"
    then: "Instruction following measured"

  - name: filter_quality
    given: "Dataset"
    when: "Filtering"
    then: "Low-quality samples removed"

  - name: phi_sft_harmony
    given: "SFT"
    when: "Harmony"
    then: "φ-balanced instruction mix"
