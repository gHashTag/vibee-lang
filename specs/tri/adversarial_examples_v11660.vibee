name: adversarial_examples_v11660
version: "11660"
language: zig
module: adversarial_examples

description: |
  TIER 250: Adversarial Example Generation
  Creates adversarial inputs to test model robustness
  Based on: FGSM, PGD, C&W attacks

types:
  AttackConfig:
    fields:
      attack_type: AttackType
      epsilon: Float
      iterations: Int
      targeted: Bool
      norm_constraint: NormType

  AttackType:
    variants:
      - fgsm
      - pgd
      - cw
      - deepfool
      - autoattack

  NormType:
    variants:
      - l_inf
      - l_2
      - l_1
      - l_0

  AdversarialExample:
    fields:
      original_input: List<Float>
      perturbed_input: List<Float>
      perturbation: List<Float>
      original_label: Int
      adversarial_label: Int
      success: Bool

  AttackResult:
    fields:
      success_rate: Float
      avg_perturbation: Float
      examples: List<String>

behaviors:
  - name: generate_fgsm
    given: Input and model
    when: Running FGSM attack
    then: Returns adversarial example

  - name: generate_pgd
    given: Input and iterations
    when: Running PGD attack
    then: Returns adversarial example

  - name: generate_cw
    given: Input and confidence
    when: Running C&W attack
    then: Returns adversarial example

  - name: generate_targeted
    given: Input and target class
    when: Creating targeted attack
    then: Returns targeted adversarial

  - name: compute_perturbation_norm
    given: Perturbation
    when: Computing norm
    then: Returns norm value

  - name: verify_adversarial
    given: Example and model
    when: Verifying success
    then: Returns verification

  - name: batch_attack
    given: Dataset
    when: Running batch attack
    then: Returns attack results

  - name: visualize_perturbation
    given: Adversarial example
    when: Creating visualization
    then: Returns visualization

creation_pattern:
  source: CleanInput
  transformer: AdversarialGenerator
  result: AdversarialExample
