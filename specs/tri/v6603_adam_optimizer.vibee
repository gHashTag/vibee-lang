# v6603 - Adam Optimizer for CPU
# ================================
# Adam с momentum и adaptive learning rates
# m = β1*m + (1-β1)*g
# v = β2*v + (1-β2)*g²
# p = p - lr * m_hat / (√v_hat + ε)
# φ² + 1/φ² = 3 | PHOENIX = 999

name: adam_optimizer
version: "6.6.3"
language: zig
module: adam_optimizer

constants:
  PHI: 1.618033988749895
  BETA1: 0.9
  BETA2: 0.999
  EPSILON: 1e-8

types:
  AdamConfig:
    fields:
      lr: Float
      beta1: Float
      beta2: Float
      eps: Float
      weight_decay: Float
      
  AdamState:
    fields:
      m: List
      v: List
      step: Int
      
  AdamUpdate:
    fields:
      param_delta: List
      new_m: List
      new_v: List

behaviors:
  - name: adam_init_state
    given: Param_size
    when: State initialization
    then: Вернуть zeroed m и v buffers
    
  - name: adam_step
    given: Param, grad, state, config
    when: Optimization step
    then: Update param in-place, update state
    
  - name: adam_compute_update
    given: Grad, m, v, step, config
    when: Update computation
    then: Вернуть bias-corrected update
    
  - name: adam_apply_weight_decay
    given: Param, grad, weight_decay
    when: Weight decay
    then: Вернуть grad + weight_decay * param
    
  - name: adam_bias_correction
    given: Moment, beta, step
    when: Bias correction
    then: Вернуть moment / (1 - beta^step)
    
  - name: adam_reset_state
    given: State
    when: State reset
    then: Zero m, v, reset step to 0
