name: benchmark_gaia
version: "11.0.0"
language: zig
module: benchmark_gaia

# BENCHMARK: GAIA
# General AI Assistants benchmark
# Target: #1 on leaderboard

types:
  GAIATask:
    fields:
      task_id: String
      level: Int
      question: String
      expected_answer: String
      file_path: Option<String>

  GAIAResult:
    fields:
      task_id: String
      predicted_answer: String
      correct: Bool
      steps_taken: Int
      time_ms: Int

  GAIAMetrics:
    fields:
      level1_accuracy: Float
      level2_accuracy: Float
      level3_accuracy: Float
      overall_accuracy: Float
      avg_time_ms: Float

  GAIAConfig:
    fields:
      dataset_path: String
      max_steps: Int
      timeout_ms: Int
      levels: List<Int>

behaviors:
  - name: load_tasks
    given: GAIAConfig
    when: Loading GAIA dataset
    then: Return list of GAIATasks

  - name: run_task
    given: GAIATask
    when: Executing single task
    then: Return GAIAResult

  - name: run_benchmark
    given: GAIAConfig
    when: Running full benchmark
    then: Return GAIAMetrics

  - name: evaluate_answer
    given: Predicted and expected
    when: Checking correctness
    then: Return bool

  - name: export_results
    given: Results and format
    when: Exporting for submission
    then: Return export path

  - name: compare_with_leaderboard
    given: GAIAMetrics
    when: Comparing with others
    then: Return ranking info
