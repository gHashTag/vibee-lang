name: llm_client_anthropic
version: "11.0.0"
language: zig
module: llm_client_anthropic

# LLM: Anthropic Client
# Claude 3.5, Claude 4 models

types:
  AnthropicConfig:
    fields:
      api_key: String
      model: String
      base_url: String

  ClaudeMessage:
    fields:
      role: String
      content: String

  ClaudeRequest:
    fields:
      messages: List<String>
      model: String
      max_tokens: Int
      system: Option<String>
      stream: Bool

  ClaudeResponse:
    fields:
      content: String
      stop_reason: String
      usage_input: Int
      usage_output: Int
      model: String

  ToolUse:
    fields:
      tool_id: String
      name: String
      input: String

behaviors:
  - name: create_client
    given: AnthropicConfig
    when: Initializing client
    then: Return client handle

  - name: chat
    given: ClaudeRequest
    when: Making message request
    then: Return ClaudeResponse

  - name: chat_stream
    given: ClaudeRequest
    when: Streaming response
    then: Yield content blocks

  - name: with_tools
    given: ClaudeRequest and tools
    when: Using tool use
    then: Return response with tool uses

  - name: continue_tool_use
    given: Tool result
    when: Continuing after tool
    then: Return next response

  - name: count_tokens
    given: Messages
    when: Counting tokens
    then: Return token count
