name: zig_benchmark_http
version: "12.0.0"
language: zig
module: zig_benchmark_http

# IMPLEMENTATION: HTTP Benchmark
# Measure HTTP client performance
# Compare with curl, JS fetch
# φ² + 1/φ² = 3

types:
  BenchmarkConfig:
    fields:
      url: String
      iterations: Int
      warmup: Int
      concurrent: Int

  BenchmarkResult:
    fields:
      total_requests: Int
      successful: Int
      failed: Int
      total_time_ns: Int
      avg_latency_ns: Int
      p50_latency_ns: Int
      p95_latency_ns: Int
      p99_latency_ns: Int
      throughput_rps: Float

  LatencyHistogram:
    fields:
      buckets: List<Int>
      counts: List<Int>
      min_ns: Int
      max_ns: Int

  ComparisonResult:
    fields:
      zig_result: String
      baseline_result: String
      speedup: Float

behaviors:
  - name: run_benchmark
    given: BenchmarkConfig
    when: Running HTTP benchmark
    then: Return BenchmarkResult

  - name: warmup
    given: URL and warmup_count
    when: Warming up connections
    then: Return warmup stats

  - name: measure_latency
    given: URL
    when: Measuring single request latency
    then: Return latency in nanoseconds

  - name: compute_percentiles
    given: List of latencies
    when: Computing p50, p95, p99
    then: Return percentile values

  - name: compare_with_curl
    given: URL and iterations
    when: Comparing Zig vs curl
    then: Return ComparisonResult

  - name: report
    given: BenchmarkResult
    when: Generating report
    then: Return formatted report string
