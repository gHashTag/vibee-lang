name: llm_streaming
version: "11.0.0"
language: zig
module: llm_streaming

# LLM: Streaming Support
# Token-by-token streaming

types:
  StreamToken:
    fields:
      token: String
      index: Int
      is_final: Bool
      finish_reason: Option<String>

  StreamBuffer:
    fields:
      tokens: List<String>
      total_tokens: Int
      complete: Bool

  StreamConfig:
    fields:
      buffer_size: Int
      flush_interval_ms: Int
      on_token_callback: Bool

  StreamStats:
    fields:
      tokens_received: Int
      time_to_first_token_ms: Int
      tokens_per_second: Float

behaviors:
  - name: start_stream
    given: Request
    when: Beginning stream
    then: Return stream handle

  - name: read_token
    given: Stream handle
    when: Getting next token
    then: Return StreamToken

  - name: read_all
    given: Stream handle
    when: Getting all tokens
    then: Return StreamBuffer

  - name: cancel_stream
    given: Stream handle
    when: Cancelling stream
    then: Return cancel status

  - name: get_stats
    given: Stream handle
    when: Getting stream stats
    then: Return StreamStats

  - name: buffer_until
    given: Stream and condition
    when: Buffering tokens
    then: Return buffered content
