# Context 1M Tokens V81 - Extended Memory
name: context_1m_v81
version: "81.0.0"
language: zig
module: context_1m

creation_pattern:
  source: LargeCodebase
  transformer: ContextManager
  result: CompressedContext

pas_patterns:
  - pattern: PRE
    application: "Hierarchical summarization"
    compression: "10x"
  - pattern: HSH
    application: "Content-addressable chunks"
    speedup: "5x"

types:
  ContextChunk:
    fields:
      id: Int
      content: String
      summary: String
      tokens: Int
      importance: Float

  ContextWindow:
    fields:
      chunks: List<ContextChunk>
      total_tokens: Int
      max_tokens: Int

  HierarchicalSummary:
    fields:
      level: Int
      content: String
      children: List<Int>

  ContextIndex:
    fields:
      embeddings: Map<Int, List<Float>>
      chunk_map: Map<Int, ContextChunk>

  RetrievalResult:
    fields:
      chunks: List<ContextChunk>
      relevance_scores: List<Float>

  CompressionConfig:
    fields:
      target_ratio: Float
      preserve_code: Bool
      preserve_types: Bool

behaviors:
  - name: chunk_codebase
    given: "Large codebase"
    when: "Chunking"
    then: "Semantic chunks"
    test_cases:
      - name: chunk_1m
        input: "1M token codebase"
        expected: "~1000 chunks"

  - name: summarize_chunk
    given: "Code chunk"
    when: "Summarization"
    then: "Compressed summary"
    test_cases:
      - name: summarize_function
        input: "100 line function"
        expected: "10 line summary"

  - name: build_hierarchy
    given: "Flat chunks"
    when: "Hierarchy building"
    then: "Tree of summaries"
    test_cases:
      - name: three_levels
        input: "1000 chunks"
        expected: "3-level tree"

  - name: retrieve_relevant
    given: "Query and index"
    when: "Semantic search"
    then: "Top-k relevant chunks"
    test_cases:
      - name: find_related
        input: "function signature"
        expected: "related implementations"

  - name: compress_context
    given: "Full context"
    when: "Compression needed"
    then: "Compressed to fit window"
    test_cases:
      - name: compress_10x
        input: "1M tokens"
        expected: "100K tokens"

  - name: expand_on_demand
    given: "Summary reference"
    when: "Detail needed"
    then: "Full content retrieved"
    test_cases:
      - name: expand_chunk
        input: "summary ID"
        expected: "full chunk content"

# φ² + 1/φ² = 3 | PHOENIX = 999
