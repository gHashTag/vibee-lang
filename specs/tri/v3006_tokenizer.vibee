# v3006 - Tokenizer Specification
# ================================
# BPE and character-level tokenization
# φ² + 1/φ² = 3 | PHOENIX = 999

name: tokenizer
version: "3.0.6"
language: zig
module: tokenizer

constants:
  PHI: 1.618033988749895
  PAD_TOKEN: 0
  UNK_TOKEN: 1
  BOS_TOKEN: 2
  EOS_TOKEN: 3
  DEFAULT_VOCAB_SIZE: 32000

types:
  TokenizerConfig:
    fields:
      vocab_size: Int
      pad_token: Int
      unk_token: Int
      bos_token: Int
      eos_token: Int
      
  Vocabulary:
    fields:
      token_to_id: Map
      id_to_token: Map
      vocab_size: Int
      
  EncodedSequence:
    fields:
      input_ids: List
      attention_mask: List
      length: Int
      
  BPEConfig:
    fields:
      vocab_size: Int
      min_frequency: Int
      special_tokens: List

behaviors:
  - name: encode
    given: Text string and vocabulary
    when: Converting text to token IDs
    then: Return encoded sequence
    
  - name: decode
    given: Token IDs and vocabulary
    when: Converting IDs to text
    then: Return decoded string
    
  - name: build_vocabulary
    given: Corpus and config
    when: Learning vocabulary from data
    then: Return vocabulary mapping
    
  - name: tokenize_char
    given: Text string
    when: Character-level tokenization
    then: Return list of character tokens
    
  - name: tokenize_bpe
    given: Text and BPE merges
    when: Applying BPE tokenization
    then: Return list of subword tokens
    
  - name: pad_sequence
    given: Sequence and max_length
    when: Padding to fixed length
    then: Return padded sequence with mask
    
  - name: truncate_sequence
    given: Sequence and max_length
    when: Truncating long sequence
    then: Return truncated sequence
    
  - name: add_special_tokens
    given: Sequence and config
    when: Adding BOS/EOS tokens
    then: Return sequence with special tokens
