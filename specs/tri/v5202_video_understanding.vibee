# v5202 - Video Understanding
# ============================
# Понимание видео - action recognition, captioning
# φ² + 1/φ² = 3 | PHOENIX = 999

name: video_understanding
version: "5.2.2"
language: zig
module: video_understanding

constants:
  PHI: 1.618033988749895
  NUM_FRAMES: 32
  PATCH_SIZE: 16
  NUM_CLASSES: 400

types:
  VideoEncoderConfig:
    fields:
      model_type: String
      num_frames: Int
      patch_size: Int
      
  VideoFeatures:
    fields:
      spatial_features: List
      temporal_features: List
      global_features: List
      
  ActionPrediction:
    fields:
      action_class: Int
      confidence: Float
      temporal_extent: List
      
  VideoCaption:
    fields:
      caption: String
      timestamps: List
      
  TemporalSegment:
    fields:
      start_frame: Int
      end_frame: Int
      label: String
      
  VideoQA:
    fields:
      question: String
      answer: String
      evidence_frames: List
      
  ObjectTrack:
    fields:
      object_id: Int
      bboxes: List
      frames: List
      
  SceneGraph:
    fields:
      objects: List
      relations: List
      frame_id: Int

behaviors:
  - name: encode_video
    given: Video frames и encoder
    when: Video encoding
    then: Вернуть video features
    
  - name: classify_action
    given: Video и classifier
    when: Action recognition
    then: Вернуть action prediction
    
  - name: temporal_action_detection
    given: Video и detector
    when: TAD
    then: Вернуть temporal segments
    
  - name: caption_video
    given: Video и captioner
    when: Video captioning
    then: Вернуть video caption
    
  - name: dense_video_captioning
    given: Video и model
    when: Dense captioning
    then: Вернуть timestamped captions
    
  - name: video_question_answering
    given: Video, question, model
    when: VideoQA
    then: Вернуть answer
    
  - name: track_objects
    given: Video и tracker
    when: Multi-object tracking
    then: Вернуть object tracks
    
  - name: video_scene_graph
    given: Video frame
    when: Scene graph generation
    then: Вернуть scene graph
