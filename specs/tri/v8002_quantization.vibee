# v8002 - Quantization
# =====================
# INT8/INT4 quantization
# Based on: GPTQ, AWQ, SmoothQuant
# φ² + 1/φ² = 3 | PHOENIX = 999

name: quantization
version: "8.0.2"
language: zig
module: quantization

constants:
  PHI: 1.618033988749895

types:
  QuantConfig:
    fields:
      bits: Int
      group_size: Int
      symmetric: Bool
      method: String
      
  QuantizedTensor:
    fields:
      data: List
      scale: List
      zero_point: List
      
  CalibrationData:
    fields:
      samples: List
      activations: Map

behaviors:
  - name: quantize_weights
    given: Weights и config
    when: Weight quantization
    then: Вернуть quantized weights
    
  - name: quantize_activations
    given: Activations и config
    when: Activation quantization
    then: Вернуть quantized activations
    
  - name: gptq_quantize
    given: Layer и calibration data
    when: GPTQ quantization
    then: Вернуть GPTQ quantized layer
    
  - name: awq_quantize
    given: Model и config
    when: AWQ quantization
    then: Вернуть AWQ quantized model
    
  - name: smooth_quant
    given: Model и alpha
    when: SmoothQuant
    then: Вернуть smoothed model
    
  - name: dequantize
    given: Quantized tensor
    when: Dequantization
    then: Вернуть float tensor
    
  - name: compute_scale
    given: Tensor и bits
    when: Scale computation
    then: Вернуть optimal scale
    
  - name: pack_int4
    given: INT4 values
    when: Packing
    then: Вернуть packed bytes
