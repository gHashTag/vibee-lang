# VIBEE Specification - IGLA MiniLM Embeddings
# MiniLM-L6-v2 384-dimensional embeddings
# RAG v3 - Real Embeddings
# φ² + 1/φ² = 3 | PHOENIX = 999

name: igla_minilm_embeddings
version: "3.0.0"
language: zig
module: igla_minilm_embeddings

types:
  MiniLMModel:
    fields:
      id: String
      model_path: String
      tokenizer_path: String
      embedding_dim: Int
      max_seq_length: Int
      loaded: Bool

  Tokenizer:
    fields:
      vocab_size: Int
      pad_token_id: Int
      cls_token_id: Int
      sep_token_id: Int
      unk_token_id: Int

  TokenizedInput:
    fields:
      input_ids: String
      attention_mask: String
      token_type_ids: String
      length: Int

  Embedding:
    fields:
      vector: String
      dimension: Int
      normalized: Bool
      text_hash: String

  EmbeddingBatch:
    fields:
      embeddings: String
      count: Int
      total_tokens: Int
      latency_ms: Float

  SimilarityResult:
    fields:
      score: Float
      method: String

  EmbeddingConfig:
    fields:
      normalize: Bool
      pooling: String
      batch_size: Int
      use_cache: Bool

  EmbeddingCache:
    fields:
      max_size: Int
      current_size: Int
      hit_rate: Float

  EmbeddingMetrics:
    fields:
      total_embeddings: Int
      avg_latency_ms: Float
      cache_hits: Int
      cache_misses: Int

behaviors:
  - name: load_model
    given: Model path
    when: Model loading
    then: MiniLM model ready

  - name: tokenize
    given: Text input
    when: Tokenization
    then: Token IDs returned

  - name: embed_text
    given: Text string
    when: Embedding requested
    then: 384-dim vector returned

  - name: embed_batch
    given: Text array
    when: Batch embedding
    then: Embedding batch returned

  - name: compute_similarity
    given: Two embeddings
    when: Similarity computed
    then: Cosine similarity score

  - name: normalize_embedding
    given: Raw embedding
    when: Normalization
    then: Unit vector returned

  - name: mean_pooling
    given: Token embeddings
    when: Pooling applied
    then: Sentence embedding returned

  - name: cache_embedding
    given: Text and embedding
    when: Caching
    then: Embedding cached

  - name: get_cached
    given: Text hash
    when: Cache lookup
    then: Cached embedding or null

  - name: get_metrics
    given: Model
    when: Metrics requested
    then: Embedding metrics returned

test_cases:
  - name: test_load_model
    input: { path: "models/minilm" }
    expected: { loaded: true, dim: 384 }

  - name: test_tokenize
    input: { text: "Hello world" }
    expected: { has_tokens: true }

  - name: test_embed
    input: { text: "Test sentence" }
    expected: { dimension: 384 }

  - name: test_similarity
    input: { text1: "Hello", text2: "Hi" }
    expected: { score_range: [0.0, 1.0] }

  - name: test_normalize
    input: { vector: "[0.5, 0.5]" }
    expected: { is_unit: true }

  - name: test_batch
    input: { texts: ["a", "b", "c"] }
    expected: { count: 3 }

  - name: test_cache
    input: { text: "cached" }
    expected: { cached: true }

  - name: test_metrics
    input: {}
    expected: { total_embeddings: 0 }
