# iGLA Self-RAG Evaluation
# Evaluation metrics for Self-RAG
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_selfrag_evaluation
version: "1.0.0"
language: zig
module: igla_selfrag_evaluation

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  EvalConfig:
    fields:
      metrics: String
      num_samples: Int

  EvalResult:
    fields:
      accuracy: Float
      f1_score: Float
      precision: Float
      recall: Float

  ConfusionMatrix:
    fields:
      tp: Int
      fp: Int
      tn: Int
      fn: Int

  QualityMetrics:
    fields:
      faithfulness: Float
      relevance: Float
      coherence: Float

  HumanEval:
    fields:
      annotator_id: Int
      score: Float
      comments: String

  BenchmarkResult:
    fields:
      dataset: String
      metrics: String
      timestamp: Int

behaviors:
  - name: evaluate_critic
    given: "Model, test_data"
    when: "Evaluation"
    then: "Evaluation metrics"

  - name: compute_accuracy
    given: "Predictions, labels"
    when: "Accuracy"
    then: "Accuracy score"

  - name: compute_f1
    given: "Predictions, labels"
    when: "F1 computation"
    then: "F1 score"

  - name: build_confusion_matrix
    given: "Predictions, labels"
    when: "Confusion matrix"
    then: "TP/FP/TN/FN"

  - name: evaluate_generation
    given: "Responses, references"
    when: "Generation eval"
    then: "Quality metrics"

  - name: run_benchmark
    given: "Model, benchmark"
    when: "Benchmarking"
    then: "Benchmark results"

  - name: aggregate_human_eval
    given: "Human scores"
    when: "Aggregation"
    then: "Aggregated score"

  - name: phi_metric_weighting
    given: "All metrics"
    when: "Sacred weighting"
    then: "φ-weighted score"
