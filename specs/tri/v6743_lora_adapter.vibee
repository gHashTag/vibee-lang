name: v6743_lora_adapter
version: "1.0.0"
language: zig
module: v6743_lora_adapter

types:
  LoRAConfig:
    fields:
      rank: Int
      alpha: Float
      dropout: Float

behaviors:
  - name: lora_forward
    given: Input and frozen weights
    when: Apply LoRA adaptation
    then: Return W0x plus scale times BAx

  - name: phi_rank
    given: Base rank
    when: Apply PHI scaling
    then: Return golden rank

  - name: merge_weights
    given: Base weights and LoRA
    when: Merge for inference
    then: Return W0 plus scale times BA
