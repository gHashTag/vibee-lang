# v6502 - Value-Aligned Loss Functions
# =====================================
# Loss functions that encode human values
# Integration: v6013 Loss + v11500 Value Learning
# φ² + 1/φ² = 3 | PHOENIX = 999

name: value_aligned_loss
version: "6.5.2"
language: zig
module: value_aligned_loss

constants:
  PHI: 1.618033988749895

types:
  ValueLossConfig:
    fields:
      task_loss_weight: Float
      value_loss_weight: Float
      harm_penalty_weight: Float
      
  ValueLoss:
    fields:
      task_loss: Float
      value_alignment_loss: Float
      harm_penalty: Float
      total_loss: Float

behaviors:
  - name: compute_value_loss
    given: Output и value_model
    when: Value loss computation
    then: Вернуть value alignment loss
    
  - name: compute_harm_penalty
    given: Output и harm_detector
    when: Harm detection
    then: Вернуть harm penalty
    
  - name: combined_loss
    given: Task loss, value loss, harm penalty
    when: Loss combination
    then: Вернуть weighted total loss
    
  - name: preference_loss
    given: Chosen, rejected outputs
    when: Preference learning
    then: Вернуть preference loss (DPO-style)
    
  - name: constitutional_loss
    given: Output и constitution
    when: Constitutional check
    then: Вернуть constitutional violation loss
    
  - name: reward_model_loss
    given: Output и reward_model
    when: Reward modeling
    then: Вернуть reward-based loss
