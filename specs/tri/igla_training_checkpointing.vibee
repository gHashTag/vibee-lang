# iGLA Training Checkpointing
# Model and optimizer state saving
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_training_checkpointing
version: "1.0.0"
language: zig
module: igla_training_checkpointing

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  CheckpointConfig:
    fields:
      save_dir: String
      save_interval: Int
      keep_last_n: Int
      save_optimizer: Bool
      async_save: Bool

  Checkpoint:
    fields:
      step: Int
      model_state: Object
      optimizer_state: Object
      scheduler_state: Object
      rng_state: Object

  CheckpointMetadata:
    fields:
      step: Int
      loss: Float
      timestamp: String
      size_gb: Float

  CheckpointMetrics:
    fields:
      save_time_sec: Float
      load_time_sec: Float
      storage_gb: Float
      checkpoint_count: Int

behaviors:
  - name: save_checkpoint
    given: "Training state"
    when: "Save interval"
    then: "Full checkpoint saved"

  - name: load_checkpoint
    given: "Checkpoint path"
    when: "Resume"
    then: "Training state restored"

  - name: save_sharded
    given: "FSDP model"
    when: "Sharded save"
    then: "Distributed checkpoint"

  - name: async_save
    given: "State"
    when: "Async"
    then: "Non-blocking save"

  - name: cleanup_old
    given: "Checkpoints"
    when: "Cleanup"
    then: "Keep only last N"

  - name: verify_checkpoint
    given: "Checkpoint"
    when: "Verification"
    then: "Integrity verified"

  - name: phi_checkpoint_harmony
    given: "Checkpointing"
    when: "Harmony"
    then: "φ-interval checkpointing"
