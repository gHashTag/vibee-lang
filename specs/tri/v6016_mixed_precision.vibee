# v6016 - Mixed Precision Training
# =================================
# FP16/BF16 тренировка
# φ² + 1/φ² = 3 | PHOENIX = 999

name: mixed_precision
version: "6.0.16"
language: zig
module: mixed_precision

constants:
  PHI: 1.618033988749895
  FP16_MAX: 65504.0
  INIT_SCALE: 65536.0

types:
  GradScaler:
    fields:
      scale: Float
      growth_factor: Float
      backoff_factor: Float
      growth_interval: Int
      
  MixedPrecisionConfig:
    fields:
      enabled: Bool
      dtype: String
      init_scale: Float

behaviors:
  - name: scaler_init
    given: Config
    when: Инициализация scaler
    then: Создать GradScaler
    
  - name: scale_loss
    given: Loss и scaler
    when: Масштабирование loss
    then: Вернуть scaled loss
    
  - name: unscale_grads
    given: Grads и scaler
    when: Обратное масштабирование
    then: Вернуть unscaled grads
    
  - name: update_scale
    given: Scaler и found_inf
    when: Обновление scale
    then: Adjust scale based on overflow
