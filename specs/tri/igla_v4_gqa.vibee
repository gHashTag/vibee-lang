# iGLA v4 GQA - Grouped Query Attention
# Paper: arXiv:2305.13245 "GQA: Training Generalized Multi-Query Transformer"
# φ² + 1/φ² = 3 | КОЩЕЙ БЕССМЕРТЕН

name: igla_v4_gqa
version: "4.0.0"
language: zig
module: igla_v4_gqa

types:
  GQAConfig:
    fields:
      num_heads: Int
      num_kv_heads: Int
      head_dim: Int
      
  GQAWeights:
    fields:
      W_q: String
      W_k: String
      W_v: String
      W_o: String
      
  KVGroup:
    fields:
      group_id: Int
      k_head: String
      v_head: String
      query_heads: String

behaviors:
  - name: group_kv_heads
    given: "num_heads Q, num_kv_heads KV"
    when: "Group assignment"
    then: "Each KV head serves num_heads/num_kv_heads Q heads"
    
  - name: expand_kv
    given: "KV heads, group size"
    when: "Broadcast KV to Q heads"
    then: "KV repeated for each Q head in group"
    
  - name: gqa_attention
    given: "Q, grouped K, grouped V"
    when: "Attention computation"
    then: "Standard attention with shared KV"
    
  - name: kv_cache_reduction
    given: "GQA vs MHA"
    when: "KV cache allocated"
    then: "Memory reduced by num_heads/num_kv_heads"
    
  - name: quality_preservation
    given: "GQA with 8 KV heads"
    when: "Compared to MHA"
    then: "Within 1% quality, 50% less KV memory"
