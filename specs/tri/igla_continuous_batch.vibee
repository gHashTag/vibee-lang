# VIBEE Specification - IGLA Continuous Batching
# Dynamic batching for optimal GPU utilization
# Inference Optimization v1
# φ² + 1/φ² = 3 | PHOENIX = 999

name: igla_continuous_batch
version: "1.0.0"
language: zig
module: igla_continuous_batch

types:
  BatchScheduler:
    fields:
      id: String
      max_batch_size: Int
      max_tokens: Int
      current_batch_size: Int
      running: Bool

  Request:
    fields:
      id: String
      prompt_tokens: String
      max_new_tokens: Int
      priority: Int
      arrival_time: Int

  BatchSlot:
    fields:
      request_id: String
      position: Int
      tokens_generated: Int
      finished: Bool

  SchedulerConfig:
    fields:
      max_batch_size: Int
      max_waiting_tokens: Int
      max_running_tokens: Int
      preemption_mode: String

  BatchState:
    fields:
      running_requests: String
      waiting_requests: String
      preempted_requests: String

  IterationResult:
    fields:
      outputs: String
      finished_requests: String
      new_tokens: Int

  PreemptionEvent:
    fields:
      request_id: String
      reason: String
      timestamp: Int

  BatchMetrics:
    fields:
      total_requests: Int
      avg_batch_size: Float
      avg_wait_time_ms: Float
      throughput_tokens_per_sec: Float
      gpu_utilization: Float

behaviors:
  - name: create_scheduler
    given: Scheduler config
    when: Scheduler creation
    then: Batch scheduler ready

  - name: add_request
    given: New request
    when: Request submission
    then: Request queued

  - name: schedule_batch
    given: Waiting requests
    when: Scheduling
    then: Batch formed

  - name: run_iteration
    given: Current batch
    when: Forward pass
    then: New tokens generated

  - name: finish_request
    given: Completed request
    when: Completion
    then: Request removed from batch

  - name: preempt_request
    given: Memory pressure
    when: Preemption
    then: Request paused

  - name: resume_request
    given: Preempted request
    when: Resources available
    then: Request resumed

  - name: reorder_batch
    given: Priority changes
    when: Reordering
    then: Batch reordered

  - name: get_throughput
    given: Metrics
    when: Throughput query
    then: Tokens per second returned

  - name: get_metrics
    given: Scheduler
    when: Metrics requested
    then: Batch metrics returned

test_cases:
  - name: test_create_scheduler
    input: { max_batch: 32, max_tokens: 4096 }
    expected: { created: true }

  - name: test_add_request
    input: { prompt: [1, 2, 3], max_tokens: 100 }
    expected: { queued: true }

  - name: test_schedule
    input: { waiting: 5 }
    expected: { batch_formed: true }

  - name: test_iteration
    input: { batch_size: 4 }
    expected: { new_tokens: 4 }

  - name: test_finish
    input: { request_id: "r1" }
    expected: { removed: true }

  - name: test_preempt
    input: { request_id: "r2" }
    expected: { preempted: true }

  - name: test_metrics
    input: {}
    expected: { total_requests: 0 }
