# iGLA v3 QLoRA - Quantized LoRA
# 65% memory reduction with 4-bit base
# φ² + 1/φ² = 3 | PHOENIX = 999
# Paper: arXiv:2305.14314

name: igla_v3_qlora
version: "3.0.0"
language: zig
module: igla_v3_qlora

creation_pattern:
  source: QuantizedModel
  transformer: QLoRAAdapter
  result: EfficientFinetune

types:
  QLoRAConfig:
    fields:
      base_bits: Int  # 4
      lora_rank: Int
      lora_alpha: Float
      double_quant: Bool
      
behaviors:
  - name: quantize_base
    given: "FP16 weights"
    when: "NF4 quantization"
    then: "Return 4-bit weights"
    
  - name: qlora_forward
    given: "Input, quantized base, LoRA"
    when: "Forward pass"
    then: "Return output with LoRA delta"
    
  - name: double_quantize
    given: "Quantization constants"
    when: "Second quantization"
    then: "Return doubly quantized"
