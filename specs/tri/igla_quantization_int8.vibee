# iGLA INT8 Quantization
# 8-bit integer quantization for embeddings
# Scientific basis: Jacob et al. 2018, Gholami et al. 2021
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_quantization_int8
version: "1.0.0"
language: zig
module: igla_quantization_int8

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999
  int8_min: -128
  int8_max: 127

scientific_references:
  - "Jacob et al. 2018: Quantization and Training of Neural Networks"
  - "Gholami et al. 2021: A Survey of Quantization Methods"
  - "Wu et al. 2020: Integer Quantization for Deep Learning Inference"

types:
  QuantConfig:
    fields:
      scale: Float
      zero_point: Int
      symmetric: Bool

  QuantizedVector:
    fields:
      values: String
      scale: Float
      zero_point: Int
      dim: Int

  CalibrationStats:
    fields:
      min_val: Float
      max_val: Float
      mean: Float
      std: Float

  QuantizationError:
    fields:
      mse: Float
      max_error: Float
      cosine_sim: Float

  DequantizedVector:
    fields:
      values: String
      dim: Int

  QuantBatch:
    fields:
      vectors: String
      count: Int
      shared_scale: Float

behaviors:
  - name: calibrate
    given: "Sample vectors"
    when: "Calibration"
    then: "Scale and zero_point computed"

  - name: quantize_symmetric
    given: "FP32 vector, scale"
    when: "Symmetric quantization"
    then: "INT8 vector (zero_point=0)"

  - name: quantize_asymmetric
    given: "FP32 vector, scale, zero_point"
    when: "Asymmetric quantization"
    then: "INT8 vector with offset"

  - name: dequantize
    given: "INT8 vector, scale, zero_point"
    when: "Dequantization"
    then: "FP32 vector restored"

  - name: dot_product_int8
    given: "Two INT8 vectors"
    when: "INT8 dot product"
    then: "Approximate dot product"

  - name: compute_error
    given: "Original, quantized"
    when: "Error analysis"
    then: "Quantization error metrics"

  - name: optimize_scale
    given: "Vectors, target_error"
    when: "Scale optimization"
    then: "Optimal scale factor"

  - name: phi_quantization_levels
    given: "Value range"
    when: "Sacred quantization"
    then: "φ-distributed levels"
