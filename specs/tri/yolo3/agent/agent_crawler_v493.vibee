name: agent_crawler_v493
version: "493.0.0"
language: zig
module: agent_crawler_v493

types:
  CrawlerAgent:
    fields:
      agent_id: String
      seed_urls: List<String>
      max_depth: Int
      max_pages: Int
      crawl_delay_ms: Int

  CrawlFrontier:
    fields:
      pending_urls: List<String>
      visited_urls: List<String>
      failed_urls: List<String>
      priority_queue: List<String>

  CrawledPage:
    fields:
      url: String
      depth: Int
      status_code: Int
      content_type: String
      links: List<String>
      crawled_at: Timestamp

  CrawlPolicy:
    fields:
      allowed_domains: List<String>
      blocked_patterns: List<String>
      follow_external: Bool
      max_redirects: Int

  CrawlStats:
    fields:
      pages_crawled: Int
      pages_failed: Int
      links_discovered: Int
      bytes_downloaded: Int
      duration_ms: Int

behaviors:
  - name: initialize_crawler
    given: Seed URLs and config
    when: Start crawl
    then: Initialize frontier

  - name: get_next_url
    given: Crawl frontier
    when: URL needed
    then: Return prioritized URL

  - name: crawl_page
    given: Target URL
    when: Crawl requested
    then: Fetch and parse page

  - name: extract_links
    given: Page content
    when: Parse links
    then: Return discovered links

  - name: filter_links
    given: Links and policy
    when: Filter needed
    then: Return allowed links

  - name: update_frontier
    given: New links
    when: Links discovered
    then: Add to frontier

  - name: check_visited
    given: URL
    when: Duplicate check
    then: Return if visited

  - name: get_crawl_stats
    given: Crawler state
    when: Stats requested
    then: Return statistics

  - name: stop_crawl
    given: Stop condition
    when: Limit reached
    then: Finalize crawl
