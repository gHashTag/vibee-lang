# iGLA KOSHEY v7 - Few-Shot Learning
# Learn from minimal examples (1-5 shots)
# φ² + 1/φ² = 3 | PHOENIX = 999
# arXiv: In-context learning, meta-learning, MAML

name: igla_koshey_few_shot
version: "7.0.0"
language: zig
module: igla_koshey_few_shot

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  FewShotConfig:
    fields:
      max_examples: Int
      example_selection: String
      pattern_extraction: Bool
      rapid_adaptation: Float

  FewShotExample:
    fields:
      input: String
      output: String
      explanation: Option<String>
      domain: String

  FewShotContext:
    fields:
      examples: List<FewShotExample>
      task_description: String
      format_template: String
      constraints: List<String>

  FewShotMetrics:
    fields:
      one_shot_accuracy: Float
      five_shot_accuracy: Float
      example_efficiency: Float
      pattern_recognition: Float

behaviors:
  - name: select_examples
    given: "Example pool"
    when: "Example selection"
    then: "Most informative examples selected"

  - name: extract_pattern
    given: "Few examples"
    when: "Pattern extraction"
    then: "Underlying pattern identified"

  - name: apply_pattern
    given: "Extracted pattern"
    when: "New input"
    then: "Pattern applied to generate output"

  - name: rapid_adapt
    given: "Single example"
    when: "One-shot learning"
    then: "Model adapted from one example"

  - name: interpolate_examples
    given: "Multiple examples"
    when: "Interpolation"
    then: "Solution interpolated from examples"

  - name: meta_generalize
    given: "Few-shot experience"
    when: "Meta-learning"
    then: "Few-shot ability improved"

  - name: phi_few_shot
    given: "Minimal examples"
    when: "Learning efficiency"
    then: "φ-ratio optimizes example usage"
