# Context Iteration System
# Rapid iteration cycle: hours not weeks
# Core Manus insight: Context Engineering beats Fine-tuning

name: context_iteration
version: "1.0.0"
language: zig
module: context_iteration

types:
  Iteration:
    fields:
      iteration_id: String
      iteration_number: Int
      started_at: Timestamp
      completed_at: Option<Timestamp>
      status: String

  IterationChange:
    fields:
      change_id: String
      change_type: String
      description: String
      affected_templates: List<String>
      affected_variables: List<String>

  IterationMetrics:
    fields:
      metrics_id: String
      iteration_id: String
      time_to_deploy_hours: Float
      benchmark_before: Float
      benchmark_after: Float
      delta_percentage: Float

  IterationExperiment:
    fields:
      experiment_id: String
      hypothesis: String
      control_context: String
      variant_context: String
      sample_size: Int
      results: Option<String>

  IterationPipeline:
    fields:
      pipeline_id: String
      stages: List<String>
      current_stage: String
      auto_rollback: Bool

  IterationFeedback:
    fields:
      feedback_id: String
      iteration_id: String
      source: String
      sentiment: String
      actionable_items: List<String>

  DeploymentWindow:
    fields:
      window_id: String
      start_time: Timestamp
      end_time: Timestamp
      allowed_changes: List<String>
      rollback_threshold: Float

behaviors:
  - name: start_iteration
    given: Change description and hypothesis
    when: New iteration begins
    then: Returns iteration ID with tracking enabled

  - name: apply_changes
    given: Iteration ID and change list
    when: Changes are ready to deploy
    then: Returns deployment result with metrics

  - name: run_experiment
    given: Control and variant contexts
    when: A/B test is configured
    then: Returns experiment ID with traffic split

  - name: collect_metrics
    given: Iteration ID and metric types
    when: Metrics collection triggered
    then: Returns comprehensive metrics report

  - name: evaluate_iteration
    given: Iteration metrics and success criteria
    when: Evaluation requested
    then: Returns pass/fail with recommendations

  - name: auto_rollback
    given: Iteration ID and failure threshold
    when: Metrics fall below threshold
    then: Triggers automatic rollback to previous version

  - name: promote_to_production
    given: Iteration ID and approval
    when: Iteration passes all checks
    then: Promotes context changes to production

  - name: generate_iteration_report
    given: Iteration ID
    when: Report generation requested
    then: Returns detailed iteration report with learnings
