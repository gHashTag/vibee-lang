name: zig_together_provider
version: "1.0.0"
language: zig
module: together_provider

description: |
  Together AI Provider - Free tier available.
  OpenAI-compatible API.
  Models: Llama, Mistral, Qwen, DeepSeek.
  φ² + 1/φ² = 3

constants:
  TOGETHER_API_URL: "https://api.together.xyz/v1/chat/completions"
  LLAMA_31_70B: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
  LLAMA_31_8B: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
  QWEN_25_72B: "Qwen/Qwen2.5-72B-Instruct-Turbo"
  DEEPSEEK_V3: "deepseek-ai/DeepSeek-V3"
  DEFAULT_MODEL: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"

types:
  TogetherConfig:
    fields:
      api_key: String
      model: String
      max_tokens: Int
      temperature: Float

  TogetherResponse:
    fields:
      content: String
      finish_reason: String
      prompt_tokens: Int
      completion_tokens: Int
      total_tokens: Int
      latency_ms: Int

behaviors:
  - name: init
    given: TogetherConfig
    when: Creating Together provider
    then: Returns initialized provider

  - name: complete
    given: Messages array
    when: Calling Together chat completions API
    then: Returns response with content

  - name: complete_with_system
    given: System prompt and user message
    when: Calling with system context
    then: Returns response
