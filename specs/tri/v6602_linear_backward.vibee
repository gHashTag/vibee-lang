# v6602 - Linear Layer with Backward
# ====================================
# Linear слой с полным backward pass
# Y = X @ W + b
# dW = X^T @ dY, db = sum(dY), dX = dY @ W^T
# φ² + 1/φ² = 3 | PHOENIX = 999

name: linear_backward
version: "6.6.2"
language: zig
module: linear_backward

constants:
  PHI: 1.618033988749895

types:
  LinearLayer:
    fields:
      weight: List
      bias: List
      weight_grad: List
      bias_grad: List
      in_features: Int
      out_features: Int
      
  LinearCache:
    fields:
      input: List
      batch_size: Int
      
  LinearGrads:
    fields:
      d_weight: List
      d_bias: List
      d_input: List

behaviors:
  - name: linear_init
    given: In_features, out_features, seed
    when: Layer initialization
    then: Вернуть layer with Xavier weights
    
  - name: linear_forward
    given: Input, layer, batch_size
    when: Forward pass
    then: Вернуть output = X @ W + b, cache input
    
  - name: linear_backward
    given: Output_grad, layer, cache
    when: Backward pass
    then: Compute dW, db, dX и accumulate to layer grads
    
  - name: linear_zero_grad
    given: Layer
    when: Gradient reset
    then: Zero weight_grad и bias_grad
    
  - name: linear_num_params
    given: Layer
    when: Parameter count
    then: Вернуть in_features * out_features + out_features
    
  - name: matmul_forward
    given: A, B, M, K, N
    when: Matrix multiplication
    then: Вернуть C = A @ B
    
  - name: matmul_backward_a
    given: dC, B, M, K, N
    when: Gradient w.r.t. A
    then: Вернуть dA = dC @ B^T
    
  - name: matmul_backward_b
    given: dC, A, M, K, N
    when: Gradient w.r.t. B
    then: Вернуть dB = A^T @ dC
