# v4802 - Graph Attention
# ========================
# GAT - внимание на графах
# φ² + 1/φ² = 3 | PHOENIX = 999

name: graph_attention
version: "4.8.2"
language: zig
module: graph_attention

constants:
  PHI: 1.618033988749895
  NUM_HEADS: 8
  DROPOUT: 0.6
  NEGATIVE_SLOPE: 0.2

types:
  GATConfig:
    fields:
      num_heads: Int
      hidden_dim: Int
      dropout: Float
      
  AttentionCoefficients:
    fields:
      src_node: Int
      dst_node: Int
      alpha: Float
      
  GATLayer:
    fields:
      W: List
      a: List
      num_heads: Int
      
  MultiHeadAttention:
    fields:
      heads: List
      concat: Bool
      
  GATv2Layer:
    fields:
      W: List
      a: List
      share_weights: Bool
      
  EdgeAttention:
    fields:
      edge_index: List
      attention_weights: List
      
  AttentionHead:
    fields:
      W_src: List
      W_dst: List
      a: List
      
  SparseAttention:
    fields:
      indices: List
      values: List
      shape: List

behaviors:
  - name: compute_attention_coefficients
    given: Node features и edge_index
    when: Вычисление alpha
    then: Вернуть attention coefficients
    
  - name: apply_attention
    given: Features и attention weights
    when: Weighted aggregation
    then: Вернуть attended features
    
  - name: gat_layer_forward
    given: Features, edge_index, layer
    when: GAT layer forward
    then: Вернуть updated features
    
  - name: multi_head_attention
    given: Features и heads
    when: Multi-head GAT
    then: Вернуть concatenated/averaged
    
  - name: gatv2_attention
    given: Features и layer
    when: GATv2 dynamic attention
    then: Вернуть attention и features
    
  - name: sparse_attention_forward
    given: Sparse attention и features
    when: Efficient sparse attention
    then: Вернуть output
    
  - name: edge_softmax
    given: Edge scores и edge_index
    when: Softmax по соседям
    then: Вернуть normalized attention
    
  - name: leaky_relu_attention
    given: Attention logits
    when: LeakyReLU activation
    then: Вернуть activated logits
