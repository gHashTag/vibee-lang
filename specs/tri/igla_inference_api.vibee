# iGLA Inference API
# REST/gRPC API server for LLM inference
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_inference_api
version: "1.0.0"
language: zig
module: igla_inference_api

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  APIConfig:
    fields:
      host: String
      port: Int
      workers: Int
      timeout_seconds: Int
      max_concurrent_requests: Int

  CompletionRequest:
    fields:
      model: String
      prompt: String
      max_tokens: Int
      temperature: Float
      top_p: Float
      stream: Bool
      stop: String

  CompletionResponse:
    fields:
      id: String
      object: String
      created: Int
      model: String
      choices: String
      usage: String

  ChatMessage:
    fields:
      role: String
      content: String
      name: String

  ChatRequest:
    fields:
      model: String
      messages: String
      max_tokens: Int
      temperature: Float
      stream: Bool

  UsageInfo:
    fields:
      prompt_tokens: Int
      completion_tokens: Int
      total_tokens: Int

  APIError:
    fields:
      code: Int
      message: String
      type: String

behaviors:
  - name: start_server
    given: "API config"
    when: "Server start"
    then: "HTTP/gRPC server running"

  - name: handle_completion
    given: "Completion request"
    when: "POST /v1/completions"
    then: "Completion response returned"

  - name: handle_chat
    given: "Chat request"
    when: "POST /v1/chat/completions"
    then: "Chat response returned"

  - name: handle_embeddings
    given: "Embedding request"
    when: "POST /v1/embeddings"
    then: "Embeddings returned"

  - name: handle_models
    given: "Models request"
    when: "GET /v1/models"
    then: "Available models listed"

  - name: handle_health
    given: "Health check"
    when: "GET /health"
    then: "Health status returned"

  - name: validate_request
    given: "Incoming request"
    when: "Validation"
    then: "Request validated or error"

  - name: rate_limit
    given: "Request"
    when: "Rate limiting"
    then: "Request allowed or throttled"

  - name: authenticate
    given: "API key"
    when: "Authentication"
    then: "Request authenticated"

  - name: phi_api_harmony
    given: "API"
    when: "Harmony"
    then: "φ-optimal request handling"
