# Reflexion Module - Verbal Reinforcement Learning
# Based on arXiv:2303.11366 - 91% HumanEval
# Self-reflection and correction without weight updates

name: agent_reflexion
version: "1.0.0"
language: zig
module: agent_reflexion

types:
  ReflexionMemory:
    fields:
      memory_id: String
      reflections: List<String>
      max_reflections: Int
      current_trial: Int

  Reflection:
    fields:
      reflection_id: String
      trial_number: Int
      task_feedback: String
      self_reflection: String
      lessons_learned: List<String>

  TrialResult:
    fields:
      trial_id: String
      success: Bool
      trajectory: List<String>
      feedback_signal: String
      error_analysis: Option<String>

  ReflexionConfig:
    fields:
      max_trials: Int
      reflection_prompt: String
      feedback_type: String
      memory_window: Int

  SelfCritique:
    fields:
      critique_id: String
      what_went_wrong: String
      what_to_improve: String
      specific_changes: List<String>

behaviors:
  - name: execute_trial
    given: Task and current memory
    when: New trial begins
    then: Returns trial result with trajectory

  - name: generate_reflection
    given: Trial result and feedback
    when: Trial fails or needs improvement
    then: Returns self-reflection with lessons

  - name: update_memory
    given: New reflection and memory
    when: Memory update needed
    then: Returns updated episodic memory

  - name: apply_lessons
    given: Lessons and next trial context
    when: Starting new trial
    then: Returns context with applied lessons

  - name: detect_repeated_errors
    given: Current error and memory
    when: Error pattern detection needed
    then: Returns whether error is repeated

  - name: generate_self_critique
    given: Failed trajectory
    when: Deep analysis needed
    then: Returns detailed self-critique

  - name: check_convergence
    given: Trial history
    when: Convergence check needed
    then: Returns whether to continue trials
