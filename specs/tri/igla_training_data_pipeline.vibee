# iGLA Training Data Pipeline
# Data preprocessing and loading
# φ² + 1/φ² = 3 | V = n × 3^k × π^m × φ^p

name: igla_training_data_pipeline
version: "1.0.0"
language: zig
module: igla_training_data_pipeline

sacred_constants:
  phi: 1.618033988749895
  trinity: 3.0
  phoenix: 999

types:
  DataPipelineConfig:
    fields:
      data_sources: List<String>
      total_tokens: String
      sequence_length: Int
      batch_size: Int
      num_workers: Int

  DataSource:
    fields:
      name: String
      path: String
      weight: Float
      tokens: String
      quality_score: Float

  DataBatch:
    fields:
      input_ids: List<Int>
      attention_mask: List<Int>
      labels: List<Int>
      batch_size: Int

  DataPipelineMetrics:
    fields:
      throughput_samples_sec: Float
      tokens_processed: String
      data_efficiency: Float
      quality_score: Float

behaviors:
  - name: load_data_sources
    given: "Data configuration"
    when: "Loading"
    then: "RedPajama, SlimPajama, Dolma, FineWeb loaded"

  - name: preprocess_text
    given: "Raw text"
    when: "Preprocessing"
    then: "Cleaned, normalized, filtered"

  - name: tokenize_batch
    given: "Text batch"
    when: "Tokenization"
    then: "Token IDs generated"

  - name: create_sequences
    given: "Tokens"
    when: "Sequencing"
    then: "Fixed-length sequences created"

  - name: mix_domains
    given: "Multiple sources"
    when: "Mixing"
    then: "Domain-balanced batches"

  - name: stream_batches
    given: "Sequences"
    when: "Streaming"
    then: "Efficient batch streaming"

  - name: phi_data_harmony
    given: "Data pipeline"
    when: "Harmony"
    then: "φ-weighted domain mixing"
