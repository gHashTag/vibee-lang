# v3900 - Reinforcement Learning
# ================================
# RL algorithms for decision making
# φ² + 1/φ² = 3 | PHOENIX = 999

name: reinforcement_learning
version: "3.9.0"
language: zig
module: reinforcement_learning

constants:
  PHI: 1.618033988749895
  GAMMA: 0.99
  GAE_LAMBDA: 0.95
  CLIP_RANGE: 0.2
  ENTROPY_COEF: 0.01

types:
  RLConfig:
    fields:
      algorithm: String
      gamma: Float
      learning_rate: Float
      batch_size: Int
      
  State:
    fields:
      observation: List
      info: Map
      
  Action:
    fields:
      action: List
      log_prob: Float
      
  Transition:
    fields:
      state: State
      action: Action
      reward: Float
      next_state: State
      done: Bool
      
  ReplayBuffer:
    fields:
      transitions: List
      max_size: Int
      priority: Bool
      
  PolicyNetwork:
    fields:
      layers: List
      action_space: String
      
  ValueNetwork:
    fields:
      layers: List
      
  PPOConfig:
    fields:
      clip_range: Float
      value_coef: Float
      entropy_coef: Float
      gae_lambda: Float

behaviors:
  - name: select_action
    given: State and policy
    when: Choosing action
    then: Return action and log probability
    
  - name: compute_returns
    given: Rewards and gamma
    when: Computing discounted returns
    then: Return return values
    
  - name: compute_gae
    given: Rewards, values, and lambda
    when: Computing advantages
    then: Return GAE advantages
    
  - name: ppo_update
    given: Batch and networks
    when: PPO policy update
    then: Return updated policy
    
  - name: dqn_update
    given: Batch and Q-network
    when: DQN value update
    then: Return updated Q-network
    
  - name: sample_from_buffer
    given: Buffer and batch size
    when: Sampling transitions
    then: Return batch of transitions
    
  - name: soft_update_target
    given: Online and target networks
    when: Polyak averaging
    then: Return updated target
    
  - name: evaluate_policy
    given: Policy and environment
    when: Testing performance
    then: Return average return
