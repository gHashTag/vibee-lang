# VIBEE ⲦⲢⲒⲚⲒⲦⲨ Token Stream
# Поток токенов для парсера
# φ² + 1/φ² = 3 | 27 символов = 3³

name: coptic_token_stream
version: "1.0.0"
language: zig
module: coptic_token_stream

sacred_formula:
  phi: 1.618033988749895
  identity: "φ² + 1/φ² = 3"
  trinity: 27
  phoenix: 999

creation_patterns:
  stream_from_lexer:
    source: Lexer
    transformer: StreamBuilder
    result: TokenStream

  filtered_stream:
    source: TokenStream
    transformer: TokenFilter
    result: TokenStream

types:
  TokenStream:
    fields:
      tokens: List<String>
      position: Int
      length: Int
      source_name: String

  StreamToken:
    fields:
      kind: Int
      lexeme: String
      span_start: Int
      span_end: Int
      line: Int
      column: Int

  TokenSpan:
    fields:
      start: Int
      end: Int
      length: Int

  StreamState:
    fields:
      current_index: Int
      mark_index: Int
      eof_reached: Bool

  LookaheadBuffer:
    fields:
      tokens: List<String>
      size: Int
      head: Int

  TokenPredicate:
    fields:
      kind_match: Int
      lexeme_match: String
      any_of: List<String>

  StreamCheckpoint:
    fields:
      position: Int
      state_hash: Int

behaviors:
  - name: create_stream
    given: List of tokens from lexer
    when: Stream creation requested
    then: Returns initialized TokenStream

  - name: current
    given: TokenStream
    when: Current token requested
    then: Returns StreamToken at current position

  - name: advance
    given: TokenStream
    when: Advance requested
    then: Returns next token and advances position

  - name: peek
    given: TokenStream
    when: Peek requested
    then: Returns current token without advancing

  - name: peek_ahead
    given: TokenStream and offset
    when: Lookahead requested
    then: Returns token at position + offset

  - name: match_token
    given: TokenStream and expected kind
    when: Match requested
    then: Returns true and advances if match

  - name: expect_token
    given: TokenStream and expected kind
    when: Expect requested
    then: Returns token or error if no match

  - name: is_at_end
    given: TokenStream
    when: End check requested
    then: Returns true if at EOF token

  - name: mark
    given: TokenStream
    when: Mark position requested
    then: Saves current position for backtrack

  - name: reset_to_mark
    given: TokenStream
    when: Reset requested
    then: Returns to marked position

  - name: filter_whitespace
    given: TokenStream
    when: Whitespace filter requested
    then: Returns stream without whitespace tokens

  - name: filter_comments
    given: TokenStream
    when: Comment filter requested
    then: Returns stream without comment tokens

  - name: get_span
    given: Start and end tokens
    when: Span calculation requested
    then: Returns TokenSpan covering range

test_cases:
  - name: test_create_stream
    input: "[const, x, =, 42]"
    expected: "TokenStream{length: 4}"

  - name: test_advance
    input: "stream at position 0"
    expected: "position becomes 1"

  - name: test_peek_ahead
    input: "stream, offset: 2"
    expected: "token at position + 2"

  - name: test_match_success
    input: "stream with const, expect const"
    expected: "true, position advances"

  - name: test_match_fail
    input: "stream with const, expect var"
    expected: "false, position unchanged"

pas_analysis:
  paper_references:
    - "Parser Combinators"
    - "Recursive Descent Parsing"
    - "Token Stream Abstractions"
  key_insights:
    - "Lookahead for LL(k) parsing"
    - "Backtracking with marks"
    - "Filtered streams for clean parsing"

self_evolution:
  metrics:
    - "Lookahead efficiency"
    - "Memory per stream"
    - "Backtrack frequency"
  improvement_targets:
    - "Lazy token generation"
    - "Parallel stream processing"
    - "Compressed token storage"
