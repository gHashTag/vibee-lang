name: agent_vision_v280
version: "1.0.0"
language: zig
module: agent_vision_v280

types:
  VisualElement:
    fields:
      id: String
      tag: String
      bounds: Object
      visible: Bool
      text: String
      attributes: Object

  Screenshot:
    fields:
      data: String
      width: Int
      height: Int
      format: String
      timestamp: Timestamp

  VisualDiff:
    fields:
      before: String
      after: String
      changed_regions: List<Object>
      similarity: Float

  OCRResult:
    fields:
      text: String
      confidence: Float
      bounds: Object
      language: String

  ObjectDetection:
    fields:
      label: String
      confidence: Float
      bounds: Object
      category: String

  VisualContext:
    fields:
      elements: List<VisualElement>
      screenshot: Screenshot
      ocr_results: List<OCRResult>
      detections: List<ObjectDetection>

  VisionConfig:
    fields:
      ocr_enabled: Bool
      detection_enabled: Bool
      diff_threshold: Float
      capture_format: String

behaviors:
  - name: capture_viewport
    given: Browser page loaded
    when: Capture requested
    then: Screenshot captured with metadata

  - name: detect_elements
    given: Screenshot available
    when: Element detection runs
    then: Visual elements identified with bounds

  - name: extract_text_ocr
    given: Screenshot region selected
    when: OCR processing runs
    then: Text extracted with confidence scores

  - name: detect_objects
    given: Screenshot available
    when: Object detection runs
    then: Objects labeled with categories

  - name: compute_visual_diff
    given: Two screenshots available
    when: Diff computation runs
    then: Changed regions identified

  - name: build_visual_context
    given: All vision data collected
    when: Context building runs
    then: Unified visual context created

  - name: find_element_visually
    given: Visual description provided
    when: Visual search runs
    then: Matching element located

  - name: verify_visual_state
    given: Expected visual state defined
    when: Verification runs
    then: Match result with confidence
