# v6000 - Tensor with Autograd
# =============================
# Тензоры с автоматическим дифференцированием
# V = n × 3^k × π^m × φ^p | φ² + 1/φ² = 3 | PHOENIX = 999

name: tensor_autograd
version: "6.0.0"
language: zig
module: tensor_autograd

constants:
  PHI: 1.618033988749895
  GOLDEN_IDENTITY: 3.0
  PHOENIX: 999
  EPSILON: 1e-8

types:
  AutogradTensor:
    fields:
      data: List
      grad: List
      shape: List
      requires_grad: Bool
      grad_fn: String
      
  GradContext:
    fields:
      saved_tensors: List
      needs_input_grad: Bool
      
  ComputeNode:
    fields:
      operation: String
      inputs: List
      output: AutogradTensor
      
  TapeEntry:
    fields:
      node: ComputeNode
      backward_fn: String

behaviors:
  - name: create_tensor
    given: Shape и requires_grad
    when: Создание тензора
    then: Вернуть AutogradTensor с нулевыми данными
    
  - name: tensor_from_data
    given: Data array и shape
    when: Создание из данных
    then: Вернуть AutogradTensor с данными
    
  - name: zero_grad
    given: AutogradTensor
    when: Обнуление градиентов
    then: Установить grad в нули
    
  - name: accumulate_grad
    given: Tensor и incoming grad
    when: Накопление градиента
    then: Добавить grad к существующему
    
  - name: detach
    given: AutogradTensor
    when: Отсоединение от графа
    then: Вернуть копию без grad_fn
    
  - name: backward
    given: Loss tensor
    when: Обратное распространение
    then: Вычислить градиенты всех requires_grad тензоров
    
  - name: register_hook
    given: Tensor и callback
    when: Регистрация хука
    then: Вызывать callback при backward
    
  - name: retain_grad
    given: Non-leaf tensor
    when: Сохранение градиента
    then: Сохранить grad после backward
