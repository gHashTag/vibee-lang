# TheoryOfMind - Social Cognition and Mental State Attribution
# Source: Theory of Mind research
# PAS Analysis: D&C (agent modeling), MLS (belief inference), PRB (uncertainty)

name: theory_of_mind
version: "1.0.0"
language: 999
module: ⲦⲎⲈⲞⲢⲨ_ⲞⲪ_ⲘⲒⲚⲆ

pas_analysis:
  source_paper: "Theory of Mind research"
  current_complexity: "O(n * a) where a = agents"
  theoretical_lower_bound: "O(n) shared model"
  gap: "Factor of a via abstraction"
  patterns_applicable:
    - symbol: D&C
      name: "Divide-and-Conquer"
      success_rate: 0.31
      rationale: "Per-agent modeling"
    - symbol: MLS
      name: "ML-Guided Search"
      success_rate: 0.06
      rationale: "Learn belief inference"
    - symbol: PRB
      name: "Probabilistic"
      success_rate: 0.12
      rationale: "Uncertain mental states"
    - symbol: PRE
      name: "Precomputation"
      success_rate: 0.16
      rationale: "Cache agent models"
  confidence: 0.73
  predicted_improvement: "Human-like social reasoning"

creation_pattern:
  source: SocialObservation
  transformer: MentalStateInferrer
  result: BeliefDesireIntention

behaviors:
  - name: belief_attribution
    given: "Agent's observations"
    when: "Infer agent's beliefs"
    then: "Belief state"
    test_cases:
      - name: false_belief
        input:
          agent: "Sally"
          object_moved: true
          agent_saw: false
        expected:
          belief: "original_location"
          false_belief_understood: true

  - name: desire_inference
    given: "Agent's actions"
    when: "Infer goals"
    then: "Desire state"
    test_cases:
      - name: goal_inference
        input:
          actions: ["approach_food", "reach"]
          context: "hungry"
        expected:
          desire: "eat_food"
          confidence: 0.9

  - name: intention_prediction
    given: "Beliefs and desires"
    when: "Predict next action"
    then: "Intended action"
    test_cases:
      - name: action_prediction
        input:
          belief: "food_in_kitchen"
          desire: "eat"
        expected:
          intention: "go_to_kitchen"
          rational: true

  - name: recursive_reasoning
    given: "Multi-agent scenario"
    when: "Model beliefs about beliefs"
    then: "Higher-order ToM"
    test_cases:
      - name: second_order
        input:
          agent_a_believes: "agent_b_believes_X"
          actual: "Y"
        expected:
          second_order_tom: true
          depth: 2

algorithms:
  bdi_model:
    beliefs: "World state representation"
    desires: "Goal states"
    intentions: "Committed plans"
    
  bayesian_tom:
    prior: "Agent type distribution"
    likelihood: "Action given mental state"
    posterior: "Mental state given actions"
    
  inverse_planning:
    method: "Infer goals from actions"
    rationality: "Assume approximately rational"

tom_levels:
  level_0: "No mental state reasoning"
  level_1: "First-order beliefs"
  level_2: "Beliefs about beliefs"
  level_n: "Recursive reasoning"

metrics:
  false_belief_accuracy: 0.9
  goal_inference_accuracy: 0.85
  action_prediction: 0.8
  recursive_depth: 3
