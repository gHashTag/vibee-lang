# SymbolicRegression - Neural-Guided Formula Discovery
# Source: arXiv:2509.10089 - KAN-SR, arXiv:2510.06635 - StruSR, arXiv:2111.00053 - Neural-Guided GP
# PAS Analysis: MLS (neural guidance), ALG (Taylor expansion), PRB (genetic programming)

name: symbolic_regression
version: "1.0.0"
language: 999
module: ⲤⲨⲘⲂⲞⲖⲒⲔ_ⲢⲈⲄⲢⲈⲤⲤⲒⲞⲚ

pas_analysis:
  source_paper: "arXiv:2509.10089, arXiv:2510.06635, arXiv:2111.00053"
  current_complexity: "O(n^k) exhaustive formula search"
  theoretical_lower_bound: "O(n log n) guided search"
  gap: "Exponential via neural guidance"
  patterns_applicable:
    - symbol: MLS
      name: "ML-Guided Search"
      success_rate: 0.06
      rationale: "KAN/PINN guides formula structure"
    - symbol: ALG
      name: "Algebraic Reorganization"
      success_rate: 0.22
      rationale: "Taylor expansion for local structure"
    - symbol: PRB
      name: "Probabilistic"
      success_rate: 0.12
      rationale: "Genetic programming evolution"
    - symbol: D&C
      name: "Divide-and-Conquer"
      success_rate: 0.31
      rationale: "Divide formula into subexpressions"
  confidence: 0.73
  predicted_improvement: "65% more expressions recovered"

creation_pattern:
  source: DataPoints
  transformer: FormulaEvolver
  result: SymbolicExpression

behaviors:
  - name: kan_guided_search
    given: "Dataset of (x, y) pairs"
    when: "Train KAN, extract structure"
    then: "Produce symbolic formula"
    test_cases:
      - name: feynman_equation
        input:
          data: "physics_dataset"
          ground_truth: "E = mc^2"
        expected:
          recovered: true
          formula: "E = m * c^2"

  - name: taylor_guidance
    given: "Trained PINN"
    when: "Compute local Taylor expansion"
    then: "Extract derivative structure"
    test_cases:
      - name: pde_structure
        input:
          pinn_output: "u(x,t)"
          expansion_order: 3
        expected:
          coefficients: [1.0, 0.0, -0.5]
          structure_preserved: true

  - name: masking_attribution
    given: "Expression tree"
    when: "Mask subtrees, measure contribution"
    then: "Score subtree importance"
    test_cases:
      - name: subtree_importance
        input:
          expression: "a*x^2 + b*x + c"
          target: "quadratic"
        expected:
          important_subtrees: ["x^2", "x"]
          scores: [0.8, 0.6, 0.2]

  - name: neural_seeded_gp
    given: "Neural network predictions"
    when: "Seed GP population"
    then: "Evolve better expressions"
    test_cases:
      - name: population_seeding
        input:
          neural_seeds: 100
          generations: 50
        expected:
          recovery_improvement: 0.65
          convergence_faster: true

algorithms:
  kan:
    name: "Kolmogorov-Arnold Network"
    formula: "f(x) = sum_q sum_p phi_q(sum_p psi_p(x_p))"
    advantage: "Interpretable activation functions"
    
  strusr:
    taylor_guidance: "Extract coefficients from PINN"
    masking_attribution: "Score subtree contributions"
    hybrid_fitness: "physics_residual + taylor_mismatch"
    
  neural_guided_gp:
    seeding: "Neural network generates initial population"
    evolution: "Genetic operators preserve high-score subtrees"
    improvement: "65% more expressions vs baseline"

metrics:
  feynman_recovery: 0.85
  srsd_accuracy: 0.92
  convergence_speedup: 2.5
  interpretability: "high"
