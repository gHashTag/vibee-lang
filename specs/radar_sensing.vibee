# RadarSensing - mmWave Radar for Human Activity Recognition
# Source: arXiv:2501.13805 - mmEgoHand, arXiv:2511.08910 - OG-PCL
# PAS Analysis: D&C (point cloud), MLS (activity classification), PRE (doppler features)

name: radar_sensing
version: "1.0.0"
language: 999
module: ⲢⲀⲆⲀⲢ_ⲤⲈⲚⲤⲒⲚⲄ

pas_analysis:
  source_paper: "arXiv:2501.13805, arXiv:2511.08910, arXiv:2306.17010"
  current_complexity: "O(n * p) where p = points"
  theoretical_lower_bound: "O(n) sparse processing"
  gap: "Dense to sparse via occupancy gating"
  patterns_applicable:
    - symbol: D&C
      name: "Divide-and-Conquer"
      success_rate: 0.31
      rationale: "Tri-view parallel structure"
    - symbol: MLS
      name: "ML-Guided Search"
      success_rate: 0.06
      rationale: "Deep learning for HAR"
    - symbol: PRE
      name: "Precomputation"
      success_rate: 0.16
      rationale: "Pre-compute doppler features"
    - symbol: HSH
      name: "Hashing"
      success_rate: 0.12
      rationale: "Occupancy grid hashing"
  confidence: 0.76
  predicted_improvement: "91.75% HAR, privacy-preserving"

creation_pattern:
  source: RadarPointCloud
  transformer: RadarClassifier
  result: ActivityLabel

behaviors:
  - name: human_activity_recognition
    given: "mmWave radar point cloud"
    when: "Apply OG-PCL network"
    then: "Classify human activity"
    test_cases:
      - name: radhar_classification
        input:
          activities: 5
          point_cloud_size: 64
        expected:
          accuracy: 0.9175
          params_m: 0.83

  - name: egocentric_hand_pose
    given: "Head-mounted mmWave + IMU"
    when: "Apply mmEgoHand"
    then: "Estimate 3D hand pose"
    test_cases:
      - name: vr_gesture
        input:
          gestures: 8
          postures: 3
        expected:
          accuracy: 0.908
          real_time: true

  - name: scene_flow_estimation
    given: "Radar point cloud sequence"
    when: "Apply milliFlow"
    then: "Estimate motion flow"
    test_cases:
      - name: human_motion_flow
        input:
          frames: 2
          points: 128
        expected:
          epe: 0.05  # meters
          downstream_improvement: true

  - name: through_wall_sensing
    given: "mmWave through obstacles"
    when: "Process reflected signals"
    then: "Detect human presence"
    test_cases:
      - name: wall_penetration
        input:
          wall_material: "drywall"
          distance: 5  # meters
        expected:
          detection_rate: 0.95
          privacy_preserved: true

algorithms:
  og_pcl:
    name: "Occupancy-Gated Parallel-CNN Bi-LSTM"
    structure: "Tri-view parallel"
    ogconv: "Occupancy compensation for sparse clouds"
    params: "0.83M"
    
  mmego_hand:
    sensors: ["mmWave", "IMU"]
    fusion: "Multi-modal transformer"
    compensation: "Head motion via IMU"
    
  milliflow:
    task: "Scene flow estimation"
    output: "Per-point 3D motion"
    downstream: ["HAR", "parsing", "tracking"]

radar_specs:
  frequency: "60-77 GHz"
  range: "0.5-10 m"
  resolution:
    range: "4 cm"
    velocity: "0.1 m/s"
    angle: "15 degrees"
  power: "< 1 W"

advantages:
  - "Privacy-preserving (no visual data)"
  - "Works in darkness"
  - "Through-wall capability"
  - "All-weather operation"
  - "Low power consumption"

metrics:
  har_accuracy: 0.9175
  gesture_accuracy: 0.908
  flow_epe: 0.05
  params_m: 0.83
