# NeuralCompression - Learned Video and Image Compression
# Source: arXiv:2512.16615 - Log-linear Sparse Attention
# PAS Analysis: ALG (transform coding), PRE (codebook), D&C (hierarchical)

name: neural_compression
version: "1.0.0"
language: 999
module: ⲚⲈⲨⲢⲀⲖ_ⲔⲞⲘⲠⲢⲈⲤⲤⲒⲞⲚ

pas_analysis:
  source_paper: "arXiv:2512.16615"
  current_complexity: "O(n²) attention in codec"
  theoretical_lower_bound: "O(n log n) hierarchical"
  gap: "Quadratic to log-linear"
  patterns_applicable:
    - symbol: ALG
      name: "Algebraic Reorganization"
      success_rate: 0.22
      rationale: "Transform coding"
    - symbol: PRE
      name: "Precomputation"
      success_rate: 0.16
      rationale: "Pre-trained codebook"
    - symbol: D&C
      name: "Divide-and-Conquer"
      success_rate: 0.31
      rationale: "Hierarchical compression"
    - symbol: HSH
      name: "Hashing"
      success_rate: 0.12
      rationale: "Entropy coding"
  confidence: 0.73
  predicted_improvement: "30% bitrate reduction vs H.265"

creation_pattern:
  source: RawMedia
  transformer: NeuralCodec
  result: CompressedBitstream

behaviors:
  - name: image_compression
    given: "Raw image"
    when: "Apply learned codec"
    then: "Compress to bitstream"
    test_cases:
      - name: kodak_compression
        input:
          resolution: [768, 512]
          target_bpp: 0.5
        expected:
          psnr: 32.5
          ms_ssim: 0.98

  - name: video_compression
    given: "Video sequence"
    when: "Apply neural video codec"
    then: "Compress with temporal redundancy"
    test_cases:
      - name: uvg_compression
        input:
          resolution: [1920, 1080]
          fps: 30
          gop: 12
        expected:
          bd_rate_vs_h265: -0.30
          encoding_fps: 5

  - name: log_linear_attention
    given: "Long token sequence"
    when: "Apply LLSA"
    then: "Compress with log-linear complexity"
    test_cases:
      - name: diffusion_compression
        input:
          tokens: 16384
          levels: 4
        expected:
          complexity: "O(n log n)"
          quality_preserved: true

  - name: entropy_coding
    given: "Quantized latents"
    when: "Apply learned entropy model"
    then: "Encode to bits"
    test_cases:
      - name: hyperprior
        input:
          latent_channels: 192
          hyperprior: true
        expected:
          bits_saved: 0.15
          decoding_speed: "real_time"

algorithms:
  learned_image_compression:
    encoder: "CNN/Transformer"
    quantization: "Learned soft quantization"
    entropy_model: "Hyperprior + autoregressive"
    decoder: "CNN/Transformer"
    
  llsa:
    name: "Log-linear Sparse Attention"
    structure: "Hierarchical"
    selection_cost: "O(n log n)"
    attention_cost: "O(n log n)"
    
  neural_video_codec:
    i_frame: "Learned image codec"
    p_frame: "Motion compensation + residual"
    b_frame: "Bidirectional prediction"

standards_comparison:
  jpeg: "DCT-based, 1992"
  h264: "Block-based, 2003"
  h265: "HEVC, 2013"
  vvc: "H.266, 2020"
  neural: "Learned, 2020+"

metrics:
  psnr: 32.5
  ms_ssim: 0.98
  bd_rate_h265: -0.30
  encoding_fps: 5
  decoding_fps: 30
