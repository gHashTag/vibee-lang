# VIBEE Browser Chat Panel v1.0.0
# AI chat sidebar with LLM integration

name: chat_panel
version: "1.0.0"
language: zig
module: chat_panel

description: |
  AI chat panel for vibecoding.
  Supports multiple LLM providers and streaming responses.

types:
  ChatMessage:
    fields:
      id: String
      role: String
      content: String
      timestamp: Timestamp

  ChatConversation:
    fields:
      id: String
      messages: List<ChatMessage>
      model: String
      created_at: Timestamp

  LLMProvider:
    fields:
      name: String
      api_key: Option<String>
      base_url: String
      models: List<String>

  StreamChunk:
    fields:
      content: String
      done: Bool
      usage: Option<Object>

  ChatContext:
    fields:
      page_content: Option<String>
      selected_code: Option<String>
      editor_file: Option<String>

  ChatCommand:
    fields:
      name: String
      description: String
      handler: String

behaviors:
  - name: send_message
    given: "User message and context"
    when: "Send"
    then: "Get AI response"

  - name: stream_response
    given: "Message"
    when: "Stream"
    then: "Yield response chunks"

  - name: set_provider
    given: "Provider config"
    when: "Configure"
    then: "Set active LLM provider"

  - name: get_page_context
    given: "Browser view"
    when: "Extract"
    then: "Return page content for context"

  - name: get_code_context
    given: "Editor"
    when: "Extract"
    then: "Return selected code"

  - name: execute_command
    given: "Command name"
    when: "Execute"
    then: "Run chat command"

  - name: clear_conversation
    given: "Conversation"
    when: "Clear"
    then: "Reset chat history"

  - name: export_conversation
    given: "Conversation"
    when: "Export"
    then: "Return markdown"

test_cases:
  - name: test_send_message
    input: { message: "Hello" }
    expected: { response_exists: true }

  - name: test_streaming
    input: { message: "Write code" }
    expected: { chunks_received: true }

  - name: test_context_extraction
    input: { page_url: "https://example.com" }
    expected: { context_extracted: true }
