# ML Optimizer - Оптимизаторы для обучения
# PAS: Адаптивные методы
# Author: Dmitrii Vasilev
# Version: 1.0.0

name: optimizer_ml
version: "1.0.0"
language: 999
module: ⲙⲗ.ⲟⲡⲧⲓⲙⲓⲍⲁⲧⲟⲣ

creation_pattern:
  source: Gradients
  transformer: Optimizer
  result: UpdatedParameters

pas_analysis:
  current: "SGD O(1) per param"
  target: "Adam with fused kernels"
  speedup: "2x throughput"
  confidence: 0.85
  patterns: ["PRE", "ALG"]

components:
  sgd:
    name: "ⲤⲄⲆ"
    description: "Stochastic Gradient Descent"
  adam:
    name: "ⲀⲆⲀⲘ"
    description: "Adam optimizer"
  adamw:
    name: "ⲀⲆⲀⲘⲰ"
    description: "AdamW with weight decay"
  scheduler:
    name: "ⲰⲈⲆⲨⲖⲈⲢ"
    description: "Learning rate scheduler"

behaviors:
  - name: step
    given: "Градиенты + параметры"
    when: "Шаг оптимизации"
    then: "Обновлённые параметры"
  - name: zero_grad
    given: "Параметры"
    when: "Обнуление"
    then: "Градиенты = 0"
  - name: schedule_lr
    given: "Эпоха/шаг"
    when: "Обновление LR"
    then: "Новый learning rate"
