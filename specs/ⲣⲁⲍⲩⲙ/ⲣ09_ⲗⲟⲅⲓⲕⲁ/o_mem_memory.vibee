# VIBEE Specification: O-Mem - Omni Memory System
# Based on arXiv:2511.13593
# Author: Dmitrii Vasilev

name: o_mem_memory
version: "1.0.0"
language: "999"
module: ⲟ_ⲙⲉⲙ_ⲡⲁⲙⲁⲧ

creation_pattern:
  source: UserInteractions
  transformer: ActiveProfiler
  result: PersonalizedMemory

description: |
  O-Mem achieves 51.67% on LoCoMo benchmark through:
  1. Active user profiling (not passive semantic grouping)
  2. Dynamic persona attribute extraction
  3. Hierarchical retrieval (persona + topic context)
  4. Token-efficient response generation

pas_analysis:
  current_algorithm: "Semantic grouping retrieval"
  current_complexity: "O(n log n) retrieval, misses critical info"
  predicted_improvement: "Active profiling + hierarchical retrieval"
  patterns_applied: [PRE, HSH]
  confidence: 0.85
  benchmark_improvement: "3% over LangMem, 3.5% over A-Mem"
  scientific_reference: "arXiv:2511.13593"

behaviors:
  - name: extract_persona_attributes
    given: User message history
    when: New interaction received
    then: Persona attributes dynamically updated
    test_cases:
      - name: extract_preferences
        input: { messages: ["I love dark themes", "Show me Python code"] }
        expected: { 
          persona: { 
            theme_preference: "dark",
            language_preference: "python",
            expertise_level: "developer"
          }
        }
      - name: extract_communication_style
        input: { messages: ["Please explain briefly", "TL;DR?"] }
        expected: { persona: { verbosity: "concise", style: "informal" } }

  - name: hierarchical_retrieval
    given: Query and memory store
    when: Context needed for response
    then: Persona attributes + topic context retrieved
    test_cases:
      - name: retrieve_with_persona
        input: { query: "How do I fix this bug?", persona: { expertise: "senior" } }
        expected: { 
          context_type: "technical",
          detail_level: "advanced",
          retrieved_topics: ["debugging", "error_handling"]
        }

  - name: update_event_records
    given: Significant interaction event
    when: Event detected
    then: Episodic memory updated
    test_cases:
      - name: record_milestone
        input: { event: "user_completed_project", timestamp: "2026-01-15" }
        expected: { 
          episodic_entry: true,
          retrievable: true,
          decay_rate: "slow"
        }

  - name: compress_to_long_term
    given: Short-term memory overflow
    when: Memory limit reached
    then: Important info compressed to long-term
    test_cases:
      - name: compress_conversation
        input: { short_term_size: 15, max_size: 10 }
        expected: { 
          compressed_count: 5,
          importance_preserved: true,
          retrieval_intact: true
        }

  - name: personalized_response
    given: User query with persona context
    when: Generating response
    then: Response tailored to user profile
    test_cases:
      - name: adapt_to_expertise
        input: { query: "What is recursion?", persona: { expertise: "beginner" } }
        expected: { 
          explanation_level: "simple",
          includes_analogy: true,
          code_complexity: "basic"
        }

memory_structure:
  short_term:
    max_turns: 10
    decay: "fast"
    retrieval: "immediate"
    
  long_term:
    storage: "compressed"
    decay: "slow"
    retrieval: "semantic_search"
    
  episodic:
    events: ["milestones", "preferences", "corrections"]
    decay: "very_slow"
    retrieval: "temporal_context"
    
  persona:
    attributes:
      - expertise_level
      - communication_style
      - topic_interests
      - language_preferences
      - time_patterns
    update_frequency: "per_interaction"

exports:
  - extract_persona_attributes
  - hierarchical_retrieval
  - update_event_records
  - compress_to_long_term
  - personalized_response
