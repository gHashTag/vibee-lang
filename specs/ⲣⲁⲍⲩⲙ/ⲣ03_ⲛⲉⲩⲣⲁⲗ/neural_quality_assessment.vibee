# Neural Quality Assessment - No-Reference Perceptual Metrics
# PAS Analysis for blind image/video quality evaluation
# arXiv: 2511.04628, 2509.10114, 2508.08700, 2508.07818

name: neural_quality_assessment
version: "1.0.0"
language: 999
module: ⲛⲉⲩⲣⲁⲗ_ⲕⲩⲁⲗⲓⲧⲩ_ⲁⲥⲥⲉⲥⲥⲙⲉⲛⲧ

creation_pattern:
  source: ImageOrVideoFrame
  transformer: BlindQualityEstimator
  result: PerceptualQualityScore

pas_analysis:
  current_algorithm: "Full-reference metrics (PSNR, SSIM)"
  current_complexity: "O(pixels × reference)"
  theoretical_lower_bound: "Ω(pixels)"
  gap: "O(pixels × reference)"
  applicable_patterns:
    - pattern: MLS
      reason: "Deep learning quality prediction"
      success_rate: 0.06
    - pattern: PRE
      reason: "Precomputed natural image statistics"
      success_rate: 0.16
    - pattern: D&C
      reason: "Separate distortion type detection"
      success_rate: 0.31
    - pattern: FDT
      reason: "Temporal modeling for video"
      success_rate: 0.13
  confidence: 0.82
  predicted_improvement: "No-reference matches full-reference correlation"
  timeline: "2024-2026"

components:
  - name: novis_vq
    description: "Streaming CNN for no-reference video quality"
    paper: "arXiv:2511.04628"
    complexity: "O(frames)"
    features:
      - no_reference_opinion_unaware
      - temporal_aware_cnn
      - predicts_lpips_psnr_ssim
      - streaming_architecture
      - outperforms_brisque

  - name: fiqa_ensemble
    description: "Lightweight ensemble for face image quality"
    paper: "arXiv:2509.10114"
    complexity: "O(pixels)"
    features:
      - mobilenetv3_shufflenetv2
      - correlation_aware_loss
      - 0_98_srcc_plcc
      - face_specific_degradations
      - efficient_deployment

  - name: cband
    description: "Banding artifact quality evaluator"
    paper: "arXiv:2508.08700"
    complexity: "O(pixels)"
    features:
      - banding_detection
      - deep_embedding_statistics
      - orders_magnitude_faster
      - differentiable_loss
      - debanding_optimization

  - name: rsfiqa
    description: "Region-aware semantic attention for fine-grained IQA"
    paper: "arXiv:2508.07818"
    complexity: "O(regions × pixels)"
    features:
      - sam_region_segmentation
      - mllm_distortion_perception
      - region_aware_attention
      - multi_dimensional_quality
      - backbone_agnostic

behaviors:
  - name: assess_video_quality
    given: "Video stream without reference"
    when: "Quality assessment needed"
    then: "Perceptual quality score"
    test_cases:
      - name: streaming_video
        input:
          video_fps: 30
          reference: false
        expected:
          correlation_with_fr: ">0.9"
          latency: "real_time"

  - name: detect_banding_artifacts
    given: "Compressed video"
    when: "Banding quality evaluation"
    then: "Banding severity score"
    test_cases:
      - name: av1_compressed
        input:
          codec: "AV1"
          quality: "low"
        expected:
          banding_detection: "accurate"
          speed: "fast"

  - name: face_quality_assessment
    given: "Face image in the wild"
    when: "Face-specific quality evaluation"
    then: "Face quality score"
    test_cases:
      - name: wild_face
        input:
          lighting: "variable"
          pose: "non_frontal"
        expected:
          srcc: ">0.98"
          plcc: ">0.98"

  - name: region_aware_quality
    given: "Image with semantic regions"
    when: "Fine-grained quality assessment"
    then: "Per-region and global quality"
    test_cases:
      - name: segmented_image
        input:
          num_regions: 10
          distortion_types: "mixed"
        expected:
          region_quality: "accurate"
          global_quality: "aggregated"

test_generation:
  strategy: property_based
  properties:
    - "No-reference correlates with full-reference"
    - "Temporal consistency in video quality"
    - "Face-specific degradations detected"
    - "Banding artifacts quantified"
    - "Region-aware quality is fine-grained"
