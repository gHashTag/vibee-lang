# Transformer - Архитектура трансформера
# PAS: Оптимизированные блоки
# Author: Dmitrii Vasilev
# Version: 1.0.0

name: transformer
version: "1.0.0"
language: 999
module: ⲙⲗ.ⲧⲣⲁⲛⲥⲫⲟⲣⲙⲉⲣ

creation_pattern:
  source: InputSequence
  transformer: TransformerModel
  result: OutputSequence

pas_analysis:
  current: "Standard transformer O(n²)"
  target: "Linear attention O(n)"
  speedup: "n/log n for long sequences"
  confidence: 0.75
  patterns: ["ALG", "TEN", "MLS"]

components:
  embedding:
    name: "ⲈⲘⲂⲈⲆⲆⲒⲚⲄ"
    description: "Входные эмбеддинги"
  encoder:
    name: "ⲈⲚⲔⲞⲆⲈⲢ"
    description: "Encoder блоки"
  decoder:
    name: "ⲆⲈⲔⲞⲆⲈⲢ"
    description: "Decoder блоки"
  layer_norm:
    name: "ⲚⲞⲢⲘⲀ.ⲤⲖⲞⲀ"
    description: "Layer normalization"
  ffn:
    name: "ⲪⲪⲚ"
    description: "Feed-forward network"

behaviors:
  - name: encode
    given: "Входная последовательность"
    when: "Encoding"
    then: "Скрытые представления"
  - name: decode
    given: "Encoder output + target"
    when: "Decoding"
    then: "Выходная последовательность"
  - name: generate
    given: "Prompt"
    when: "Autoregressive generation"
    then: "Сгенерированный текст"
