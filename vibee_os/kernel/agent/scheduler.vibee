name: vibee_os_agent_scheduler
version: "0.1.0"
language: zig
module: kernel/agent/scheduler
description: Agent Scheduler - manages execution of multiple AI agents, LLM API rate limiting, and resource allocation

behaviors:
  - name: schedule_agent_task
    given: An agent has a task to execute
    when: scheduler_submit is called with agent and task
    then: Task is queued and scheduled according to priority
    test_cases:
      - name: submit_high_priority
        input: {agent_id: "swe", task: "generate code", priority: "high"}
        expected: {queued: true, position: 1}
      - name: submit_low_priority
        input: {agent_id: "test", task: "run tests", priority: "low"}
        expected: {queued: true, position: 3}

  - name: execute_next_task
    given: Tasks are queued and LLM resources available
    when: scheduler_tick is called
    then: Next task is executed respecting rate limits
    test_cases:
      - name: execute_with_quota
        input: {queue_size: 5, llm_quota_remaining: 1000}
        expected: {executed: true, tokens_used: 500}
      - name: execute_rate_limited
        input: {queue_size: 5, llm_quota_remaining: 0}
        expected: {executed: false, reason: "rate_limited", retry_after_ms: 60000}

  - name: manage_llm_quota
    given: Multiple agents competing for LLM resources
    when: Agent requests LLM tokens
    then: Quota is allocated fairly based on priority and history
    test_cases:
      - name: allocate_to_high_priority
        input: {agent_id: "swe", requested: 1000, priority: "high", total_available: 5000}
        expected: {allocated: 1000}
      - name: allocate_limited
        input: {agent_id: "test", requested: 1000, priority: "low", total_available: 500}
        expected: {allocated: 500}

  - name: preempt_long_running_task
    given: A task is running too long
    when: Task exceeds timeout or higher priority task arrives
    then: Task is preempted and state is saved
    test_cases:
      - name: timeout_preemption
        input: {task_id: "task1", running_time_ms: 30000, timeout_ms: 10000}
        expected: {preempted: true, reason: "timeout", state_saved: true}
      - name: priority_preemption
        input: {task_id: "task1", priority: "low", new_task_priority: "critical"}
        expected: {preempted: true, reason: "higher_priority", state_saved: true}

  - name: handle_agent_failure
    given: An agent task fails
    when: Failure is detected
    then: Task is retried or escalated based on policy
    test_cases:
      - name: retry_transient_failure
        input: {task_id: "task1", error: "network_timeout", retry_count: 0}
        expected: {action: "retry", delay_ms: 1000}
      - name: escalate_permanent_failure
        input: {task_id: "task1", error: "invalid_spec", retry_count: 3}
        expected: {action: "escalate", notify: "user"}

types:
  AgentTask:
    id: str
    agent_id: str
    task_type: TaskType
    payload: str
    priority: Priority
    state: TaskState
    created_at: int
    started_at: int?
    completed_at: int?
    timeout_ms: int
    retry_count: int
    max_retries: int
    tokens_budget: int
    tokens_used: int

  TaskType:
    variants:
      - ProcessSpec       # Parse and process .vibee specification
      - GenerateCode      # Generate code from AST
      - ExecuteTests      # Run test cases
      - UserIntent        # Process natural language intent
      - Coordination      # Multi-agent coordination
      - SelfImprovement   # Learning and reflection
      - Maintenance       # System maintenance tasks

  Priority:
    variants:
      - Critical    # System-critical, immediate execution
      - High        # User-facing, fast response needed
      - Normal      # Standard tasks
      - Low         # Background tasks
      - Idle        # Only when system is idle

  TaskState:
    variants:
      - Pending
      - Queued
      - Running
      - Paused
      - Completed
      - Failed
      - Cancelled
      - TimedOut

  SchedulerState:
    running_tasks: [AgentTask]
    pending_queue: [AgentTask]
    completed_tasks: [AgentTask]
    failed_tasks: [AgentTask]
    total_tokens_used: int
    tokens_quota: int
    quota_reset_at: int

  LLMQuota:
    total_tokens: int
    used_tokens: int
    reset_interval_ms: int
    last_reset: int
    per_agent_limits: {str: int}

  SchedulingPolicy:
    variants:
      - FIFO              # First in, first out
      - Priority          # Priority-based
      - RoundRobin        # Fair sharing
      - MLFQ              # Multi-level feedback queue
      - Adaptive          # AI-driven adaptive scheduling

  PreemptionPolicy:
    timeout_ms: int
    allow_priority_preemption: bool
    save_state_on_preempt: bool

  RetryPolicy:
    max_retries: int
    base_delay_ms: int
    max_delay_ms: int
    exponential_backoff: bool
    retryable_errors: [str]

  SchedulerConfig:
    policy: SchedulingPolicy
    preemption: PreemptionPolicy
    retry: RetryPolicy
    llm_quota: LLMQuota
    max_concurrent_tasks: int
    tick_interval_ms: int

  SchedulerMetrics:
    tasks_completed: int
    tasks_failed: int
    average_wait_time_ms: int
    average_execution_time_ms: int
    tokens_efficiency: float
    preemptions: int

functions:
  # Lifecycle
  - name: scheduler_init
    params: {config: SchedulerConfig}
    returns: SchedulerState
    description: Initialize the agent scheduler

  - name: scheduler_shutdown
    params: {}
    returns: bool
    description: Gracefully shutdown scheduler

  # Task management
  - name: scheduler_submit
    params: {agent_id: str, task_type: TaskType, payload: str, priority: Priority}
    returns: str
    description: Submit a task, returns task ID

  - name: scheduler_cancel
    params: {task_id: str}
    returns: bool
    description: Cancel a pending or running task

  - name: scheduler_pause
    params: {task_id: str}
    returns: bool
    description: Pause a running task

  - name: scheduler_resume
    params: {task_id: str}
    returns: bool
    description: Resume a paused task

  # Execution
  - name: scheduler_tick
    params: {}
    returns: [AgentTask]
    description: Execute one scheduling cycle, returns completed tasks

  - name: scheduler_run
    params: {}
    returns: void
    description: Run scheduler main loop

  # Quota management
  - name: quota_request
    params: {agent_id: str, tokens: int}
    returns: int
    description: Request LLM tokens, returns allocated amount

  - name: quota_release
    params: {agent_id: str, tokens: int}
    returns: void
    description: Release unused tokens back to pool

  - name: quota_reset
    params: {}
    returns: void
    description: Reset quota (called periodically)

  # Monitoring
  - name: scheduler_status
    params: {}
    returns: SchedulerState
    description: Get current scheduler state

  - name: scheduler_metrics
    params: {}
    returns: SchedulerMetrics
    description: Get scheduler metrics

  - name: task_status
    params: {task_id: str}
    returns: AgentTask?
    description: Get status of a specific task

imports:
  - kernel.agent.core
  - kernel.ipc

scheduling_algorithm: |
  VIBEE OS Agent Scheduler Algorithm:
  
  1. ADAPTIVE MULTI-LEVEL FEEDBACK QUEUE (AMLFQ)
  
  Queues:
  - Q0 (Critical): Immediate execution, no preemption
  - Q1 (High): 100ms time slice, preemptable by Q0
  - Q2 (Normal): 500ms time slice, preemptable by Q0-Q1
  - Q3 (Low): 1000ms time slice, preemptable by Q0-Q2
  - Q4 (Idle): Infinite time slice, preemptable by all
  
  2. LLM QUOTA MANAGEMENT
  
  - Global quota: X tokens per minute
  - Per-agent quota: Proportional to priority
  - Burst allowance: 2x quota for short bursts
  - Rate limiting: Exponential backoff on quota exhaustion
  
  3. PREEMPTION RULES
  
  - Critical tasks preempt everything
  - Higher priority preempts lower (with state save)
  - Timeout preemption after configured limit
  - Cooperative yield for long-running tasks
  
  4. FAILURE HANDLING
  
  - Transient errors: Retry with exponential backoff
  - Permanent errors: Escalate to user
  - Cascade failures: Circuit breaker pattern
  
  5. ADAPTIVE OPTIMIZATION
  
  - Learn from task execution patterns
  - Adjust time slices based on historical data
  - Predict task duration for better scheduling
  - Balance throughput vs latency based on load
