# ============================================================================
# STREAMS - Потоковая обработка данных на Vibee
# ============================================================================
# Readable, Writable, Transform, Pipelines
# ============================================================================

Specification Streams:
  """Потоки как спецификация обработки данных."""

  # ==========================================================================
  # CORE TYPES
  # ==========================================================================

  Trait Stream<T>:
    Method next() -> Promise<Option<T>>
    Method close() -> Promise<Void>

  Trait ReadableStream<T>:
    Method read() -> Promise<Option<T>>
    Method is_readable() -> Boolean
    Method pipe<U>(transform: Transform<T, U>) -> ReadableStream<U>
    Method pipe_to(writable: WritableStream<T>) -> Promise<Void>

  Trait WritableStream<T>:
    Method write(chunk: T) -> Promise<Void>
    Method is_writable() -> Boolean
    Method close() -> Promise<Void>
    Method abort(reason: Error?) -> Promise<Void>

  Trait Transform<In, Out>:
    Method transform(chunk: In) -> Promise<List<Out>>
    Method flush() -> Promise<List<Out>>

  Trait DuplexStream<R, W>:
    readable: ReadableStream<R>
    writable: WritableStream<W>

  Type StreamState:
    variants:
      - Idle
      - Reading
      - Writing
      - Closed
      - Errored: Error

  # ==========================================================================
  # READABLE STREAM
  # ==========================================================================

  Behavior ReadableStreamImpl:
    When stream.readable<T>(source: StreamSource<T>) -> ReadableStream<T>:
      Then:
        - return ReadableStreamImpl(source)

    Type ReadableStreamImpl<T>:
      source: StreamSource<T>
      state: StreamState = Idle
      buffer: Queue<T>
      high_water_mark: Int
      readers: List<ReadRequest<T>>

      Method read() -> Promise<Option<T>>:
        if state == Closed:
          return None
        
        if state == Errored(e):
          throw e
        
        if buffer.length > 0:
          return Some(buffer.dequeue())
        
        # Request more data
        return await read_from_source()

      Method read_from_source() -> Promise<Option<T>>:
        state = Reading
        
        try:
          chunk = await source.pull()
          
          if chunk == null:
            state = Closed
            await source.close()
            return None
          
          state = Idle
          return Some(chunk)
        catch e:
          state = Errored(e)
          throw e

      Method cancel(reason: Error?) -> Promise<Void>:
        state = Closed
        await source.cancel(reason)

      Method pipe<U>(transform: Transform<T, U>) -> ReadableStream<U>:
        return TransformStream(self, transform)

      Method pipe_to(writable: WritableStream<T>) -> Promise<Void>:
        while true:
          chunk = await read()
          match chunk:
            Some(data) -> await writable.write(data)
            None -> break
        
        await writable.close()

      Method tee() -> (ReadableStream<T>, ReadableStream<T>):
        branch1 = Queue<T>()
        branch2 = Queue<T>()
        
        spawn async () -> {
          while true:
            chunk = await read()
            match chunk:
              Some(data) ->
                branch1.enqueue(data)
                branch2.enqueue(data)
              None -> break
        }
        
        return (
          stream.from_queue(branch1),
          stream.from_queue(branch2)
        )

    Type StreamSource<T>:
      start: (() -> Promise<Void>)?
      pull: () -> Promise<T?>
      cancel: ((Error?) -> Promise<Void>)?
      close: (() -> Promise<Void>)?

  # ==========================================================================
  # WRITABLE STREAM
  # ==========================================================================

  Behavior WritableStreamImpl:
    When stream.writable<T>(sink: StreamSink<T>) -> WritableStream<T>:
      Then:
        - return WritableStreamImpl(sink)

    Type WritableStreamImpl<T>:
      sink: StreamSink<T>
      state: StreamState = Idle
      buffer: Queue<T>
      high_water_mark: Int
      pending_writes: List<WriteRequest<T>>

      Method write(chunk: T) -> Promise<Void>:
        if state == Closed:
          throw Error("Stream is closed")
        
        if state == Errored(e):
          throw e
        
        state = Writing
        
        try:
          await sink.write(chunk)
          state = Idle
        catch e:
          state = Errored(e)
          throw e

      Method close() -> Promise<Void>:
        if state == Closed:
          return
        
        # Wait for pending writes
        while pending_writes.length > 0:
          await sleep(1.ms)
        
        await sink.close()
        state = Closed

      Method abort(reason: Error?) -> Promise<Void>:
        state = Errored(reason ?? Error("Aborted"))
        await sink.abort(reason)

      Method get_writer() -> WritableStreamWriter<T>:
        return WritableStreamWriter(self)

    Type StreamSink<T>:
      start: (() -> Promise<Void>)?
      write: (T) -> Promise<Void>
      close: (() -> Promise<Void>)?
      abort: ((Error?) -> Promise<Void>)?

    Type WritableStreamWriter<T>:
      stream: WritableStream<T>
      ready: Promise<Void>
      closed: Promise<Void>

      Method write(chunk: T) -> Promise<Void>:
        await ready
        await stream.write(chunk)

      Method close() -> Promise<Void>:
        await stream.close()

      Method abort(reason: Error?) -> Promise<Void>:
        await stream.abort(reason)

      Method release_lock():
        # Release writer lock

  # ==========================================================================
  # TRANSFORM STREAM
  # ==========================================================================

  Behavior TransformStreamImpl:
    When stream.transform<In, Out>(transformer: Transformer<In, Out>) -> TransformStream<In, Out>:
      Then:
        - return TransformStreamImpl(transformer)

    Type TransformStreamImpl<In, Out>:
      transformer: Transformer<In, Out>
      readable: ReadableStream<Out>
      writable: WritableStream<In>

      Method transform(chunk: In) -> Promise<List<Out>>:
        return await transformer.transform(chunk)

      Method flush() -> Promise<List<Out>>:
        return await transformer.flush()

    Type Transformer<In, Out>:
      start: ((TransformController<Out>) -> Promise<Void>)?
      transform: (In, TransformController<Out>) -> Promise<Void>
      flush: ((TransformController<Out>) -> Promise<Void>)?

    Type TransformController<T>:
      Method enqueue(chunk: T)
      Method error(e: Error)
      Method terminate()

  # ==========================================================================
  # STREAM OPERATORS
  # ==========================================================================

  Behavior StreamOperators:
    # Map
    When stream.map<T, U>(fn: (T) -> U) -> Transform<T, U>:
      Then:
        - return MapTransform(fn)

    Type MapTransform<T, U>:
      fn: (T) -> U

      Method transform(chunk: T) -> Promise<List<U>>:
        return [fn(chunk)]

      Method flush() -> Promise<List<U>>:
        return []

    # Filter
    When stream.filter<T>(predicate: (T) -> Boolean) -> Transform<T, T>:
      Then:
        - return FilterTransform(predicate)

    Type FilterTransform<T>:
      predicate: (T) -> Boolean

      Method transform(chunk: T) -> Promise<List<T>>:
        if predicate(chunk):
          return [chunk]
        return []

    # FlatMap
    When stream.flat_map<T, U>(fn: (T) -> List<U>) -> Transform<T, U>:
      Then:
        - return FlatMapTransform(fn)

    # Take
    When stream.take<T>(count: Int) -> Transform<T, T>:
      Then:
        - return TakeTransform(count)

    Type TakeTransform<T>:
      count: Int
      taken: Int = 0

      Method transform(chunk: T) -> Promise<List<T>>:
        if taken >= count:
          return []
        taken += 1
        return [chunk]

    # Skip
    When stream.skip<T>(count: Int) -> Transform<T, T>:
      Then:
        - return SkipTransform(count)

    # Batch
    When stream.batch<T>(size: Int) -> Transform<T, List<T>>:
      Then:
        - return BatchTransform(size)

    Type BatchTransform<T>:
      size: Int
      buffer: List<T> = []

      Method transform(chunk: T) -> Promise<List<List<T>>>:
        buffer.push(chunk)
        if buffer.length >= size:
          batch = buffer
          buffer = []
          return [batch]
        return []

      Method flush() -> Promise<List<List<T>>>:
        if buffer.length > 0:
          return [buffer]
        return []

    # Window
    When stream.window<T>(size: Int, slide: Int = 1) -> Transform<T, List<T>>:
      Then:
        - return WindowTransform(size, slide)

    # Debounce
    When stream.debounce<T>(duration: Duration) -> Transform<T, T>:
      Then:
        - return DebounceTransform(duration)

    Type DebounceTransform<T>:
      duration: Duration
      last_value: T?
      timer: Timer?

      Method transform(chunk: T) -> Promise<List<T>>:
        last_value = chunk
        timer?.cancel()
        
        return await Promise((resolve) -> {
          timer = set_timeout(duration, () -> {
            if last_value != null:
              resolve([last_value])
              last_value = null
            else:
              resolve([])
          })
        })

    # Throttle
    When stream.throttle<T>(duration: Duration) -> Transform<T, T>:
      Then:
        - return ThrottleTransform(duration)

    # Buffer with time
    When stream.buffer_time<T>(duration: Duration) -> Transform<T, List<T>>:
      Then:
        - return BufferTimeTransform(duration)

    # Distinct
    When stream.distinct<T>(key_fn: ((T) -> Any)? = null) -> Transform<T, T>:
      Then:
        - return DistinctTransform(key_fn)

    Type DistinctTransform<T>:
      key_fn: ((T) -> Any)?
      seen: Set<Any> = Set()

      Method transform(chunk: T) -> Promise<List<T>>:
        key = if key_fn then key_fn(chunk) else chunk
        if key in seen:
          return []
        seen.add(key)
        return [chunk]

    # Scan (reduce with intermediate values)
    When stream.scan<T, U>(initial: U, fn: (U, T) -> U) -> Transform<T, U>:
      Then:
        - return ScanTransform(initial, fn)

    Type ScanTransform<T, U>:
      accumulator: U
      fn: (U, T) -> U

      Method transform(chunk: T) -> Promise<List<U>>:
        accumulator = fn(accumulator, chunk)
        return [accumulator]

    # Merge streams
    When stream.merge<T>(...streams: ReadableStream<T>) -> ReadableStream<T>:
      Then:
        - return MergedStream(streams)

    # Concat streams
    When stream.concat<T>(...streams: ReadableStream<T>) -> ReadableStream<T>:
      Then:
        - return ConcatStream(streams)

    # Zip streams
    When stream.zip<T, U>(stream1: ReadableStream<T>, stream2: ReadableStream<U>) -> ReadableStream<(T, U)>:
      Then:
        - return ZipStream(stream1, stream2)

  # ==========================================================================
  # ASYNC ITERATION
  # ==========================================================================

  Behavior AsyncIteration:
    When stream.from_iterable<T>(iterable: Iterable<T>) -> ReadableStream<T>:
      Then:
        - iterator = iterable.iterator()
        - return stream.readable({
            pull: () -> {
              result = iterator.next()
              if result.done:
                return null
              return result.value
            }
          })

    When stream.from_async_iterable<T>(iterable: AsyncIterable<T>) -> ReadableStream<T>:
      Then:
        - iterator = iterable.async_iterator()
        - return stream.readable({
            pull: async () -> {
              result = await iterator.next()
              if result.done:
                return null
              return result.value
            }
          })

    When stream.from_array<T>(array: List<T>) -> ReadableStream<T>:
      Then:
        - return stream.from_iterable(array)

    When stream.from_queue<T>(queue: Queue<T>) -> ReadableStream<T>:
      Then:
        - return stream.readable({
            pull: async () -> {
              return await queue.dequeue()
            }
          })

    When stream.to_array<T>(readable: ReadableStream<T>) -> Promise<List<T>>:
      Then:
        - result = []
        - while true:
            - chunk = await readable.read()
            - match chunk:
                Some(data) -> result.push(data)
                None -> break
        - return result

    # For-await support
    When for await item in stream:
      Then:
        - while true:
            - chunk = await stream.read()
            - match chunk:
                Some(data) -> yield data
                None -> break

  # ==========================================================================
  # BYTE STREAMS
  # ==========================================================================

  Behavior ByteStreams:
    Type ByteReadableStream = ReadableStream<Bytes>
    Type ByteWritableStream = WritableStream<Bytes>

    When stream.read_file(path: Path) -> ByteReadableStream:
      Then:
        - file = await fs.open(path, "r")
        - return stream.readable({
            pull: async () -> {
              chunk = await file.read(64 * 1024)  # 64KB chunks
              if chunk.length == 0:
                return null
              return chunk
            },
            close: async () -> {
              await file.close()
            }
          })

    When stream.write_file(path: Path) -> ByteWritableStream:
      Then:
        - file = await fs.open(path, "w")
        - return stream.writable({
            write: async (chunk) -> {
              await file.write(chunk)
            },
            close: async () -> {
              await file.close()
            }
          })

    # Text encoding/decoding
    When stream.text_decoder(encoding: String = "utf-8") -> Transform<Bytes, String>:
      Then:
        - decoder = TextDecoder(encoding)
        - return {
            transform: (chunk) -> [decoder.decode(chunk, stream: true)],
            flush: () -> [decoder.decode()]
          }

    When stream.text_encoder(encoding: String = "utf-8") -> Transform<String, Bytes>:
      Then:
        - encoder = TextEncoder(encoding)
        - return {
            transform: (chunk) -> [encoder.encode(chunk)]
          }

    # Line splitting
    When stream.split_lines() -> Transform<String, String>:
      Then:
        - buffer = ""
        - return {
            transform: (chunk) -> {
              buffer += chunk
              lines = buffer.split("\n")
              buffer = lines.pop()  # Keep incomplete line
              return lines
            },
            flush: () -> {
              if buffer.length > 0:
                return [buffer]
              return []
            }
          }

    # JSON lines
    When stream.json_lines<T>() -> Transform<String, T>:
      Then:
        - return stream.split_lines()
            .pipe(stream.filter(line -> line.trim().length > 0))
            .pipe(stream.map(line -> json.parse<T>(line)))

    # Compression
    When stream.gzip() -> Transform<Bytes, Bytes>:
      Then:
        - return GzipTransform()

    When stream.gunzip() -> Transform<Bytes, Bytes>:
      Then:
        - return GunzipTransform()

  # ==========================================================================
  # PIPELINE
  # ==========================================================================

  Behavior Pipeline:
    When stream.pipeline(...stages: Any) -> Promise<Void>:
      Then:
        - if stages.length < 2:
            - throw Error("Pipeline requires at least 2 stages")
        
        - source = stages[0]
        - transforms = stages.slice(1, -1)
        - sink = stages.last()
        
        - current = source
        - for transform in transforms:
            - current = current.pipe(transform)
        
        - await current.pipe_to(sink)

    When stream.compose<T, U>(...transforms: Transform) -> Transform<T, U>:
      Then:
        - return ComposedTransform(transforms)

  # ==========================================================================
  # EXAMPLE
  # ==========================================================================

  Example "Streams":
    ```vibee
    # Read file as stream
    file_stream = stream.read_file("large_file.txt")

    # Process with pipeline
    await stream.pipeline(
      file_stream,
      stream.text_decoder(),
      stream.split_lines(),
      stream.filter(line -> line.length > 0),
      stream.map(line -> line.to_uppercase()),
      stream.batch(100),
      stream.writable({
        write: async (batch) -> {
          await db.insert_many(batch)
        }
      })
    )

    # Transform stream
    numbers = stream.from_array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

    result = await numbers
      .pipe(stream.filter(n -> n % 2 == 0))
      .pipe(stream.map(n -> n * 2))
      .pipe(stream.take(3))
      |> stream.to_array()

    # result = [4, 8, 12]

    # Async iteration
    for await line in stream.read_file("data.txt")
        .pipe(stream.text_decoder())
        .pipe(stream.split_lines()):
      process_line(line)

    # JSON lines processing
    for await record in stream.read_file("data.jsonl")
        .pipe(stream.text_decoder())
        .pipe(stream.json_lines<Record>()):
      await process_record(record)

    # Merge multiple streams
    stream1 = stream.from_array([1, 3, 5])
    stream2 = stream.from_array([2, 4, 6])
    merged = stream.merge(stream1, stream2)

    # Batch processing with time window
    events = get_event_stream()
    
    batched = events
      .pipe(stream.buffer_time(1.second))
      .pipe(stream.filter(batch -> batch.length > 0))

    for await batch in batched:
      await process_event_batch(batch)

    # Debounce user input
    input_stream = get_user_input_stream()
    
    debounced = input_stream
      .pipe(stream.debounce(300.ms))
      .pipe(stream.distinct())

    for await query in debounced:
      results = await search(query)
      display_results(results)

    # Compression pipeline
    await stream.pipeline(
      stream.read_file("data.json"),
      stream.gzip(),
      stream.write_file("data.json.gz")
    )

    # Decompression
    await stream.pipeline(
      stream.read_file("data.json.gz"),
      stream.gunzip(),
      stream.text_decoder(),
      stream.write_file("data_restored.json")
    )

    # Custom transform
    uppercase_transform = stream.transform({
      transform: async (chunk, controller) -> {
        controller.enqueue(chunk.to_uppercase())
      }
    })

    # Tee stream (split into two)
    (branch1, branch2) = source_stream.tee()
    
    # Process both branches independently
    spawn process_branch1(branch1)
    spawn process_branch2(branch2)

    # Scan (running total)
    totals = stream.from_array([1, 2, 3, 4, 5])
      .pipe(stream.scan(0, (acc, n) -> acc + n))
    
    # totals: 1, 3, 6, 10, 15
    ```
