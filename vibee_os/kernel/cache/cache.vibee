# ============================================================================
# CACHE - Кеширование данных на Vibee
# ============================================================================
# In-memory cache, LRU, TTL, Distributed cache
# ============================================================================

Specification Cache:
  """Кеширование как спецификация временного хранения данных."""

  # ==========================================================================
  # CACHE TRAIT
  # ==========================================================================

  Trait Cache<K, V>:
    Method get(key: K) -> Option<V>
    Method set(key: K, value: V)
    Method set_with_ttl(key: K, value: V, ttl: Duration)
    Method delete(key: K) -> Boolean
    Method exists(key: K) -> Boolean
    Method clear()
    Method size() -> Int

  # ==========================================================================
  # IN-MEMORY CACHE
  # ==========================================================================

  Type MemoryCache<K, V>:
    entries: Map<K, CacheEntry<V>>
    max_size: Option<Int>
    default_ttl: Option<Duration>
    stats: CacheStats

    Static Method new() -> MemoryCache<K, V>:
      return MemoryCache({}, null, null, CacheStats.new())

    Static Method with_max_size(max_size: Int) -> MemoryCache<K, V>:
      return MemoryCache({}, Some(max_size), null, CacheStats.new())

    Static Method with_ttl(ttl: Duration) -> MemoryCache<K, V>:
      return MemoryCache({}, null, Some(ttl), CacheStats.new())

    Static Method with_options(options: CacheOptions) -> MemoryCache<K, V>:
      return MemoryCache({}, options.max_size, options.default_ttl, CacheStats.new())

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        entry = self.entries.get(key)?
        
        if entry.is_expired():
          self.entries.remove(key)
          self.stats.misses.inc()
          return null
        
        entry.last_accessed = Instant.now()
        entry.access_count += 1
        self.stats.hits.inc()
        return Some(entry.value)

      Method set(key: K, value: V):
        ttl = self.default_ttl
        self.set_with_ttl(key, value, ttl.unwrap_or(Duration.MAX))

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        self.maybe_evict()
        
        entry = CacheEntry(
          value: value,
          created_at: Instant.now(),
          last_accessed: Instant.now(),
          expires_at: if ttl == Duration.MAX then null else Some(Instant.now() + ttl),
          access_count: 0
        )
        
        self.entries[key] = entry

      Method delete(key: K) -> Boolean:
        return self.entries.remove(key) != null

      Method exists(key: K) -> Boolean:
        entry = self.entries.get(key)
        if entry is Some(e):
          if e.is_expired():
            self.entries.remove(key)
            return false
          return true
        return false

      Method clear():
        self.entries.clear()

      Method size() -> Int:
        return self.entries.length

    Method maybe_evict():
      if self.max_size is Some(max):
        while self.entries.length >= max:
          self.evict_one()

    Method evict_one():
      # Remove expired first
      for (key, entry) in self.entries:
        if entry.is_expired():
          self.entries.remove(key)
          self.stats.evictions.inc()
          return
      
      # Remove least recently accessed
      oldest_key = null
      oldest_time = Instant.MAX
      
      for (key, entry) in self.entries:
        if entry.last_accessed < oldest_time:
          oldest_time = entry.last_accessed
          oldest_key = key
      
      if oldest_key != null:
        self.entries.remove(oldest_key)
        self.stats.evictions.inc()

    Method get_or_set(key: K, f: () -> V) -> V:
      if self.get(key) is Some(v):
        return v
      
      value = f()
      self.set(key, value)
      return value

    Method get_or_set_async(key: K, f: () -> Promise<V>) -> Promise<V>:
      if self.get(key) is Some(v):
        return Promise.resolve(v)
      
      return f().then(value -> {
        self.set(key, value)
        value
      })

    Method stats() -> CacheStats:
      return self.stats

  Type CacheEntry<V>:
    value: V
    created_at: Instant
    last_accessed: Instant
    expires_at: Option<Instant>
    access_count: Int

    Method is_expired() -> Boolean:
      if self.expires_at is Some(exp):
        return Instant.now() >= exp
      return false

    Method ttl_remaining() -> Option<Duration>:
      if self.expires_at is Some(exp):
        remaining = exp - Instant.now()
        return if remaining.is_negative() then Some(Duration.zero()) else Some(remaining)
      return null

  Type CacheOptions:
    max_size: Option<Int>
    default_ttl: Option<Duration>
    eviction_policy: EvictionPolicy

    Static Method default() -> CacheOptions:
      return CacheOptions(null, null, EvictionPolicy.LRU)

  Type EvictionPolicy:
    variants:
      - LRU   # Least Recently Used
      - LFU   # Least Frequently Used
      - FIFO  # First In First Out
      - Random

  Type CacheStats:
    hits: Atomic<Int>
    misses: Atomic<Int>
    evictions: Atomic<Int>

    Static Method new() -> CacheStats:
      return CacheStats(Atomic(0), Atomic(0), Atomic(0))

    Method hit_rate() -> Float:
      total = self.hits.load() + self.misses.load()
      if total == 0:
        return 0.0
      return self.hits.load().to_float() / total.to_float()

    Method reset():
      self.hits.store(0)
      self.misses.store(0)
      self.evictions.store(0)

  # ==========================================================================
  # LRU CACHE
  # ==========================================================================

  Type LRUCache<K, V>:
    capacity: Int
    map: Map<K, LRUNode<K, V>>
    head: Option<LRUNode<K, V>>
    tail: Option<LRUNode<K, V>>
    stats: CacheStats

    Static Method new(capacity: Int) -> LRUCache<K, V>:
      return LRUCache(capacity, {}, null, null, CacheStats.new())

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        node = self.map.get(key)?
        
        if node.is_expired():
          self.remove_node(node)
          self.map.remove(key)
          self.stats.misses.inc()
          return null
        
        # Move to front
        self.remove_node(node)
        self.add_to_front(node)
        
        self.stats.hits.inc()
        return Some(node.value)

      Method set(key: K, value: V):
        self.set_with_ttl(key, value, Duration.MAX)

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        expires_at = if ttl == Duration.MAX then null else Some(Instant.now() + ttl)
        
        if self.map.get(key) is Some(existing):
          existing.value = value
          existing.expires_at = expires_at
          self.remove_node(existing)
          self.add_to_front(existing)
        else:
          if self.map.length >= self.capacity:
            self.evict_lru()
          
          node = LRUNode(key, value, expires_at, null, null)
          self.map[key] = node
          self.add_to_front(node)

      Method delete(key: K) -> Boolean:
        node = self.map.get(key)?
        self.remove_node(node)
        self.map.remove(key)
        return true

      Method exists(key: K) -> Boolean:
        node = self.map.get(key)
        if node is Some(n):
          if n.is_expired():
            self.remove_node(n)
            self.map.remove(key)
            return false
          return true
        return false

      Method clear():
        self.map.clear()
        self.head = null
        self.tail = null

      Method size() -> Int:
        return self.map.length

    Method add_to_front(node: LRUNode<K, V>):
      node.next = self.head
      node.prev = null
      
      if self.head is Some(h):
        h.prev = Some(node)
      
      self.head = Some(node)
      
      if self.tail == null:
        self.tail = Some(node)

    Method remove_node(node: LRUNode<K, V>):
      if node.prev is Some(p):
        p.next = node.next
      else:
        self.head = node.next
      
      if node.next is Some(n):
        n.prev = node.prev
      else:
        self.tail = node.prev

    Method evict_lru():
      if self.tail is Some(t):
        self.map.remove(t.key)
        self.remove_node(t)
        self.stats.evictions.inc()

  Type LRUNode<K, V>:
    key: K
    value: V
    expires_at: Option<Instant>
    prev: Option<LRUNode<K, V>>
    next: Option<LRUNode<K, V>>

    Method is_expired() -> Boolean:
      if self.expires_at is Some(exp):
        return Instant.now() >= exp
      return false

  # ==========================================================================
  # TTL CACHE
  # ==========================================================================

  Type TTLCache<K, V>:
    entries: Map<K, TTLEntry<V>>
    default_ttl: Duration
    cleanup_interval: Duration
    cleanup_task: Option<Task>
    stats: CacheStats

    Static Method new(default_ttl: Duration) -> TTLCache<K, V>:
      cache = TTLCache(
        entries: {},
        default_ttl: default_ttl,
        cleanup_interval: Duration.minutes(1),
        cleanup_task: null,
        stats: CacheStats.new()
      )
      cache.start_cleanup()
      return cache

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        entry = self.entries.get(key)?
        
        if entry.is_expired():
          self.entries.remove(key)
          self.stats.misses.inc()
          return null
        
        self.stats.hits.inc()
        return Some(entry.value)

      Method set(key: K, value: V):
        self.set_with_ttl(key, value, self.default_ttl)

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        entry = TTLEntry(
          value: value,
          expires_at: Instant.now() + ttl
        )
        self.entries[key] = entry

      Method delete(key: K) -> Boolean:
        return self.entries.remove(key) != null

      Method exists(key: K) -> Boolean:
        entry = self.entries.get(key)
        if entry is Some(e):
          if e.is_expired():
            self.entries.remove(key)
            return false
          return true
        return false

      Method clear():
        self.entries.clear()

      Method size() -> Int:
        return self.entries.length

    Method start_cleanup():
      self.cleanup_task = Some(spawn {
        loop:
          sleep(self.cleanup_interval)
          self.cleanup_expired()
      })

    Method cleanup_expired():
      now = Instant.now()
      expired_keys = []
      
      for (key, entry) in self.entries:
        if entry.expires_at <= now:
          expired_keys.push(key)
      
      for key in expired_keys:
        self.entries.remove(key)
        self.stats.evictions.inc()

    Method stop():
      if self.cleanup_task is Some(task):
        task.cancel()

  Type TTLEntry<V>:
    value: V
    expires_at: Instant

    Method is_expired() -> Boolean:
      return Instant.now() >= self.expires_at

  # ==========================================================================
  # WRITE-THROUGH CACHE
  # ==========================================================================

  Type WriteThroughCache<K, V>:
    cache: Cache<K, V>
    store: CacheStore<K, V>

    Static Method new(cache: Cache<K, V>, store: CacheStore<K, V>) -> WriteThroughCache<K, V>:
      return WriteThroughCache(cache, store)

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        # Try cache first
        if self.cache.get(key) is Some(v):
          return Some(v)
        
        # Load from store
        value = self.store.load(key)?
        self.cache.set(key, value)
        return Some(value)

      Method set(key: K, value: V):
        # Write to both
        self.store.save(key, value)
        self.cache.set(key, value)

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        self.store.save(key, value)
        self.cache.set_with_ttl(key, value, ttl)

      Method delete(key: K) -> Boolean:
        self.store.delete(key)
        return self.cache.delete(key)

      Method exists(key: K) -> Boolean:
        return self.cache.exists(key) or self.store.exists(key)

      Method clear():
        self.cache.clear()

      Method size() -> Int:
        return self.cache.size()

  Trait CacheStore<K, V>:
    Method load(key: K) -> Option<V>
    Method save(key: K, value: V)
    Method delete(key: K)
    Method exists(key: K) -> Boolean

  # ==========================================================================
  # WRITE-BEHIND CACHE
  # ==========================================================================

  Type WriteBehindCache<K, V>:
    cache: Cache<K, V>
    store: CacheStore<K, V>
    write_queue: Channel<(K, V)>
    batch_size: Int
    flush_interval: Duration
    worker: Task

    Static Method new(cache: Cache<K, V>, store: CacheStore<K, V>) -> WriteBehindCache<K, V>:
      wbc = WriteBehindCache(
        cache: cache,
        store: store,
        write_queue: Channel.unbounded(),
        batch_size: 100,
        flush_interval: Duration.seconds(5),
        worker: null
      )
      wbc.start_worker()
      return wbc

    Method start_worker():
      self.worker = spawn {
        batch = []
        last_flush = Instant.now()
        
        loop:
          select:
            (key, value) = self.write_queue.recv():
              batch.push((key, value))
              
              if batch.length >= self.batch_size:
                self.flush_batch(batch)
                batch = []
                last_flush = Instant.now()
            
            timeout(self.flush_interval):
              if batch.length > 0:
                self.flush_batch(batch)
                batch = []
                last_flush = Instant.now()
      }

    Method flush_batch(batch: List<(K, V)>):
      for (key, value) in batch:
        self.store.save(key, value)

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        if self.cache.get(key) is Some(v):
          return Some(v)
        
        value = self.store.load(key)?
        self.cache.set(key, value)
        return Some(value)

      Method set(key: K, value: V):
        self.cache.set(key, value)
        self.write_queue.send((key, value))

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        self.cache.set_with_ttl(key, value, ttl)
        self.write_queue.send((key, value))

      Method delete(key: K) -> Boolean:
        self.store.delete(key)
        return self.cache.delete(key)

      Method exists(key: K) -> Boolean:
        return self.cache.exists(key)

      Method clear():
        self.cache.clear()

      Method size() -> Int:
        return self.cache.size()

  # ==========================================================================
  # MULTI-LEVEL CACHE
  # ==========================================================================

  Type MultiLevelCache<K, V>:
    levels: List<Cache<K, V>>

    Static Method new(levels: List<Cache<K, V>>) -> MultiLevelCache<K, V>:
      return MultiLevelCache(levels)

    Trait Cache<K, V>:
      Method get(key: K) -> Option<V>:
        for (i, cache) in self.levels.enumerate():
          if cache.get(key) is Some(v):
            # Populate higher levels
            for j in 0..i:
              self.levels[j].set(key, v)
            return Some(v)
        return null

      Method set(key: K, value: V):
        for cache in self.levels:
          cache.set(key, value)

      Method set_with_ttl(key: K, value: V, ttl: Duration):
        for cache in self.levels:
          cache.set_with_ttl(key, value, ttl)

      Method delete(key: K) -> Boolean:
        result = false
        for cache in self.levels:
          if cache.delete(key):
            result = true
        return result

      Method exists(key: K) -> Boolean:
        for cache in self.levels:
          if cache.exists(key):
            return true
        return false

      Method clear():
        for cache in self.levels:
          cache.clear()

      Method size() -> Int:
        return self.levels[0].size()

  # ==========================================================================
  # MEMOIZATION
  # ==========================================================================

  Behavior Memoization:
    When memoize<A, R>(f: (A) -> R) -> (A) -> R:
      Then:
        cache = MemoryCache<A, R>.new()
        
        return (arg: A) -> {
          cache.get_or_set(arg, () -> f(arg))
        }

    When memoize_async<A, R>(f: (A) -> Promise<R>) -> (A) -> Promise<R>:
      Then:
        cache = MemoryCache<A, R>.new()
        pending = Map<A, Promise<R>>()
        
        return (arg: A) -> {
          if cache.get(arg) is Some(v):
            return Promise.resolve(v)
          
          if pending.get(arg) is Some(p):
            return p
          
          promise = f(arg).then(result -> {
            cache.set(arg, result)
            pending.remove(arg)
            result
          })
          
          pending[arg] = promise
          return promise
        }

    When memoize_with_ttl<A, R>(f: (A) -> R, ttl: Duration) -> (A) -> R:
      Then:
        cache = TTLCache<A, R>.new(ttl)
        
        return (arg: A) -> {
          if cache.get(arg) is Some(v):
            return v
          
          result = f(arg)
          cache.set(arg, result)
          return result
        }

  # ==========================================================================
  # DECORATOR
  # ==========================================================================

  Behavior CacheDecorator:
    @cached
    fn expensive_computation(x: Int) -> Int:
      # Automatically memoized
      sleep(Duration.seconds(1))
      return x * x

    @cached(ttl: Duration.minutes(5))
    fn fetch_user(id: Int) -> User:
      return database.find_user(id)

    @cached(max_size: 1000)
    fn compute_hash(data: String) -> String:
      return sha256(data).to_hex()

  # ==========================================================================
  # EXAMPLE
  # ==========================================================================

  Example "Cache":
    ```vibee
    # Simple in-memory cache
    cache = MemoryCache<String, User>.new()
    
    cache.set("user:1", user)
    user = cache.get("user:1")?

    # With TTL
    cache.set_with_ttl("session:abc", session, Duration.hours(1))

    # With max size
    cache = MemoryCache<String, Data>.with_max_size(1000)

    # LRU cache
    lru = LRUCache<String, Response>.new(100)
    lru.set("key", response)

    # TTL cache with automatic cleanup
    ttl_cache = TTLCache<String, Token>.new(Duration.minutes(15))
    ttl_cache.set("token:xyz", token)

    # Get or compute
    value = cache.get_or_set("expensive_key", () -> {
      compute_expensive_value()
    })

    # Async get or compute
    value = await cache.get_or_set_async("api_data", async () -> {
      await fetch_from_api()
    })

    # Write-through cache (sync writes to store)
    store = DatabaseStore()
    wt_cache = WriteThroughCache.new(
      MemoryCache.new(),
      store
    )

    # Write-behind cache (async writes to store)
    wb_cache = WriteBehindCache.new(
      MemoryCache.new(),
      store
    )

    # Multi-level cache (L1 -> L2 -> Store)
    l1 = MemoryCache.with_max_size(100)
    l2 = MemoryCache.with_max_size(10000)
    
    multi = MultiLevelCache.new([l1, l2])

    # Memoization
    fib = memoize((n: Int) -> {
      if n <= 1:
        n
      else:
        fib(n - 1) + fib(n - 2)
    })

    result = fib(50)  # Fast due to memoization

    # Memoize with TTL
    get_weather = memoize_with_ttl(
      (city: String) -> fetch_weather(city),
      Duration.minutes(10)
    )

    # Cache stats
    stats = cache.stats()
    print("Hit rate: ${stats.hit_rate() * 100}%")
    print("Hits: ${stats.hits.load()}")
    print("Misses: ${stats.misses.load()}")
    print("Evictions: ${stats.evictions.load()}")

    # Decorator-based caching
    @cached(ttl: Duration.hours(1))
    fn get_user_profile(user_id: Int) -> Profile:
      return database.query_profile(user_id)
    ```
