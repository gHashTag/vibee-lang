# ============================================================================
# CONTAINER ORCHESTRATION - Оркестрация контейнеров на Vibee
# ============================================================================
# Scheduling, scaling, service mesh, deployments, rollouts
# ============================================================================

Specification ContainerOrchestration:
  """
  Оркестрация контейнеров как спецификация инфраструктуры.
  Каждый контейнер - актор, каждое развёртывание - поведение.
  """

  # ==========================================================================
  # ТИПЫ ДАННЫХ
  # ==========================================================================

  Type Container:
    id: ContainerId
    name: String
    image: Image
    state: ContainerState
    resources: ResourceRequirements
    ports: List<PortMapping>
    env: Map<String, String>
    volumes: List<VolumeMount>
    health_check: HealthCheck?
    restart_policy: RestartPolicy
    node: NodeId?
    created_at: Timestamp
    started_at: Timestamp?

  Type ContainerId:
    value: String

  Type Image:
    registry: String?
    repository: String
    tag: String = "latest"
    digest: String?

  Type ContainerState:
    variants:
      - Pending
      - Creating
      - Running
      - Paused
      - Stopping
      - Stopped
      - Failed: String
      - Unknown

  Type ResourceRequirements:
    requests: Resources
    limits: Resources

  Type Resources:
    cpu: CPUQuantity        # millicores (1000m = 1 core)
    memory: ByteSize
    gpu: Int?
    ephemeral_storage: ByteSize?

  Type CPUQuantity:
    millicores: Int

  Type PortMapping:
    container_port: Port
    host_port: Port?
    protocol: Protocol = TCP
    name: String?

  Type Protocol:
    variants: [TCP, UDP, SCTP]

  Type VolumeMount:
    name: String
    mount_path: Path
    sub_path: String?
    read_only: Boolean = false

  Type Volume:
    variants:
      - EmptyDir: EmptyDirConfig
      - HostPath: HostPathConfig
      - PersistentVolumeClaim: PVCConfig
      - ConfigMap: ConfigMapConfig
      - Secret: SecretConfig
      - NFS: NFSConfig

  Type EmptyDirConfig:
    medium: StorageMedium = Default
    size_limit: ByteSize?

  Type StorageMedium:
    variants: [Default, Memory]

  Type HostPathConfig:
    path: Path
    type: HostPathType = DirectoryOrCreate

  Type HostPathType:
    variants: [DirectoryOrCreate, Directory, FileOrCreate, File, Socket, CharDevice, BlockDevice]

  Type PVCConfig:
    claim_name: String
    read_only: Boolean = false

  Type HealthCheck:
    probe: Probe
    initial_delay: Duration = 0.seconds
    period: Duration = 10.seconds
    timeout: Duration = 1.second
    success_threshold: Int = 1
    failure_threshold: Int = 3

  Type Probe:
    variants:
      - HTTP: (path: String, port: Port, headers: Map<String, String>?)
      - TCP: Port
      - Exec: List<String>
      - GRPC: (port: Port, service: String?)

  Type RestartPolicy:
    variants:
      - Always
      - OnFailure
      - Never

  # ==========================================================================
  # WORKLOADS
  # ==========================================================================

  Type Pod:
    id: PodId
    name: String
    namespace: String
    labels: Map<String, String>
    annotations: Map<String, String>
    containers: List<Container>
    init_containers: List<Container>
    volumes: List<Volume>
    node_selector: Map<String, String>
    affinity: Affinity?
    tolerations: List<Toleration>
    service_account: String?
    state: PodState
    conditions: List<PodCondition>
    ip: IPAddress?
    node: NodeId?

  Type PodId:
    value: UUID

  Type PodState:
    phase: PodPhase
    reason: String?
    message: String?

  Type PodPhase:
    variants:
      - Pending
      - Running
      - Succeeded
      - Failed
      - Unknown

  Type PodCondition:
    type: ConditionType
    status: Boolean
    reason: String?
    message: String?
    last_transition: Timestamp

  Type ConditionType:
    variants:
      - PodScheduled
      - ContainersReady
      - Initialized
      - Ready

  Type Deployment:
    id: DeploymentId
    name: String
    namespace: String
    labels: Map<String, String>
    replicas: Int
    selector: LabelSelector
    template: PodTemplate
    strategy: DeploymentStrategy
    revision_history_limit: Int = 10
    progress_deadline: Duration = 10.minutes
    status: DeploymentStatus

  Type DeploymentId:
    value: UUID

  Type LabelSelector:
    match_labels: Map<String, String>
    match_expressions: List<LabelExpression>?

  Type LabelExpression:
    key: String
    operator: SelectorOperator
    values: List<String>?

  Type SelectorOperator:
    variants: [In, NotIn, Exists, DoesNotExist]

  Type PodTemplate:
    metadata: PodMetadata
    spec: PodSpec

  Type PodMetadata:
    labels: Map<String, String>
    annotations: Map<String, String>

  Type PodSpec:
    containers: List<ContainerSpec>
    init_containers: List<ContainerSpec>?
    volumes: List<Volume>?
    node_selector: Map<String, String>?
    affinity: Affinity?
    tolerations: List<Toleration>?
    service_account: String?
    restart_policy: RestartPolicy = Always

  Type ContainerSpec:
    name: String
    image: Image
    command: List<String>?
    args: List<String>?
    env: List<EnvVar>?
    ports: List<PortMapping>?
    resources: ResourceRequirements?
    volume_mounts: List<VolumeMount>?
    liveness_probe: HealthCheck?
    readiness_probe: HealthCheck?
    startup_probe: HealthCheck?

  Type EnvVar:
    name: String
    value: String?
    value_from: EnvVarSource?

  Type EnvVarSource:
    variants:
      - ConfigMapKeyRef: (name: String, key: String)
      - SecretKeyRef: (name: String, key: String)
      - FieldRef: String
      - ResourceFieldRef: (container: String, resource: String)

  Type DeploymentStrategy:
    variants:
      - RollingUpdate: RollingUpdateConfig
      - Recreate

  Type RollingUpdateConfig:
    max_unavailable: IntOrPercent = Percent(25)
    max_surge: IntOrPercent = Percent(25)

  Type IntOrPercent:
    variants:
      - Int: Int
      - Percent: Int

  Type DeploymentStatus:
    replicas: Int
    ready_replicas: Int
    available_replicas: Int
    unavailable_replicas: Int
    updated_replicas: Int
    observed_generation: Int
    conditions: List<DeploymentCondition>

  Type DeploymentCondition:
    type: DeploymentConditionType
    status: Boolean
    reason: String?
    message: String?
    last_update: Timestamp
    last_transition: Timestamp

  Type DeploymentConditionType:
    variants: [Available, Progressing, ReplicaFailure]

  # ==========================================================================
  # SCHEDULING
  # ==========================================================================

  Type Node:
    id: NodeId
    name: String
    labels: Map<String, String>
    annotations: Map<String, String>
    taints: List<Taint>
    capacity: Resources
    allocatable: Resources
    allocated: Resources
    conditions: List<NodeCondition>
    state: NodeState

  Type NodeId:
    value: String

  Type NodeState:
    variants:
      - Ready
      - NotReady
      - Unknown
      - Cordoned
      - Draining

  Type NodeCondition:
    type: NodeConditionType
    status: Boolean
    reason: String?
    message: String?

  Type NodeConditionType:
    variants: [Ready, MemoryPressure, DiskPressure, PIDPressure, NetworkUnavailable]

  Type Taint:
    key: String
    value: String?
    effect: TaintEffect

  Type TaintEffect:
    variants:
      - NoSchedule
      - PreferNoSchedule
      - NoExecute

  Type Toleration:
    key: String?
    operator: TolerationOperator = Equal
    value: String?
    effect: TaintEffect?
    toleration_seconds: Int?

  Type TolerationOperator:
    variants: [Equal, Exists]

  Type Affinity:
    node_affinity: NodeAffinity?
    pod_affinity: PodAffinity?
    pod_anti_affinity: PodAntiAffinity?

  Type NodeAffinity:
    required: NodeSelector?
    preferred: List<PreferredSchedulingTerm>?

  Type NodeSelector:
    terms: List<NodeSelectorTerm>

  Type NodeSelectorTerm:
    match_expressions: List<NodeSelectorRequirement>
    match_fields: List<NodeSelectorRequirement>?

  Type NodeSelectorRequirement:
    key: String
    operator: SelectorOperator
    values: List<String>?

  Type PreferredSchedulingTerm:
    weight: Int  # 1-100
    preference: NodeSelectorTerm

  Type PodAffinity:
    required: List<PodAffinityTerm>?
    preferred: List<WeightedPodAffinityTerm>?

  Type PodAntiAffinity:
    required: List<PodAffinityTerm>?
    preferred: List<WeightedPodAffinityTerm>?

  Type PodAffinityTerm:
    label_selector: LabelSelector
    topology_key: String
    namespaces: List<String>?

  Type WeightedPodAffinityTerm:
    weight: Int
    pod_affinity_term: PodAffinityTerm

  Behavior Scheduler:
    """Pod scheduling"""

    State:
      nodes: Map<NodeId, Node>
      pending_pods: Queue<Pod>
      scheduling_queue: PriorityQueue<Pod>

    When schedule(pod):
      Then:
        - # Filter nodes
        - feasible_nodes = nodes.values().filter(n ->
            check_node_conditions(n) and
            check_resources(n, pod) and
            check_node_selector(n, pod) and
            check_taints_tolerations(n, pod) and
            check_affinity(n, pod)
          )
        
        - if feasible_nodes.is_empty():
            - emit SchedulingFailed(pod, "No feasible nodes")
            - return Error(NoFeasibleNodes)
        
        - # Score nodes
        - scored_nodes = feasible_nodes.map(n -> {
            node: n,
            score: calculate_score(n, pod)
          })
        
        - # Select best node
        - best = scored_nodes.max_by(s -> s.score)
        
        - # Bind pod to node
        - await bind_pod(pod, best.node)
        - emit PodScheduled(pod, best.node)
        - return Ok(best.node)

    When calculate_score(node, pod):
      Then:
        - score = 0
        
        - # Resource balance
        - cpu_ratio = (node.allocated.cpu + pod.resources.requests.cpu) / node.allocatable.cpu
        - mem_ratio = (node.allocated.memory + pod.resources.requests.memory) / node.allocatable.memory
        - score += (1 - abs(cpu_ratio - mem_ratio)) * 10
        
        - # Least requested
        - score += (1 - cpu_ratio) * 10
        - score += (1 - mem_ratio) * 10
        
        - # Node affinity
        - if pod.affinity?.node_affinity?.preferred:
            - for term in pod.affinity.node_affinity.preferred:
                - if matches_node_selector_term(node, term.preference):
                    - score += term.weight
        
        - # Pod affinity/anti-affinity
        - score += calculate_pod_affinity_score(node, pod)
        
        - return score

    When check_resources(node, pod):
      Then:
        - available_cpu = node.allocatable.cpu - node.allocated.cpu
        - available_mem = node.allocatable.memory - node.allocated.memory
        
        - return pod.resources.requests.cpu <= available_cpu and
                pod.resources.requests.memory <= available_mem

    When check_taints_tolerations(node, pod):
      Then:
        - for taint in node.taints:
            - if not pod.tolerations.any(t -> tolerates(t, taint)):
                - return false
        - return true

    When tolerates(toleration, taint):
      Then:
        - if toleration.key and toleration.key != taint.key:
            - return false
        - if toleration.effect and toleration.effect != taint.effect:
            - return false
        - if toleration.operator == Equal:
            - return toleration.value == taint.value
        - return true  # Exists operator

  # ==========================================================================
  # AUTOSCALING
  # ==========================================================================

  Type HorizontalPodAutoscaler:
    name: String
    namespace: String
    target: ScaleTarget
    min_replicas: Int = 1
    max_replicas: Int
    metrics: List<MetricSpec>
    behavior: ScalingBehavior?
    status: HPAStatus

  Type ScaleTarget:
    kind: String  # Deployment, StatefulSet, etc.
    name: String

  Type MetricSpec:
    variants:
      - Resource: ResourceMetric
      - Pods: PodsMetric
      - Object: ObjectMetric
      - External: ExternalMetric

  Type ResourceMetric:
    name: String  # cpu, memory
    target: MetricTarget

  Type MetricTarget:
    type: MetricTargetType
    value: Int?
    average_value: Int?
    average_utilization: Int?

  Type MetricTargetType:
    variants: [Utilization, Value, AverageValue]

  Type ScalingBehavior:
    scale_up: ScalingRules?
    scale_down: ScalingRules?

  Type ScalingRules:
    stabilization_window: Duration = 0.seconds
    select_policy: ScalingPolicySelect = Max
    policies: List<ScalingPolicy>

  Type ScalingPolicySelect:
    variants: [Max, Min, Disabled]

  Type ScalingPolicy:
    type: ScalingPolicyType
    value: Int
    period: Duration

  Type ScalingPolicyType:
    variants: [Pods, Percent]

  Type HPAStatus:
    current_replicas: Int
    desired_replicas: Int
    current_metrics: List<MetricStatus>
    last_scale_time: Timestamp?

  Behavior Autoscaler:
    """Horizontal Pod Autoscaler"""

    When autoscale(hpa):
      Then:
        - # Get current metrics
        - metrics = await collect_metrics(hpa)
        
        - # Calculate desired replicas
        - desired = calculate_desired_replicas(hpa, metrics)
        
        - # Apply scaling behavior
        - desired = apply_scaling_behavior(hpa, desired)
        
        - # Clamp to min/max
        - desired = clamp(desired, hpa.min_replicas, hpa.max_replicas)
        
        - # Scale if needed
        - if desired != hpa.status.current_replicas:
            - await scale_target(hpa.target, desired)
            - emit Scaled(hpa, hpa.status.current_replicas, desired)

    When calculate_desired_replicas(hpa, metrics):
      Then:
        - ratios = []
        
        - for (spec, status) in zip(hpa.metrics, metrics):
            - ratio = match spec:
                Resource(r) ->
                  status.current / r.target.average_utilization
                Pods(p) ->
                  status.current / p.target.average_value
                _ ->
                  status.current / spec.target.value
            - add ratio to ratios
        
        - # Use max ratio
        - max_ratio = ratios.max()
        - return ceil(hpa.status.current_replicas * max_ratio)

  # ==========================================================================
  # SERVICE MESH
  # ==========================================================================

  Type Service:
    name: String
    namespace: String
    selector: Map<String, String>
    ports: List<ServicePort>
    type: ServiceType = ClusterIP
    cluster_ip: IPAddress?
    external_ips: List<IPAddress>?
    load_balancer_ip: IPAddress?

  Type ServicePort:
    name: String?
    port: Port
    target_port: Port
    protocol: Protocol = TCP
    node_port: Port?

  Type ServiceType:
    variants:
      - ClusterIP
      - NodePort
      - LoadBalancer
      - ExternalName: String

  Type Ingress:
    name: String
    namespace: String
    rules: List<IngressRule>
    tls: List<IngressTLS>?
    default_backend: IngressBackend?

  Type IngressRule:
    host: String?
    http: HTTPIngressRuleValue

  Type HTTPIngressRuleValue:
    paths: List<HTTPIngressPath>

  Type HTTPIngressPath:
    path: String
    path_type: PathType
    backend: IngressBackend

  Type PathType:
    variants: [Exact, Prefix, ImplementationSpecific]

  Type IngressBackend:
    service: ServiceBackend
    resource: ResourceBackend?

  Type ServiceBackend:
    name: String
    port: ServiceBackendPort

  Type ServiceBackendPort:
    name: String?
    number: Port?

  Type IngressTLS:
    hosts: List<String>
    secret_name: String

  Type VirtualService:
    """Istio-style traffic management"""
    name: String
    hosts: List<String>
    http: List<HTTPRoute>
    tcp: List<TCPRoute>?
    tls: List<TLSRoute>?

  Type HTTPRoute:
    name: String?
    match: List<HTTPMatchRequest>?
    route: List<HTTPRouteDestination>
    redirect: HTTPRedirect?
    rewrite: HTTPRewrite?
    timeout: Duration?
    retries: HTTPRetry?
    fault: HTTPFaultInjection?
    mirror: Destination?
    mirror_percentage: Float?
    headers: HeaderOperations?

  Type HTTPMatchRequest:
    uri: StringMatch?
    headers: Map<String, StringMatch>?
    query_params: Map<String, StringMatch>?
    method: StringMatch?

  Type StringMatch:
    variants:
      - Exact: String
      - Prefix: String
      - Regex: String

  Type HTTPRouteDestination:
    destination: Destination
    weight: Int = 100
    headers: HeaderOperations?

  Type Destination:
    host: String
    port: Port?
    subset: String?

  Type HTTPRetry:
    attempts: Int
    per_try_timeout: Duration?
    retry_on: String?

  Type HTTPFaultInjection:
    delay: FaultDelay?
    abort: FaultAbort?

  Type FaultDelay:
    percentage: Float
    fixed_delay: Duration

  Type FaultAbort:
    percentage: Float
    http_status: Int

  Type DestinationRule:
    """Traffic policies"""
    name: String
    host: String
    traffic_policy: TrafficPolicy?
    subsets: List<Subset>?

  Type TrafficPolicy:
    connection_pool: ConnectionPoolSettings?
    load_balancer: LoadBalancerSettings?
    outlier_detection: OutlierDetection?
    tls: TLSSettings?

  Type ConnectionPoolSettings:
    tcp: TCPSettings?
    http: HTTPSettings?

  Type TCPSettings:
    max_connections: Int?
    connect_timeout: Duration?

  Type HTTPSettings:
    h2_upgrade_policy: H2UpgradePolicy?
    http1_max_pending_requests: Int?
    http2_max_requests: Int?
    max_requests_per_connection: Int?
    max_retries: Int?

  Type H2UpgradePolicy:
    variants: [Default, DoNotUpgrade, Upgrade]

  Type LoadBalancerSettings:
    simple: SimpleLB?
    consistent_hash: ConsistentHashLB?

  Type SimpleLB:
    variants: [RoundRobin, LeastConn, Random, Passthrough]

  Type ConsistentHashLB:
    variants:
      - HTTPHeaderName: String
      - HTTPCookie: HTTPCookie
      - UseSourceIP
      - HTTPQueryParameterName: String

  Type HTTPCookie:
    name: String
    path: String?
    ttl: Duration?

  Type OutlierDetection:
    consecutive_errors: Int?
    consecutive_gateway_errors: Int?
    interval: Duration?
    base_ejection_time: Duration?
    max_ejection_percent: Int?
    min_health_percent: Int?

  Type Subset:
    name: String
    labels: Map<String, String>
    traffic_policy: TrafficPolicy?

  # ==========================================================================
  # СОБЫТИЯ
  # ==========================================================================

  Events:
    PodScheduled:
      pod_id: PodId
      node_id: NodeId

    PodStarted:
      pod_id: PodId
      containers: List<ContainerId>

    PodFailed:
      pod_id: PodId
      reason: String

    DeploymentUpdated:
      deployment_id: DeploymentId
      replicas: Int
      ready: Int

    Scaled:
      target: String
      from_replicas: Int
      to_replicas: Int
      reason: String

    RolloutStarted:
      deployment_id: DeploymentId
      revision: Int

    RolloutCompleted:
      deployment_id: DeploymentId
      revision: Int
      duration: Duration

    RolloutFailed:
      deployment_id: DeploymentId
      reason: String

    NodeReady:
      node_id: NodeId

    NodeNotReady:
      node_id: NodeId
      reason: String

  # ==========================================================================
  # ПРИМЕР ИСПОЛЬЗОВАНИЯ
  # ==========================================================================

  Example "Deployment with Rolling Update":
    ```vibee
    Deployment web_app:
      name: "web-app"
      namespace: "production"
      replicas: 3
      
      selector:
        match_labels:
          app: "web-app"
      
      strategy:
        RollingUpdate:
          max_unavailable: Percent(25)
          max_surge: Percent(25)
      
      template:
        metadata:
          labels:
            app: "web-app"
            version: "v1.2.0"
        
        spec:
          containers:
            - name: "app"
              image: Image(
                repository: "myregistry/web-app",
                tag: "v1.2.0"
              )
              ports:
                - container_port: 8080
                  name: "http"
              
              resources:
                requests:
                  cpu: CPUQuantity(100)  # 100m
                  memory: 128.MB
                limits:
                  cpu: CPUQuantity(500)
                  memory: 512.MB
              
              env:
                - name: "DATABASE_URL"
                  value_from: SecretKeyRef("db-secret", "url")
              
              liveness_probe:
                probe: HTTP(path: "/health", port: 8080)
                initial_delay: 10.seconds
                period: 10.seconds
              
              readiness_probe:
                probe: HTTP(path: "/ready", port: 8080)
                period: 5.seconds
    ```

  Example "Canary Deployment with Service Mesh":
    ```vibee
    # Destination rule with subsets
    DestinationRule web_app_dr:
      name: "web-app"
      host: "web-app"
      
      subsets:
        - name: "stable"
          labels:
            version: "v1.0.0"
        
        - name: "canary"
          labels:
            version: "v1.1.0"
      
      traffic_policy:
        connection_pool:
          http:
            http2_max_requests: 1000
            max_requests_per_connection: 10
        
        outlier_detection:
          consecutive_errors: 5
          interval: 30.seconds
          base_ejection_time: 30.seconds
          max_ejection_percent: 50

    # Virtual service for traffic splitting
    VirtualService web_app_vs:
      name: "web-app"
      hosts: ["web-app"]
      
      http:
        - name: "canary-route"
          route:
            - destination:
                host: "web-app"
                subset: "stable"
              weight: 90
            
            - destination:
                host: "web-app"
                subset: "canary"
              weight: 10
          
          retries:
            attempts: 3
            per_try_timeout: 2.seconds
            retry_on: "5xx,reset,connect-failure"
    ```

  Example "Horizontal Pod Autoscaler":
    ```vibee
    HorizontalPodAutoscaler web_app_hpa:
      name: "web-app-hpa"
      namespace: "production"
      
      target:
        kind: "Deployment"
        name: "web-app"
      
      min_replicas: 2
      max_replicas: 10
      
      metrics:
        - Resource:
            name: "cpu"
            target:
              type: Utilization
              average_utilization: 70
        
        - Resource:
            name: "memory"
            target:
              type: Utilization
              average_utilization: 80
      
      behavior:
        scale_up:
          stabilization_window: 0.seconds
          policies:
            - type: Percent
              value: 100
              period: 15.seconds
            - type: Pods
              value: 4
              period: 15.seconds
          select_policy: Max
        
        scale_down:
          stabilization_window: 5.minutes
          policies:
            - type: Percent
              value: 10
              period: 1.minute
    ```
