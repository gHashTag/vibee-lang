# ============================================================================
# SEARCH ENGINE - Полнотекстовый поиск на Vibee
# ============================================================================
# Indexing, full-text search, facets, aggregations
# ============================================================================

Specification SearchEngine:
  """Поисковый движок как спецификация поиска."""

  # ==========================================================================
  # INDEX TYPES
  # ==========================================================================

  Type Index:
    name: String
    settings: IndexSettings
    mappings: Mappings
    shards: List<Shard>
    aliases: List<String>
    created_at: Timestamp

  Type IndexSettings:
    number_of_shards: Int = 1
    number_of_replicas: Int = 1
    refresh_interval: Duration = 1.second
    analysis: AnalysisSettings?
    max_result_window: Int = 10000

  Type AnalysisSettings:
    analyzers: Map<String, Analyzer>
    tokenizers: Map<String, Tokenizer>
    filters: Map<String, TokenFilter>
    char_filters: Map<String, CharFilter>

  Type Analyzer:
    type: AnalyzerType
    tokenizer: String?
    filter: List<String>?
    char_filter: List<String>?

  Type AnalyzerType:
    variants:
      - Standard
      - Simple
      - Whitespace
      - Stop
      - Keyword
      - Pattern: String
      - Language: String
      - Custom

  Type Tokenizer:
    variants:
      - Standard
      - Letter
      - Lowercase
      - Whitespace
      - UAXURLEmail
      - Classic
      - NGram: (min: Int, max: Int)
      - EdgeNGram: (min: Int, max: Int)
      - Pattern: String

  Type TokenFilter:
    variants:
      - Lowercase
      - Uppercase
      - Stop: List<String>?
      - Stemmer: String
      - Synonym: SynonymConfig
      - NGram: (min: Int, max: Int)
      - EdgeNGram: (min: Int, max: Int)
      - Shingle: (min: Int, max: Int)
      - Trim
      - Length: (min: Int, max: Int)
      - Unique

  Type SynonymConfig:
    synonyms: List<String>?
    synonyms_path: Path?

  Type CharFilter:
    variants:
      - HTMLStrip
      - Mapping: Map<String, String>
      - PatternReplace: (pattern: String, replacement: String)

  Type Mappings:
    properties: Map<String, FieldMapping>
    dynamic: DynamicMapping = True

  Type DynamicMapping:
    variants: [True, False, Strict, Runtime]

  Type FieldMapping:
    type: FieldType
    analyzer: String?
    search_analyzer: String?
    index: Boolean = true
    store: Boolean = false
    doc_values: Boolean = true
    fields: Map<String, FieldMapping>?
    copy_to: List<String>?
    null_value: Any?

  Type FieldType:
    variants:
      - Text
      - Keyword
      - Long | Integer | Short | Byte
      - Double | Float | HalfFloat
      - Boolean
      - Date: DateFormat?
      - Object
      - Nested
      - GeoPoint
      - GeoShape
      - Completion
      - DenseVector: Int
      - SparseVector

  Type DateFormat:
    format: String = "strict_date_optional_time||epoch_millis"

  # ==========================================================================
  # DOCUMENT TYPES
  # ==========================================================================

  Type Document:
    id: DocumentId
    index: String
    source: Map<String, Any>
    version: Int?
    seq_no: Int?
    primary_term: Int?

  Type DocumentId:
    value: String

  Type BulkOperation:
    variants:
      - Index: (index: String, id: DocumentId?, doc: Map<String, Any>)
      - Create: (index: String, id: DocumentId, doc: Map<String, Any>)
      - Update: (index: String, id: DocumentId, doc: Map<String, Any>, upsert: Boolean)
      - Delete: (index: String, id: DocumentId)

  Type BulkResponse:
    took: Duration
    errors: Boolean
    items: List<BulkItemResponse>

  Type BulkItemResponse:
    operation: String
    index: String
    id: DocumentId
    status: Int
    error: BulkError?

  Type BulkError:
    type: String
    reason: String

  # ==========================================================================
  # QUERY DSL
  # ==========================================================================

  Type Query:
    variants:
      # Full-text queries
      - Match: MatchQuery
      - MatchPhrase: MatchPhraseQuery
      - MatchPhrasePrefix: MatchPhrasePrefixQuery
      - MultiMatch: MultiMatchQuery
      - QueryString: QueryStringQuery
      - SimpleQueryString: SimpleQueryStringQuery
      
      # Term-level queries
      - Term: TermQuery
      - Terms: TermsQuery
      - Range: RangeQuery
      - Exists: String
      - Prefix: PrefixQuery
      - Wildcard: WildcardQuery
      - Regexp: RegexpQuery
      - Fuzzy: FuzzyQuery
      - IDs: List<DocumentId>
      
      # Compound queries
      - Bool: BoolQuery
      - Boosting: BoostingQuery
      - ConstantScore: (query: Query, boost: Float)
      - DisMax: DisMaxQuery
      - FunctionScore: FunctionScoreQuery
      
      # Specialized queries
      - Nested: NestedQuery
      - HasChild: HasChildQuery
      - HasParent: HasParentQuery
      - MoreLikeThis: MoreLikeThisQuery
      - Percolate: PercolateQuery
      - KNN: KNNQuery
      
      # Match all/none
      - MatchAll: Float?
      - MatchNone

  Type MatchQuery:
    field: String
    query: String
    operator: Operator = Or
    fuzziness: Fuzziness?
    prefix_length: Int = 0
    max_expansions: Int = 50
    analyzer: String?
    minimum_should_match: String?

  Type Operator:
    variants: [And, Or]

  Type Fuzziness:
    variants:
      - Auto
      - Zero
      - One
      - Two

  Type MatchPhraseQuery:
    field: String
    query: String
    slop: Int = 0
    analyzer: String?

  Type MultiMatchQuery:
    query: String
    fields: List<String>
    type: MultiMatchType = BestFields
    operator: Operator = Or
    tie_breaker: Float = 0.0

  Type MultiMatchType:
    variants: [BestFields, MostFields, CrossFields, Phrase, PhrasePrefix, BoolPrefix]

  Type TermQuery:
    field: String
    value: Any
    boost: Float = 1.0

  Type TermsQuery:
    field: String
    values: List<Any>

  Type RangeQuery:
    field: String
    gt: Any?
    gte: Any?
    lt: Any?
    lte: Any?
    format: String?
    time_zone: String?

  Type BoolQuery:
    must: List<Query> = []
    filter: List<Query> = []
    should: List<Query> = []
    must_not: List<Query> = []
    minimum_should_match: Int?

  Type FuzzyQuery:
    field: String
    value: String
    fuzziness: Fuzziness = Auto
    prefix_length: Int = 0
    max_expansions: Int = 50

  Type KNNQuery:
    field: String
    query_vector: List<Float>
    k: Int
    num_candidates: Int?
    filter: Query?

  # ==========================================================================
  # SEARCH REQUEST/RESPONSE
  # ==========================================================================

  Type SearchRequest:
    index: String | List<String>
    query: Query?
    from: Int = 0
    size: Int = 10
    sort: List<Sort>?
    source: SourceFilter?
    highlight: Highlight?
    aggregations: Map<String, Aggregation>?
    post_filter: Query?
    rescore: List<Rescore>?
    suggest: Map<String, Suggest>?
    track_total_hits: Boolean | Int = true
    timeout: Duration?
    explain: Boolean = false

  Type Sort:
    variants:
      - Field: (field: String, order: SortOrder, mode: SortMode?)
      - Score: SortOrder
      - GeoDistance: (field: String, point: GeoPoint, order: SortOrder, unit: DistanceUnit)
      - Script: (script: Script, order: SortOrder, type: String)

  Type SortOrder:
    variants: [Asc, Desc]

  Type SortMode:
    variants: [Min, Max, Sum, Avg, Median]

  Type SourceFilter:
    variants:
      - Enabled: Boolean
      - Includes: List<String>
      - Excludes: List<String>
      - IncludesExcludes: (includes: List<String>, excludes: List<String>)

  Type Highlight:
    fields: Map<String, HighlightField>
    pre_tags: List<String> = ["<em>"]
    post_tags: List<String> = ["</em>"]
    fragment_size: Int = 100
    number_of_fragments: Int = 5
    type: HighlightType = Unified

  Type HighlightField:
    fragment_size: Int?
    number_of_fragments: Int?
    pre_tags: List<String>?
    post_tags: List<String>?

  Type HighlightType:
    variants: [Unified, Plain, FVH]

  Type SearchResponse:
    took: Duration
    timed_out: Boolean
    shards: ShardStats
    hits: Hits
    aggregations: Map<String, AggregationResult>?
    suggest: Map<String, List<SuggestResult>>?

  Type ShardStats:
    total: Int
    successful: Int
    skipped: Int
    failed: Int

  Type Hits:
    total: TotalHits
    max_score: Float?
    hits: List<Hit>

  Type TotalHits:
    value: Int
    relation: TotalHitsRelation

  Type TotalHitsRelation:
    variants: [Eq, Gte]

  Type Hit:
    index: String
    id: DocumentId
    score: Float?
    source: Map<String, Any>?
    highlight: Map<String, List<String>>?
    sort: List<Any>?
    explanation: Explanation?

  # ==========================================================================
  # AGGREGATIONS
  # ==========================================================================

  Type Aggregation:
    variants:
      # Bucket aggregations
      - Terms: TermsAggregation
      - Range: RangeAggregation
      - DateRange: DateRangeAggregation
      - Histogram: HistogramAggregation
      - DateHistogram: DateHistogramAggregation
      - Filter: Query
      - Filters: Map<String, Query>
      - Nested: String
      - Global
      - Missing: String
      - GeoDistance: GeoDistanceAggregation
      
      # Metric aggregations
      - Avg: String
      - Sum: String
      - Min: String
      - Max: String
      - Count: String
      - Stats: String
      - ExtendedStats: String
      - Cardinality: CardinalityAggregation
      - Percentiles: PercentilesAggregation
      - TopHits: TopHitsAggregation
      
      # Pipeline aggregations
      - BucketSort: BucketSortAggregation
      - CumulativeSum: String
      - Derivative: String
      - MovingAvg: MovingAvgAggregation

  Type TermsAggregation:
    field: String
    size: Int = 10
    order: Map<String, SortOrder>?
    min_doc_count: Int = 1
    include: String?
    exclude: String?
    missing: Any?
    aggs: Map<String, Aggregation>?

  Type HistogramAggregation:
    field: String
    interval: Float
    min_doc_count: Int = 0
    extended_bounds: (min: Float, max: Float)?
    aggs: Map<String, Aggregation>?

  Type DateHistogramAggregation:
    field: String
    calendar_interval: CalendarInterval?
    fixed_interval: Duration?
    format: String?
    time_zone: String?
    min_doc_count: Int = 0
    aggs: Map<String, Aggregation>?

  Type CalendarInterval:
    variants: [Minute, Hour, Day, Week, Month, Quarter, Year]

  Type RangeAggregation:
    field: String
    ranges: List<RangeBucket>
    keyed: Boolean = false
    aggs: Map<String, Aggregation>?

  Type RangeBucket:
    key: String?
    from: Float?
    to: Float?

  Type TopHitsAggregation:
    size: Int = 3
    sort: List<Sort>?
    source: SourceFilter?
    highlight: Highlight?

  Type AggregationResult:
    variants:
      - Buckets: List<Bucket>
      - Value: Float
      - Values: Map<String, Float>
      - Hits: Hits

  Type Bucket:
    key: Any
    key_as_string: String?
    doc_count: Int
    aggregations: Map<String, AggregationResult>?

  # ==========================================================================
  # SUGGEST
  # ==========================================================================

  Type Suggest:
    variants:
      - Term: TermSuggest
      - Phrase: PhraseSuggest
      - Completion: CompletionSuggest

  Type TermSuggest:
    text: String
    field: String
    size: Int = 5
    sort: SuggestSort = Score
    suggest_mode: SuggestMode = Missing

  Type SuggestSort:
    variants: [Score, Frequency]

  Type SuggestMode:
    variants: [Missing, Popular, Always]

  Type CompletionSuggest:
    prefix: String
    field: String
    size: Int = 5
    skip_duplicates: Boolean = false
    fuzzy: FuzzyConfig?
    contexts: Map<String, List<String>>?

  Type FuzzyConfig:
    fuzziness: Fuzziness = Auto
    transpositions: Boolean = true
    min_length: Int = 3
    prefix_length: Int = 1

  Type SuggestResult:
    text: String
    offset: Int
    length: Int
    options: List<SuggestOption>

  Type SuggestOption:
    text: String
    score: Float
    freq: Int?
    highlighted: String?

  # ==========================================================================
  # INDEXING BEHAVIOR
  # ==========================================================================

  Behavior Indexing:
    When search.create_index(name, settings, mappings):
      Then:
        - index = Index(
            name: name,
            settings: settings ?? IndexSettings(),
            mappings: mappings ?? Mappings(properties: {}),
            shards: create_shards(settings.number_of_shards),
            created_at: now()
          )
        - indices[name] = index
        - emit IndexCreated(name)

    When search.index(index, id, document):
      Then:
        - doc_id = id ?? generate_id()
        - analyzed = analyze_document(document, indices[index].mappings)
        - shard = get_shard(index, doc_id)
        - shard.index(doc_id, analyzed, document)
        - emit DocumentIndexed(index, doc_id)
        - return doc_id

    When search.bulk(operations):
      Then:
        - results = []
        - for op in operations:
            - result = match op:
                Index(idx, id, doc) -> search.index(idx, id, doc)
                Create(idx, id, doc) -> search.create(idx, id, doc)
                Update(idx, id, doc, upsert) -> search.update(idx, id, doc, upsert)
                Delete(idx, id) -> search.delete(idx, id)
            - add result to results
        - return BulkResponse(results)

    When search.update(index, id, partial_doc, upsert):
      Then:
        - existing = search.get(index, id)
        - if not existing and not upsert:
            - raise DocumentNotFound(index, id)
        - merged = merge(existing?.source ?? {}, partial_doc)
        - search.index(index, id, merged)

    When search.delete(index, id):
      Then:
        - shard = get_shard(index, id)
        - shard.delete(id)
        - emit DocumentDeleted(index, id)

    When search.delete_by_query(index, query):
      Then:
        - results = search.search(SearchRequest(index: index, query: query, size: 10000))
        - for hit in results.hits.hits:
            - search.delete(index, hit.id)
        - return results.hits.total.value

  # ==========================================================================
  # SEARCH BEHAVIOR
  # ==========================================================================

  Behavior Searching:
    When search.search(request):
      Then:
        - start = now()
        - indices = resolve_indices(request.index)
        
        - # Execute query on each shard
        - shard_results = parallel(
            indices.flat_map(i -> i.shards).map(s ->
              execute_on_shard(s, request)
            )
          )
        
        - # Merge results
        - merged = merge_shard_results(shard_results, request)
        
        - # Apply post_filter
        - if request.post_filter:
            - merged.hits = filter_hits(merged.hits, request.post_filter)
        
        - # Compute aggregations
        - if request.aggregations:
            - merged.aggregations = compute_aggregations(shard_results, request.aggregations)
        
        - # Apply highlighting
        - if request.highlight:
            - merged.hits = apply_highlighting(merged.hits, request.query, request.highlight)
        
        - merged.took = now() - start
        - return merged

    When execute_on_shard(shard, request):
      Then:
        - # Parse and optimize query
        - optimized = optimize_query(request.query)
        
        - # Execute query
        - doc_ids = shard.query(optimized)
        
        - # Score documents
        - scored = doc_ids.map(id -> {
            id: id,
            score: calculate_score(shard, id, optimized)
          })
        
        - # Sort
        - sorted = apply_sort(scored, request.sort)
        
        - # Paginate
        - paginated = sorted.slice(request.from, request.from + request.size)
        
        - # Fetch source
        - hits = paginated.map(s -> {
            id: s.id,
            score: s.score,
            source: fetch_source(shard, s.id, request.source)
          })
        
        - return ShardResult(hits, scored.size)

    When calculate_score(shard, doc_id, query):
      """BM25 scoring"""
      Then:
        - match query:
            Match(m) ->
              terms = analyze(m.query, m.analyzer)
              sum(terms.map(t -> bm25_score(shard, doc_id, m.field, t)))
            Bool(b) ->
              must_score = sum(b.must.map(q -> calculate_score(shard, doc_id, q)))
              should_score = sum(b.should.map(q -> calculate_score(shard, doc_id, q)))
              must_score + should_score
            ConstantScore(q, boost) ->
              if matches(shard, doc_id, q) then boost else 0
            _ -> 1.0

    When bm25_score(shard, doc_id, field, term):
      Then:
        - k1 = 1.2
        - b = 0.75
        - tf = term_frequency(shard, doc_id, field, term)
        - df = document_frequency(shard, field, term)
        - dl = document_length(shard, doc_id, field)
        - avgdl = average_document_length(shard, field)
        - N = shard.doc_count
        
        - idf = log((N - df + 0.5) / (df + 0.5) + 1)
        - tf_norm = (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * dl / avgdl))
        
        - return idf * tf_norm

  # ==========================================================================
  # EXAMPLE
  # ==========================================================================

  Example "Search Engine Usage":
    ```vibee
    # Create index
    await search.create_index("products", 
      settings: IndexSettings(
        number_of_shards: 3,
        analysis: AnalysisSettings(
          analyzers: {
            "autocomplete": Analyzer(
              type: Custom,
              tokenizer: "standard",
              filter: ["lowercase", "autocomplete_filter"]
            )
          },
          filters: {
            "autocomplete_filter": EdgeNGram(min: 1, max: 20)
          }
        )
      ),
      mappings: Mappings(
        properties: {
          "name": FieldMapping(type: Text, analyzer: "standard", fields: {
            "autocomplete": FieldMapping(type: Text, analyzer: "autocomplete")
          }),
          "description": FieldMapping(type: Text),
          "price": FieldMapping(type: Float),
          "category": FieldMapping(type: Keyword),
          "tags": FieldMapping(type: Keyword),
          "created_at": FieldMapping(type: Date())
        }
      )
    )

    # Index documents
    await search.index("products", "1", {
      name: "iPhone 15 Pro",
      description: "Latest Apple smartphone",
      price: 999.99,
      category: "electronics",
      tags: ["phone", "apple", "smartphone"]
    })

    # Search with aggregations
    results = await search.search(SearchRequest(
      index: "products",
      query: Bool(BoolQuery(
        must: [Match(MatchQuery(field: "name", query: "iphone"))],
        filter: [Range(RangeQuery(field: "price", lte: 1500))]
      )),
      aggregations: {
        "categories": Terms(TermsAggregation(field: "category", size: 10)),
        "price_ranges": Range(RangeAggregation(
          field: "price",
          ranges: [
            RangeBucket(key: "cheap", to: 100),
            RangeBucket(key: "mid", from: 100, to: 500),
            RangeBucket(key: "expensive", from: 500)
          ]
        )),
        "avg_price": Avg("price")
      },
      highlight: Highlight(fields: { "name": {}, "description": {} }),
      sort: [Field("price", Asc)],
      size: 20
    ))
    ```
