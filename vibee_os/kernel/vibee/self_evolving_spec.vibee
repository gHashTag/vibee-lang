name: vibee_os_self_evolving_spec
version: "0.1.0"
language: gleam
module: kernel/vibee/self_evolving
description: Self-Evolving Specifications - спецификации которые улучшают себя через LLM и тестирование

behaviors:
  - name: spec_improves_itself
    given: Specification exists with test failures
    when: self_improve is triggered
    then: LLM analyzes failures and generates improved spec
    test_cases:
      - name: fix_failing_test
        input: {spec: "calculator.vibee", failing_tests: 2}
        expected: {improved: true, tests_fixed: 2, new_spec_valid: true}
      - name: no_failures_optimize
        input: {spec: "calculator.vibee", failing_tests: 0}
        expected: {improved: true, optimization: "performance", tests_still_pass: true}

  - name: spec_learns_from_usage
    given: Specification is deployed and used
    when: Usage patterns are collected
    then: Spec evolves to match actual usage
    test_cases:
      - name: add_missing_behavior
        input: {spec: "api.vibee", usage: "users often call /health endpoint"}
        expected: {new_behavior: "health_check", added: true}
      - name: optimize_hot_path
        input: {spec: "api.vibee", usage: "90% calls to /users"}
        expected: {optimization: "cache_users", applied: true}

  - name: spec_generates_tests
    given: Specification has behaviors without tests
    when: generate_tests is called
    then: LLM generates comprehensive test cases
    test_cases:
      - name: generate_edge_cases
        input: {behavior: "divide", has_tests: false}
        expected: {tests_generated: 5, includes_edge_cases: true, includes_zero_division: true}

  - name: spec_refactors_itself
    given: Specification has code smells
    when: refactor is triggered
    then: LLM refactors while preserving behavior
    test_cases:
      - name: extract_common_behavior
        input: {spec: "large.vibee", duplicate_code: true}
        expected: {refactored: true, behaviors_extracted: 3, tests_still_pass: true}

  - name: spec_merges_with_other
    given: Two related specifications exist
    when: merge is requested
    then: Specifications are intelligently merged
    test_cases:
      - name: merge_user_specs
        input: {spec_a: "user_create.vibee", spec_b: "user_update.vibee"}
        expected: {merged: "user.vibee", behaviors_combined: true, no_conflicts: true}

  - name: spec_splits_when_large
    given: Specification exceeds complexity threshold
    when: split is triggered
    then: Specification is split into cohesive modules
    test_cases:
      - name: split_monolith
        input: {spec: "monolith.vibee", behaviors: 50}
        expected: {split_into: 5, each_cohesive: true, imports_correct: true}

types:
  EvolvingSpec:
    spec: Specification
    history: [SpecVersion]
    metrics: SpecMetrics
    evolution_config: EvolutionConfig
    llm_provider: str

  SpecVersion:
    id: str
    spec: Specification
    timestamp: int
    author: EvolutionAuthor
    changes: [SpecChange]
    test_results: TestResults
    parent_id: str?

  EvolutionAuthor:
    variants:
      - Human: {name: str}
      - LLM: {model: str, prompt: str}
      - Hybrid: {human: str, llm: str}
      - System: {trigger: str}

  SpecChange:
    type: ChangeType
    target: str
    before: str?
    after: str
    reason: str

  ChangeType:
    variants:
      - AddBehavior
      - ModifyBehavior
      - RemoveBehavior
      - AddType
      - ModifyType
      - RemoveType
      - AddFunction
      - ModifyFunction
      - RemoveFunction
      - AddTest
      - ModifyTest
      - RemoveTest
      - Refactor
      - Optimize
      - Fix

  SpecMetrics:
    behaviors_count: int
    types_count: int
    functions_count: int
    tests_count: int
    test_pass_rate: float
    complexity_score: float
    coverage_percent: float
    usage_count: int
    error_rate: float
    avg_response_time_ms: float

  EvolutionConfig:
    auto_improve: bool
    improve_on_failure: bool
    improve_on_usage: bool
    min_test_pass_rate: float
    max_complexity: float
    llm_model: str
    human_approval_required: bool
    max_changes_per_evolution: int

  TestResults:
    total: int
    passed: int
    failed: int
    skipped: int
    failures: [TestFailure]
    duration_ms: int

  TestFailure:
    test_name: str
    behavior: str
    expected: str
    actual: str
    error: str?

  # Evolution Operations
  EvolutionRequest:
    spec_id: str
    operation: EvolutionOperation
    context: EvolutionContext
    constraints: [EvolutionConstraint]

  EvolutionOperation:
    variants:
      - Improve: {target: str?}
      - Fix: {failures: [TestFailure]}
      - Optimize: {metric: str}
      - Refactor: {smell: str}
      - GenerateTests: {behavior: str?}
      - AddBehavior: {description: str}
      - Merge: {other_spec: str}
      - Split: {criteria: str}
      - LearnFromUsage: {usage_data: UsageData}

  EvolutionContext:
    current_spec: Specification
    test_results: TestResults?
    usage_data: UsageData?
    related_specs: [str]
    constraints: [str]

  EvolutionConstraint:
    variants:
      - PreserveTests
      - PreserveBehaviors: {behaviors: [str]}
      - MaxComplexity: {score: float}
      - MaxChanges: {count: int}
      - RequireApproval
      - NoBreakingChanges

  UsageData:
    calls: [UsageCall]
    errors: [UsageError]
    patterns: [UsagePattern]
    period_hours: int

  UsageCall:
    behavior: str
    count: int
    avg_duration_ms: float
    params_distribution: {str: {str: int}}

  UsageError:
    behavior: str
    error_type: str
    count: int
    sample_input: str?

  UsagePattern:
    sequence: [str]
    count: int
    description: str

  EvolutionResult:
    success: bool
    new_spec: Specification?
    changes: [SpecChange]
    test_results: TestResults?
    approval_required: bool
    explanation: str

  # LLM Prompts for Evolution
  EvolutionPrompt:
    system: str
    user: str
    examples: [PromptExample]

  PromptExample:
    input: str
    output: str

functions:
  # Core evolution
  - name: evolve
    params: {request: EvolutionRequest}
    returns: EvolutionResult
    description: Evolve specification based on request

  - name: improve
    params: {spec: EvolvingSpec, target: str?}
    returns: EvolutionResult
    description: Improve specification (fix failures or optimize)

  - name: fix_failures
    params: {spec: EvolvingSpec, failures: [TestFailure]}
    returns: EvolutionResult
    description: Fix failing tests

  - name: optimize
    params: {spec: EvolvingSpec, metric: str}
    returns: EvolutionResult
    description: Optimize for specific metric

  # Test generation
  - name: generate_tests
    params: {spec: EvolvingSpec, behavior: str?}
    returns: EvolutionResult
    description: Generate test cases using LLM

  - name: generate_edge_cases
    params: {spec: EvolvingSpec, behavior: str}
    returns: [TestCase]
    description: Generate edge case tests

  # Refactoring
  - name: refactor
    params: {spec: EvolvingSpec, smell: str}
    returns: EvolutionResult
    description: Refactor to remove code smell

  - name: extract_behavior
    params: {spec: EvolvingSpec, code: str}
    returns: EvolutionResult
    description: Extract common code into behavior

  # Learning
  - name: learn_from_usage
    params: {spec: EvolvingSpec, usage: UsageData}
    returns: EvolutionResult
    description: Evolve based on usage patterns

  - name: suggest_improvements
    params: {spec: EvolvingSpec}
    returns: [EvolutionRequest]
    description: Suggest possible improvements

  # Merge/Split
  - name: merge_specs
    params: {spec_a: EvolvingSpec, spec_b: EvolvingSpec}
    returns: EvolutionResult
    description: Merge two specifications

  - name: split_spec
    params: {spec: EvolvingSpec, criteria: str}
    returns: [EvolutionResult]
    description: Split specification into modules

  # History
  - name: get_history
    params: {spec: EvolvingSpec}
    returns: [SpecVersion]
    description: Get evolution history

  - name: rollback
    params: {spec: EvolvingSpec, version_id: str}
    returns: EvolutionResult
    description: Rollback to previous version

  - name: diff_versions
    params: {version_a: str, version_b: str}
    returns: [SpecChange]
    description: Get diff between versions

  # Approval
  - name: request_approval
    params: {result: EvolutionResult}
    returns: str
    description: Request human approval

  - name: approve
    params: {approval_id: str}
    returns: bool
    description: Approve evolution

  - name: reject
    params: {approval_id: str, reason: str}
    returns: bool
    description: Reject evolution

imports:
  - kernel.vibee.compiler
  - kernel.agent.llm_backend
  - config.llm_providers

evolution_prompts: |
  # LLM Prompts for Self-Evolution
  
  ## Fix Failing Tests
  ```
  System: You are a Vibee specification expert. Fix the failing tests by modifying the specification.
  
  User: 
  Specification:
  {spec}
  
  Failing tests:
  {failures}
  
  Fix the specification to make all tests pass. Return only the modified YAML.
  ```
  
  ## Generate Tests
  ```
  System: You are a Vibee testing expert. Generate comprehensive test cases.
  
  User:
  Behavior:
  {behavior}
  
  Generate test cases including:
  1. Happy path
  2. Edge cases
  3. Error cases
  4. Boundary values
  
  Return test cases in Vibee YAML format.
  ```
  
  ## Optimize
  ```
  System: You are a Vibee optimization expert.
  
  User:
  Specification:
  {spec}
  
  Metrics:
  {metrics}
  
  Optimize for: {target_metric}
  
  Return optimized specification.
  ```
  
  ## Learn from Usage
  ```
  System: You are a Vibee evolution expert.
  
  User:
  Specification:
  {spec}
  
  Usage patterns:
  {usage}
  
  Suggest improvements based on actual usage.
  Return modified specification with new behaviors.
  ```

self_evolution_loop: |
  # Self-Evolution Loop
  
  ```
  ┌─────────────────────────────────────────────────────────────┐
  │                    Self-Evolution Loop                       │
  │                                                              │
  │  ┌──────────┐    ┌──────────┐    ┌──────────┐              │
  │  │   Spec   │───▶│   Test   │───▶│ Analyze  │              │
  │  │          │    │          │    │ Results  │              │
  │  └──────────┘    └──────────┘    └────┬─────┘              │
  │       ▲                               │                     │
  │       │                               ▼                     │
  │  ┌────┴─────┐    ┌──────────┐    ┌──────────┐              │
  │  │  Apply   │◀───│  Approve │◀───│   LLM    │              │
  │  │ Changes  │    │ (Human)  │    │ Improve  │              │
  │  └──────────┘    └──────────┘    └──────────┘              │
  │                                                              │
  │  Triggers:                                                   │
  │  • Test failure                                              │
  │  • Usage pattern detected                                    │
  │  • Complexity threshold exceeded                             │
  │  • Manual request                                            │
  │  • Scheduled improvement                                     │
  └─────────────────────────────────────────────────────────────┘
  ```

evolution_examples: |
  # Evolution Examples
  
  ## 1. Fix Failing Test
  
  Before:
  ```yaml
  - name: divide
    given: Two numbers a and b
    when: divide(a, b) is called
    then: Returns a / b
    test_cases:
      - name: divide_by_zero
        input: {a: 10, b: 0}
        expected: {error: "division_by_zero"}  # FAILS!
  ```
  
  After (LLM fixed):
  ```yaml
  - name: divide
    given: Two numbers a and b where b != 0
    when: divide(a, b) is called
    then: Returns a / b
    test_cases:
      - name: divide_by_zero
        input: {a: 10, b: 0}
        expected: {error: "division_by_zero"}  # PASSES!
  
  - name: divide_by_zero_error
    given: Divisor is zero
    when: divide(a, 0) is called
    then: Returns error "division_by_zero"
  ```
  
  ## 2. Learn from Usage
  
  Usage data:
  ```yaml
  calls:
    - behavior: get_user
      count: 10000
    - behavior: get_user_by_email  # Not in spec!
      count: 5000
      error_rate: 1.0  # Always fails
  ```
  
  LLM adds:
  ```yaml
  - name: get_user_by_email
    given: Email address is provided
    when: get_user_by_email(email) is called
    then: Returns user with matching email or null
  ```
  
  ## 3. Refactor Duplicate Code
  
  Before:
  ```yaml
  - name: create_user
    then: validate_email, hash_password, save_to_db
  
  - name: update_user
    then: validate_email, hash_password, save_to_db
  ```
  
  After (LLM refactored):
  ```yaml
  - name: process_user_data
    then: validate_email, hash_password
  
  - name: create_user
    then: process_user_data, save_to_db
  
  - name: update_user
    then: process_user_data, update_in_db
  ```
