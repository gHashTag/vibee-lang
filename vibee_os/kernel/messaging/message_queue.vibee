# ============================================================================
# MESSAGE QUEUE - Очереди сообщений на Vibee
# ============================================================================
# Message broker, event sourcing, CQRS, dead letter queues
# ============================================================================

Specification MessageQueue:
  """
  Message Queue как спецификация асинхронной коммуникации.
  Каждое сообщение - событие, каждая очередь - актор.
  """

  # ==========================================================================
  # ТИПЫ ДАННЫХ
  # ==========================================================================

  Type Message:
    id: MessageId
    topic: Topic
    key: String?
    payload: Bytes
    headers: Map<String, String>
    timestamp: Timestamp
    partition: Int?
    offset: Int?

  Type MessageId:
    value: UUID

  Type Topic:
    name: String
    partitions: Int = 1
    replication_factor: Int = 1
    retention: RetentionPolicy
    config: TopicConfig

  Type TopicConfig:
    max_message_size: ByteSize = 1.MB
    compression: Compression = None
    cleanup_policy: CleanupPolicy = Delete
    segment_size: ByteSize = 1.GB
    segment_time: Duration = 7.days

  Type Compression:
    variants: [None, Gzip, Snappy, LZ4, Zstd]

  Type CleanupPolicy:
    variants:
      - Delete
      - Compact
      - CompactDelete

  Type RetentionPolicy:
    time: Duration = 7.days
    size: ByteSize?
    messages: Int?

  Type Queue:
    name: String
    type: QueueType
    config: QueueConfig
    messages: List<QueuedMessage>
    consumers: List<Consumer>
    dead_letter: Queue?

  Type QueueType:
    variants:
      - Standard
      - FIFO
      - Priority
      - Delay

  Type QueueConfig:
    max_size: Int = 100000
    max_message_size: ByteSize = 256.KB
    visibility_timeout: Duration = 30.seconds
    message_retention: Duration = 4.days
    delivery_delay: Duration = 0.seconds
    max_receive_count: Int = 5
    deduplication_window: Duration = 5.minutes

  Type QueuedMessage:
    message: Message
    state: MessageState
    receive_count: Int
    first_received: Timestamp?
    visible_at: Timestamp

  Type MessageState:
    variants:
      - Available
      - InFlight
      - Delayed
      - DeadLetter

  # ==========================================================================
  # PRODUCER
  # ==========================================================================

  Type Producer:
    id: ProducerId
    config: ProducerConfig
    topics: Set<Topic>

  Type ProducerConfig:
    acks: Acks = All
    retries: Int = 3
    retry_backoff: Duration = 100.ms
    batch_size: Int = 16384
    linger_ms: Duration = 5.ms
    compression: Compression = None
    idempotent: Boolean = true
    transactional_id: String?

  Type Acks:
    variants:
      - None: 0      # Fire and forget
      - Leader: 1    # Leader acknowledged
      - All: -1      # All replicas acknowledged

  Behavior ProducerBehavior:
    """Поведение продюсера"""

    State:
      config: ProducerConfig
      batch_buffer: Map<Topic, List<Message>>
      pending_acks: Map<MessageId, Promise<SendResult>>
      sequence_numbers: Map<Topic, Int>

    When producer.send(topic, message):
      Then:
        - # Assign key if not provided
        - if not message.key:
            - message.key = generate_key()
        
        - # Determine partition
        - partition = partition_for(topic, message.key)
        - message.partition = partition
        
        - # Add to batch
        - add message to batch_buffer[topic]
        
        - # Create promise for ack
        - promise = create_promise()
        - pending_acks[message.id] = promise
        
        - # Flush if batch is full
        - if batch_buffer[topic].size >= config.batch_size:
            - await flush_batch(topic)
        
        - return promise

    When producer.send_batch(topic, messages):
      Then:
        - results = []
        - for message in messages:
            - add await producer.send(topic, message) to results
        - await flush_batch(topic)
        - return results

    When flush_batch(topic):
      Then:
        - batch = batch_buffer[topic]
        - clear batch_buffer[topic]
        
        - if batch.is_empty():
            - return
        
        - # Compress if configured
        - if config.compression != None:
            - batch = compress_batch(batch, config.compression)
        
        - # Send to broker
        - result = await send_to_broker(topic, batch, config.acks)
        
        - # Resolve promises
        - for message in batch:
            - pending_acks[message.id].resolve(result)

    When producer.flush():
      """Flush all pending batches"""
      Then:
        - for topic in batch_buffer.keys():
            - await flush_batch(topic)

    When producer.transaction(callback):
      """Transactional send"""
      Given config.transactional_id is defined
      Then:
        - await begin_transaction()
        - try:
            - result = await callback(producer)
            - await commit_transaction()
            - return result
          catch error:
            - await abort_transaction()
            - raise error

  # ==========================================================================
  # CONSUMER
  # ==========================================================================

  Type Consumer:
    id: ConsumerId
    group: ConsumerGroup?
    config: ConsumerConfig
    subscriptions: Set<Topic>
    assignments: Map<Topic, List<Int>>  # topic -> partitions

  Type ConsumerGroup:
    id: GroupId
    members: List<Consumer>
    leader: ConsumerId?
    generation: Int
    protocol: AssignmentProtocol

  Type ConsumerConfig:
    group_id: String?
    auto_offset_reset: OffsetReset = Latest
    enable_auto_commit: Boolean = true
    auto_commit_interval: Duration = 5.seconds
    max_poll_records: Int = 500
    max_poll_interval: Duration = 5.minutes
    session_timeout: Duration = 30.seconds
    heartbeat_interval: Duration = 3.seconds
    fetch_min_bytes: Int = 1
    fetch_max_wait: Duration = 500.ms

  Type OffsetReset:
    variants:
      - Earliest
      - Latest
      - None

  Type AssignmentProtocol:
    variants:
      - Range
      - RoundRobin
      - Sticky
      - CooperativeSticky

  Behavior ConsumerBehavior:
    """Поведение консьюмера"""

    State:
      config: ConsumerConfig
      offsets: Map<(Topic, Int), Int>  # (topic, partition) -> offset
      paused: Set<(Topic, Int)>

    When consumer.subscribe(topics, handler):
      Then:
        - for topic in topics:
            - add topic to subscriptions
        
        - if config.group_id:
            - await join_group()
        - else:
            - assign_all_partitions(topics)
        
        - start consume_loop(handler)

    When consume_loop(handler):
      Then:
        - loop:
            - # Heartbeat
            - if config.group_id:
                - send_heartbeat()
            
            - # Fetch messages
            - records = await fetch_records()
            
            - # Process messages
            - for record in records:
                - try:
                    - await handler(record)
                    - if not config.enable_auto_commit:
                        - mark_for_commit(record)
                  catch error:
                    - handle_processing_error(record, error)
            
            - # Auto commit
            - if config.enable_auto_commit:
                - maybe_commit()

    When consumer.poll(timeout):
      """Manual polling"""
      Then:
        - records = await fetch_records(timeout)
        - return records

    When consumer.commit():
      """Manual commit"""
      Then:
        - await commit_offsets(offsets)

    When consumer.commit_async(callback):
      Then:
        - spawn:
            - result = await commit_offsets(offsets)
            - callback(result)

    When consumer.seek(topic, partition, offset):
      Then:
        - offsets[(topic, partition)] = offset

    When consumer.seek_to_beginning(topic, partition):
      Then:
        - offset = await get_beginning_offset(topic, partition)
        - consumer.seek(topic, partition, offset)

    When consumer.seek_to_end(topic, partition):
      Then:
        - offset = await get_end_offset(topic, partition)
        - consumer.seek(topic, partition, offset)

    When consumer.pause(topic, partition):
      Then:
        - add (topic, partition) to paused

    When consumer.resume(topic, partition):
      Then:
        - remove (topic, partition) from paused

    When join_group():
      Then:
        - # Send JoinGroup request
        - response = await send_join_group(config.group_id)
        
        - if response.leader == consumer.id:
            - # Perform assignment
            - assignments = assign_partitions(response.members, subscriptions)
            - await send_sync_group(assignments)
        - else:
            - # Wait for assignment
            - assignment = await receive_sync_group()
            - apply_assignment(assignment)

    When rebalance():
      Then:
        - emit RebalanceStarted(consumer.id)
        - await commit_offsets(offsets)
        - await join_group()
        - emit RebalanceCompleted(consumer.id, assignments)

  # ==========================================================================
  # EVENT SOURCING
  # ==========================================================================

  Behavior EventSourcing:
    """Event Sourcing паттерн"""

    Type Event:
      id: EventId
      aggregate_id: AggregateId
      aggregate_type: String
      event_type: String
      data: Any
      metadata: EventMetadata
      version: Int
      timestamp: Timestamp

    Type EventMetadata:
      correlation_id: String?
      causation_id: String?
      user_id: String?
      trace_id: String?

    Type EventStore:
      streams: Map<StreamId, EventStream>

    Type EventStream:
      id: StreamId
      events: List<Event>
      version: Int
      metadata: Map<String, Any>

    Type StreamId:
      value: String

    Type Aggregate:
      id: AggregateId
      type: String
      version: Int
      state: Any
      uncommitted_events: List<Event>

    When event_store.append(stream_id, events, expected_version):
      """Append events with optimistic concurrency"""
      Then:
        - stream = streams.get_or_create(stream_id)
        
        - # Check version for optimistic locking
        - if expected_version != AnyVersion:
            - if stream.version != expected_version:
                - raise ConcurrencyError(stream_id, expected_version, stream.version)
        
        - # Append events
        - for event in events:
            - event.version = stream.version + 1
            - add event to stream.events
            - increment stream.version
            - emit EventAppended(stream_id, event)
        
        - return stream.version

    When event_store.read(stream_id, from_version, count):
      Then:
        - stream = streams[stream_id]
        - if not stream:
            - return []
        
        - return stream.events
            .filter(e -> e.version >= from_version)
            .take(count)

    When event_store.read_all(from_position, count):
      """Read all events across streams"""
      Then:
        - all_events = streams.values()
            .flat_map(s -> s.events)
            .sort_by(e -> e.timestamp)
        
        - return all_events.skip(from_position).take(count)

    When event_store.subscribe(stream_id, handler):
      Then:
        - subscription = Subscription(stream_id, handler)
        - add subscription to subscriptions
        - return subscription

    When event_store.subscribe_all(handler):
      Then:
        - subscription = Subscription("$all", handler)
        - add subscription to subscriptions
        - return subscription

    # Aggregate behavior
    When aggregate.apply(event):
      Then:
        - new_state = aggregate.evolve(aggregate.state, event)
        - return aggregate with
            state = new_state,
            version = event.version

    When aggregate.raise_event(event_type, data):
      Then:
        - event = Event(
            id: generate_id(),
            aggregate_id: aggregate.id,
            aggregate_type: aggregate.type,
            event_type: event_type,
            data: data,
            version: aggregate.version + 1,
            timestamp: now()
          )
        - add event to aggregate.uncommitted_events
        - aggregate.apply(event)

    When aggregate.load(aggregate_id):
      Then:
        - stream_id = "${aggregate.type}-${aggregate_id}"
        - events = await event_store.read(stream_id, 0, MaxInt)
        
        - aggregate = Aggregate(
            id: aggregate_id,
            type: aggregate.type,
            version: 0,
            state: aggregate.initial_state()
          )
        
        - for event in events:
            - aggregate = aggregate.apply(event)
        
        - return aggregate

    When aggregate.save():
      Then:
        - if aggregate.uncommitted_events.is_empty():
            - return
        
        - stream_id = "${aggregate.type}-${aggregate.id}"
        - expected_version = aggregate.version - aggregate.uncommitted_events.size
        
        - await event_store.append(
            stream_id,
            aggregate.uncommitted_events,
            expected_version
          )
        
        - clear aggregate.uncommitted_events

  # ==========================================================================
  # CQRS
  # ==========================================================================

  Behavior CQRS:
    """Command Query Responsibility Segregation"""

    Type Command:
      id: CommandId
      type: String
      aggregate_id: AggregateId?
      data: Any
      metadata: CommandMetadata
      timestamp: Timestamp

    Type CommandMetadata:
      user_id: String?
      correlation_id: String?
      expected_version: Int?

    Type CommandResult:
      variants:
        - Success: (events: List<Event>)
        - Failure: (error: CommandError)

    Type CommandError:
      code: String
      message: String
      details: Any?

    Type Query:
      type: String
      params: Map<String, Any>

    Type CommandHandler:
      command_type: String
      handle: (Command, Aggregate) -> CommandResult

    Type QueryHandler:
      query_type: String
      handle: (Query) -> Async<Any>

    Type Projection:
      name: String
      handlers: Map<String, EventHandler>
      state: Any
      position: Int

    Type EventHandler:
      event_type: String
      handle: (Event, ProjectionState) -> ProjectionState

    State:
      command_handlers: Map<String, CommandHandler>
      query_handlers: Map<String, QueryHandler>
      projections: Map<String, Projection>

    When dispatch_command(command):
      Then:
        - handler = command_handlers[command.type]
        - if not handler:
            - return Failure(CommandError("UNKNOWN_COMMAND", "Unknown command type"))
        
        - # Load aggregate
        - aggregate = await load_aggregate(command.aggregate_id)
        
        - # Validate
        - validation = validate_command(command, aggregate)
        - if validation.errors:
            - return Failure(CommandError("VALIDATION_ERROR", validation.errors))
        
        - # Handle command
        - result = handler.handle(command, aggregate)
        
        - match result:
            Success(events) ->
              - await aggregate.save()
              - emit CommandExecuted(command, events)
              - return result
            Failure(error) ->
              - emit CommandFailed(command, error)
              - return result

    When execute_query(query):
      Then:
        - handler = query_handlers[query.type]
        - if not handler:
            - raise UnknownQueryError(query.type)
        
        - result = await handler.handle(query)
        - emit QueryExecuted(query)
        - return result

    When projection.process(event):
      Then:
        - handler = projection.handlers[event.event_type]
        - if handler:
            - projection.state = handler.handle(event, projection.state)
            - projection.position = event.version
            - emit ProjectionUpdated(projection.name, event)

    When rebuild_projection(projection_name):
      Then:
        - projection = projections[projection_name]
        - projection.state = projection.initial_state()
        - projection.position = 0
        
        - events = await event_store.read_all(0, MaxInt)
        - for event in events:
            - projection.process(event)
        
        - emit ProjectionRebuilt(projection_name)

  # ==========================================================================
  # DEAD LETTER QUEUE
  # ==========================================================================

  Behavior DeadLetterQueue:
    """Обработка failed сообщений"""

    Type DeadLetter:
      original_message: Message
      error: String
      failure_count: Int
      first_failure: Timestamp
      last_failure: Timestamp
      source_queue: String

    State:
      messages: List<DeadLetter>
      config: DLQConfig

    Type DLQConfig:
      max_receive_count: Int = 5
      retention: Duration = 14.days
      alarm_threshold: Int = 100

    When move_to_dlq(message, error, source_queue):
      Then:
        - dead_letter = DeadLetter(
            original_message: message,
            error: error,
            failure_count: message.receive_count,
            first_failure: message.first_received,
            last_failure: now(),
            source_queue: source_queue
          )
        
        - add dead_letter to messages
        - emit MessageMovedToDLQ(dead_letter)
        
        - if messages.size >= config.alarm_threshold:
            - emit DLQThresholdExceeded(messages.size)

    When redrive(count):
      """Переотправить сообщения из DLQ"""
      Then:
        - to_redrive = messages.take(count)
        
        - for dead_letter in to_redrive:
            - await send_to_queue(
                dead_letter.source_queue,
                dead_letter.original_message
              )
            - remove dead_letter from messages
            - emit MessageRedriven(dead_letter)

    When purge():
      """Очистить DLQ"""
      Then:
        - count = messages.size
        - clear messages
        - emit DLQPurged(count)

  # ==========================================================================
  # СОБЫТИЯ
  # ==========================================================================

  Events:
    MessagePublished:
      message_id: MessageId
      topic: String
      partition: Int

    MessageConsumed:
      message_id: MessageId
      consumer_id: ConsumerId
      latency: Duration

    MessageFailed:
      message_id: MessageId
      error: String
      retry_count: Int

    MessageMovedToDLQ:
      message_id: MessageId
      source_queue: String
      error: String

    EventAppended:
      stream_id: StreamId
      event_id: EventId
      version: Int

    CommandExecuted:
      command_id: CommandId
      events_count: Int

    CommandFailed:
      command_id: CommandId
      error: String

    ProjectionUpdated:
      projection: String
      position: Int

    RebalanceStarted:
      consumer_id: ConsumerId
      group_id: String

    RebalanceCompleted:
      consumer_id: ConsumerId
      assignments: Map<Topic, List<Int>>

  # ==========================================================================
  # ПРИМЕР ИСПОЛЬЗОВАНИЯ
  # ==========================================================================

  Example "Order Processing with Event Sourcing":
    ```vibee
    # Define aggregate
    Aggregate Order:
      initial_state: () -> { status: "pending", items: [], total: 0 }
      
      evolve: (state, event) ->
        match event.event_type:
          "OrderCreated" ->
            state with
              id = event.data.order_id,
              customer_id = event.data.customer_id,
              status = "created"
          
          "ItemAdded" ->
            state with
              items = state.items + [event.data.item],
              total = state.total + event.data.item.price
          
          "OrderConfirmed" ->
            state with status = "confirmed"
          
          "OrderShipped" ->
            state with
              status = "shipped",
              tracking_number = event.data.tracking_number

    # Command handlers
    CommandHandler CreateOrder:
      command_type: "CreateOrder"
      
      handle: (cmd, aggregate) ->
        if aggregate.version > 0:
          return Failure(CommandError("ORDER_EXISTS", "Order already exists"))
        
        aggregate.raise_event("OrderCreated", {
          order_id: cmd.aggregate_id,
          customer_id: cmd.data.customer_id
        })
        
        Success(aggregate.uncommitted_events)

    CommandHandler AddItem:
      command_type: "AddItem"
      
      handle: (cmd, aggregate) ->
        if aggregate.state.status != "created":
          return Failure(CommandError("INVALID_STATE", "Cannot add items"))
        
        aggregate.raise_event("ItemAdded", {
          item: cmd.data.item
        })
        
        Success(aggregate.uncommitted_events)

    # Projection for read model
    Projection OrderSummary:
      initial_state: () -> { orders: {} }
      
      handlers:
        "OrderCreated": (event, state) ->
          state.orders[event.aggregate_id] = {
            id: event.aggregate_id,
            customer_id: event.data.customer_id,
            status: "created",
            items: [],
            total: 0
          }
          state
        
        "ItemAdded": (event, state) ->
          order = state.orders[event.aggregate_id]
          order.items.push(event.data.item)
          order.total += event.data.item.price
          state
        
        "OrderConfirmed": (event, state) ->
          state.orders[event.aggregate_id].status = "confirmed"
          state

    # Usage
    await dispatch_command(Command(
      type: "CreateOrder",
      aggregate_id: "order-123",
      data: { customer_id: "cust-456" }
    ))

    await dispatch_command(Command(
      type: "AddItem",
      aggregate_id: "order-123",
      data: { item: { sku: "PROD-1", price: 29.99 } }
    ))

    # Query read model
    order = await execute_query(Query(
      type: "GetOrder",
      params: { order_id: "order-123" }
    ))
    ```

  Example "Message Queue Consumer":
    ```vibee
    # Create consumer
    consumer = Consumer(
      config: ConsumerConfig(
        group_id: "order-processors",
        auto_offset_reset: Earliest,
        enable_auto_commit: false
      )
    )

    # Subscribe and process
    await consumer.subscribe(["orders"], async (message) ->
      order = JSON.parse(message.payload)
      
      try:
        await process_order(order)
        await consumer.commit()
      catch error:
        log.error("Failed to process order", error: error)
        # Will be retried or moved to DLQ
        raise error
    )
    ```
