# ============================================================================
# BACKGROUND JOBS - Фоновые задачи и очереди на Vibee
# ============================================================================
# Job queues, workers, scheduling, retries, dead letter queues
# ============================================================================

Specification BackgroundJobs:
  """Фоновые задачи как спецификация асинхронной обработки."""

  # ==========================================================================
  # CORE TYPES
  # ==========================================================================

  Type Job:
    id: JobId
    name: String
    payload: Any
    queue: String
    priority: Priority
    status: JobStatus
    attempts: Int
    max_attempts: Int
    delay: Duration?
    scheduled_at: DateTime?
    started_at: DateTime?
    completed_at: DateTime?
    failed_at: DateTime?
    error: JobError?
    result: Any?
    progress: Float?
    metadata: JobMetadata
    created_at: DateTime

  Type JobStatus:
    variants:
      - Pending
      - Scheduled
      - Active
      - Completed
      - Failed
      - Retrying
      - Cancelled
      - Stalled

  Type Priority:
    variants:
      - Critical = 1
      - High = 2
      - Normal = 3
      - Low = 4

  Type JobError:
    message: String
    stack: String?
    code: String?
    attempt: Int

  Type JobMetadata:
    created_by: String?
    correlation_id: String?
    parent_job_id: JobId?
    tags: List<String>
    custom: Map<String, Any>

  Type JobOptions:
    queue: String = "default"
    priority: Priority = Normal
    delay: Duration?
    scheduled_at: DateTime?
    max_attempts: Int = 3
    backoff: BackoffStrategy = Exponential(1.second, 2.0)
    timeout: Duration = 5.minutes
    remove_on_complete: Boolean = false
    remove_on_fail: Boolean = false
    unique: UniqueConstraint?
    depends_on: List<JobId>?

  Type BackoffStrategy:
    variants:
      - Fixed: Duration
      - Linear: (initial: Duration, increment: Duration)
      - Exponential: (initial: Duration, multiplier: Float)
      - Custom: (attempt: Int) -> Duration

  Type UniqueConstraint:
    key: String
    duration: Duration?

  # ==========================================================================
  # QUEUE
  # ==========================================================================

  Behavior Queue:
    When queue.create(name, options):
      Then:
        - return Queue(name, options)

    Type Queue:
      name: String
      options: QueueOptions
      workers: List<Worker>
      handlers: Map<String, JobHandler>

      Method add(job_name, payload, options) -> Job:
        job = Job(
          id: generate_job_id(),
          name: job_name,
          payload: payload,
          queue: name,
          priority: options.priority ?? Normal,
          status: if options.delay or options.scheduled_at then Scheduled else Pending,
          attempts: 0,
          max_attempts: options.max_attempts ?? self.options.default_max_attempts,
          delay: options.delay,
          scheduled_at: options.scheduled_at ?? (if options.delay then now() + options.delay else null),
          metadata: JobMetadata(
            correlation_id: options.correlation_id,
            tags: options.tags ?? []
          ),
          created_at: now()
        )
        
        # Check unique constraint
        if options.unique:
          existing = await find_job_by_unique_key(options.unique.key)
          if existing and existing.status in [Pending, Scheduled, Active]:
            return existing
        
        await store_job(job)
        emit JobAdded(job)
        return job

      Method add_bulk(jobs: List<(String, Any, JobOptions)>) -> List<Job>:
        created = []
        for (name, payload, options) in jobs:
          job = await add(name, payload, options)
          created.push(job)
        return created

      Method process(job_name, handler, options):
        handlers[job_name] = handler
        
        # Start workers if not already running
        if workers.length == 0:
          start_workers(options.concurrency ?? self.options.concurrency)

      Method pause():
        for worker in workers:
          worker.pause()

      Method resume():
        for worker in workers:
          worker.resume()

      Method close():
        for worker in workers:
          await worker.stop()
        workers.clear()

      Method get_job(id: JobId) -> Job?:
        return await load_job(id)

      Method get_jobs(status: JobStatus?, limit: Int = 100) -> List<Job>:
        return await query_jobs(name, status, limit)

      Method remove_job(id: JobId):
        await delete_job(id)

      Method retry_job(id: JobId):
        job = await load_job(id)
        if job.status == Failed:
          job.status = Pending
          job.attempts = 0
          job.error = null
          await store_job(job)

      Method cancel_job(id: JobId):
        job = await load_job(id)
        if job.status in [Pending, Scheduled]:
          job.status = Cancelled
          await store_job(job)
          emit JobCancelled(job)

      Method clean(grace_period: Duration, status: JobStatus?):
        cutoff = now() - grace_period
        await delete_jobs_before(name, cutoff, status)

      Method on(event, handler):
        event_handlers[event] = handler

    Type QueueOptions:
      concurrency: Int = 1
      default_max_attempts: Int = 3
      default_timeout: Duration = 5.minutes
      rate_limit: RateLimit?
      stalled_interval: Duration = 30.seconds
      metrics_interval: Duration = 5.seconds

    Type RateLimit:
      max: Int
      duration: Duration

  # ==========================================================================
  # WORKER
  # ==========================================================================

  Behavior Worker:
    Type Worker:
      id: WorkerId
      queue: Queue
      status: WorkerStatus
      current_job: Job?
      processed: Int = 0
      failed: Int = 0

      Method start():
        status = Running
        spawn process_loop()

      Method pause():
        status = Paused

      Method resume():
        status = Running

      Method stop():
        status = Stopped
        if current_job:
          # Return job to queue
          await requeue_job(current_job)

      Method process_loop():
        while status != Stopped:
          if status == Paused:
            await sleep(100.ms)
            continue
          
          # Check rate limit
          if queue.options.rate_limit:
            await wait_for_rate_limit(queue.options.rate_limit)
          
          # Get next job
          job = await get_next_job(queue.name)
          
          if job == null:
            await sleep(100.ms)
            continue
          
          current_job = job
          await process_job(job)
          current_job = null

      Method process_job(job: Job):
        handler = queue.handlers[job.name]
        
        if handler == null:
          log.error("No handler for job: ${job.name}")
          await fail_job(job, Error("No handler registered"))
          return
        
        job.status = Active
        job.started_at = now()
        job.attempts += 1
        await store_job(job)
        emit JobStarted(job)
        
        try:
          # Create job context
          ctx = JobContext(
            job: job,
            worker: self,
            update_progress: async (progress) -> {
              job.progress = progress
              await store_job(job)
              emit JobProgress(job, progress)
            },
            log: create_job_logger(job)
          )
          
          # Execute with timeout
          result = await with_timeout(
            handler(job.payload, ctx),
            job.metadata.timeout ?? queue.options.default_timeout
          )
          
          # Success
          job.status = Completed
          job.completed_at = now()
          job.result = result
          await store_job(job)
          
          processed += 1
          emit JobCompleted(job, result)
          
          # Remove if configured
          if job.metadata.remove_on_complete:
            await delete_job(job.id)
        
        catch error:
          await handle_job_error(job, error)

      Method handle_job_error(job: Job, error: Error):
        job.error = JobError(
          message: error.message,
          stack: error.stack,
          attempt: job.attempts
        )
        
        failed += 1
        emit JobFailed(job, error)
        
        if job.attempts < job.max_attempts:
          # Retry with backoff
          delay = calculate_backoff(job.attempts, job.metadata.backoff)
          job.status = Retrying
          job.scheduled_at = now() + delay
          await store_job(job)
          emit JobRetrying(job, delay)
        else:
          # Move to failed
          job.status = Failed
          job.failed_at = now()
          await store_job(job)
          
          # Move to dead letter queue if configured
          if queue.options.dead_letter_queue:
            await move_to_dlq(job, queue.options.dead_letter_queue)
          
          # Remove if configured
          if job.metadata.remove_on_fail:
            await delete_job(job.id)

    Type WorkerStatus:
      variants: [Running, Paused, Stopped]

    Type JobContext:
      job: Job
      worker: Worker
      update_progress: (Float) -> Promise<Void>
      log: Logger

    Type JobHandler:
      (payload: Any, context: JobContext) -> Promise<Any>

  # ==========================================================================
  # SCHEDULER
  # ==========================================================================

  Behavior Scheduler:
    When scheduler.create(options):
      Then:
        - return Scheduler(options)

    Type Scheduler:
      jobs: Map<String, ScheduledJob>
      running: Boolean = false

      Method schedule(name, cron, handler, options) -> ScheduledJob:
        scheduled = ScheduledJob(
          name: name,
          cron: parse_cron(cron),
          handler: handler,
          options: options,
          next_run: calculate_next_run(cron),
          enabled: true
        )
        jobs[name] = scheduled
        return scheduled

      Method every(interval: Duration, handler, options) -> ScheduledJob:
        return schedule(
          options.name ?? generate_name(),
          interval_to_cron(interval),
          handler,
          options
        )

      Method at(time: Time, handler, options) -> ScheduledJob:
        cron = "${time.minute} ${time.hour} * * *"
        return schedule(options.name ?? generate_name(), cron, handler, options)

      Method start():
        running = true
        spawn scheduler_loop()

      Method stop():
        running = false

      Method scheduler_loop():
        while running:
          now_time = now()
          
          for job in jobs.values():
            if job.enabled and job.next_run <= now_time:
              spawn run_scheduled_job(job)
              job.last_run = now_time
              job.next_run = calculate_next_run(job.cron, now_time)
          
          await sleep(1.second)

      Method run_scheduled_job(job: ScheduledJob):
        try:
          emit ScheduledJobStarted(job)
          await job.handler()
          emit ScheduledJobCompleted(job)
        catch error:
          emit ScheduledJobFailed(job, error)
          
          if job.options.retry_on_fail:
            # Retry logic

      Method enable(name: String):
        jobs[name]?.enabled = true

      Method disable(name: String):
        jobs[name]?.enabled = false

      Method remove(name: String):
        jobs.delete(name)

      Method get_next_runs(count: Int = 10) -> List<(String, DateTime)>:
        runs = []
        for job in jobs.values():
          if job.enabled:
            next_runs = calculate_next_runs(job.cron, count)
            for run in next_runs:
              runs.push((job.name, run))
        return runs.sort_by((_, time) -> time).take(count)

    Type ScheduledJob:
      name: String
      cron: CronExpression
      handler: () -> Promise<Void>
      options: ScheduleOptions
      next_run: DateTime
      last_run: DateTime?
      enabled: Boolean

    Type ScheduleOptions:
      name: String?
      timezone: String?
      retry_on_fail: Boolean = false
      max_retries: Int = 3
      overlap: Boolean = false

    Type CronExpression:
      minute: CronField
      hour: CronField
      day_of_month: CronField
      month: CronField
      day_of_week: CronField

    Type CronField:
      variants:
        - Any
        - Value: Int
        - Range: (start: Int, end: Int)
        - Step: (base: CronField, step: Int)
        - List: List<CronField>

  # ==========================================================================
  # FLOW / PIPELINES
  # ==========================================================================

  Behavior JobFlows:
    When flow.create(name):
      Then:
        - return FlowBuilder(name)

    Type FlowBuilder:
      name: String
      steps: List<FlowStep>

      Method add(job_name, payload_fn, options) -> FlowBuilder:
        steps.push(FlowStep(
          type: Job,
          job_name: job_name,
          payload_fn: payload_fn,
          options: options
        ))
        return self

      Method parallel(jobs: List<(String, PayloadFn, JobOptions)>) -> FlowBuilder:
        steps.push(FlowStep(
          type: Parallel,
          jobs: jobs
        ))
        return self

      Method condition(predicate, then_steps, else_steps) -> FlowBuilder:
        steps.push(FlowStep(
          type: Condition,
          predicate: predicate,
          then_steps: then_steps,
          else_steps: else_steps
        ))
        return self

      Method build() -> Flow:
        return Flow(name, steps)

    Type Flow:
      name: String
      steps: List<FlowStep>

      Method run(initial_data: Any, queue: Queue) -> FlowExecution:
        execution = FlowExecution(
          id: generate_flow_id(),
          flow: self,
          status: Running,
          data: initial_data,
          step_index: 0,
          created_at: now()
        )
        
        spawn execute_flow(execution, queue)
        return execution

    Type FlowStep:
      variants:
        - Job: (job_name: String, payload_fn: PayloadFn, options: JobOptions)
        - Parallel: List<(String, PayloadFn, JobOptions)>
        - Condition: (predicate: Predicate, then_steps: List<FlowStep>, else_steps: List<FlowStep>)

    Type FlowExecution:
      id: FlowId
      flow: Flow
      status: FlowStatus
      data: Any
      step_index: Int
      results: List<Any>
      created_at: DateTime
      completed_at: DateTime?

    Type FlowStatus:
      variants: [Running, Completed, Failed, Cancelled]

    When execute_flow(execution, queue):
      Then:
        - for step in execution.flow.steps:
            - match step:
                Job(job_name, payload_fn, options) ->
                  payload = payload_fn(execution.data, execution.results)
                  job = await queue.add(job_name, payload, options)
                  result = await wait_for_job(job)
                  execution.results.push(result)
                  execution.data = result
                
                Parallel(jobs) ->
                  job_promises = jobs.map((name, payload_fn, opts) -> {
                    payload = payload_fn(execution.data, execution.results)
                    job = await queue.add(name, payload, opts)
                    return wait_for_job(job)
                  })
                  results = await Promise.all(job_promises)
                  execution.results.push(results)
                
                Condition(predicate, then_steps, else_steps) ->
                  if predicate(execution.data, execution.results):
                    await execute_steps(then_steps, execution, queue)
                  else:
                    await execute_steps(else_steps, execution, queue)
            
            - execution.step_index += 1
        
        - execution.status = Completed
        - execution.completed_at = now()

  # ==========================================================================
  # MONITORING
  # ==========================================================================

  Behavior Monitoring:
    When queue.get_metrics() -> QueueMetrics:
      Then:
        - return QueueMetrics(
            waiting: await count_jobs(queue.name, Pending),
            active: await count_jobs(queue.name, Active),
            completed: await count_jobs(queue.name, Completed),
            failed: await count_jobs(queue.name, Failed),
            delayed: await count_jobs(queue.name, Scheduled),
            paused: queue.workers.all(w -> w.status == Paused)
          )

    Type QueueMetrics:
      waiting: Int
      active: Int
      completed: Int
      failed: Int
      delayed: Int
      paused: Boolean

    When queue.get_worker_metrics() -> List<WorkerMetrics>:
      Then:
        - return queue.workers.map(w -> WorkerMetrics(
            id: w.id,
            status: w.status,
            current_job: w.current_job?.id,
            processed: w.processed,
            failed: w.failed
          ))

    Type WorkerMetrics:
      id: WorkerId
      status: WorkerStatus
      current_job: JobId?
      processed: Int
      failed: Int

  # ==========================================================================
  # EXAMPLE
  # ==========================================================================

  Example "Background Jobs":
    ```vibee
    # Create queue
    email_queue = queue.create("emails", {
      concurrency: 5,
      rate_limit: { max: 100, duration: 1.minute }
    })

    # Define job handlers
    email_queue.process("send_email", async (payload, ctx) -> {
      ctx.log.info("Sending email to ${payload.to}")
      
      ctx.update_progress(0.1)
      template = await load_template(payload.template)
      
      ctx.update_progress(0.5)
      html = render_template(template, payload.data)
      
      ctx.update_progress(0.8)
      await smtp.send({
        to: payload.to,
        subject: payload.subject,
        html: html
      })
      
      ctx.update_progress(1.0)
      return { sent: true, timestamp: now() }
    }, {
      timeout: 30.seconds
    })

    email_queue.process("send_bulk_email", async (payload, ctx) -> {
      total = payload.recipients.length
      
      for (i, recipient) in payload.recipients.enumerate():
        await email_queue.add("send_email", {
          to: recipient,
          template: payload.template,
          data: payload.data
        })
        ctx.update_progress(i / total)
      
      return { queued: total }
    })

    # Add jobs
    job = await email_queue.add("send_email", {
      to: "user@example.com",
      subject: "Welcome!",
      template: "welcome",
      data: { name: "John" }
    }, {
      priority: High,
      max_attempts: 5,
      backoff: Exponential(1.second, 2.0)
    })

    # Add delayed job
    await email_queue.add("send_email", {
      to: "user@example.com",
      subject: "Reminder",
      template: "reminder"
    }, {
      delay: 1.hour
    })

    # Add scheduled job
    await email_queue.add("send_email", {
      to: "user@example.com",
      subject: "Daily Report"
    }, {
      scheduled_at: tomorrow_at(9, 0)
    })

    # Event handlers
    email_queue.on("completed", (job, result) -> {
      log.info("Job ${job.id} completed: ${result}")
    })

    email_queue.on("failed", (job, error) -> {
      log.error("Job ${job.id} failed: ${error.message}")
      alert.send("Job failed: ${job.name}")
    })

    # Scheduler
    scheduler = scheduler.create()

    scheduler.schedule("daily_report", "0 9 * * *", async () -> {
      report = await generate_daily_report()
      await email_queue.add("send_bulk_email", {
        recipients: await get_admin_emails(),
        template: "daily_report",
        data: report
      })
    })

    scheduler.every(5.minutes, async () -> {
      await cleanup_expired_sessions()
    }, { name: "session_cleanup" })

    scheduler.start()

    # Job flow
    order_flow = flow.create("process_order")
      .add("validate_order", (data) -> data.order)
      .add("charge_payment", (data, results) -> {
        order: results[0],
        payment_method: data.payment_method
      })
      .parallel([
        ("send_confirmation", (data, results) -> { order: results[0], email: data.email }),
        ("update_inventory", (data, results) -> { items: results[0].items }),
        ("notify_warehouse", (data, results) -> { order: results[0] })
      ])
      .add("complete_order", (data, results) -> { order_id: results[0].id })
      .build()

    execution = await order_flow.run({
      order: order_data,
      payment_method: "card",
      email: "customer@example.com"
    }, order_queue)

    # Monitor
    metrics = await email_queue.get_metrics()
    log.info("Queue status: ${metrics.waiting} waiting, ${metrics.active} active")
    ```
