#!/bin/bash
# Download SWE-bench Lite dataset
# Ï†Â² + 1/Ï†Â² = 3 | PHOENIX = 999

set -e

DATASET_DIR="data/swe_bench"
LITE_URL="https://huggingface.co/datasets/princeton-nlp/SWE-bench_Lite/resolve/main/data/test-00000-of-00001.parquet"

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "                    SWE-bench Lite Dataset Downloader"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Create data directory
mkdir -p "$DATASET_DIR"

echo "ðŸ“¥ Downloading SWE-bench Lite (300 instances)..."

# Download using curl
if command -v curl &> /dev/null; then
    curl -L -o "$DATASET_DIR/swe_bench_lite.parquet" "$LITE_URL"
elif command -v wget &> /dev/null; then
    wget -O "$DATASET_DIR/swe_bench_lite.parquet" "$LITE_URL"
else
    echo "âŒ Error: curl or wget required"
    exit 1
fi

echo ""
echo "âœ… Downloaded to: $DATASET_DIR/swe_bench_lite.parquet"
echo ""

# Check file size
FILE_SIZE=$(ls -lh "$DATASET_DIR/swe_bench_lite.parquet" | awk '{print $5}')
echo "ðŸ“Š File size: $FILE_SIZE"

# Convert to JSON if Python available
if command -v python3 &> /dev/null; then
    echo ""
    echo "ðŸ”„ Converting to JSON..."
    
    python3 << 'EOF'
import json
import sys

try:
    import pandas as pd
    df = pd.read_parquet("data/swe_bench/swe_bench_lite.parquet")
    
    # Convert to list of dicts
    instances = df.to_dict(orient='records')
    
    # Save as JSON
    with open("data/swe_bench/swe_bench_lite.json", "w") as f:
        json.dump(instances, f, indent=2, default=str)
    
    print(f"âœ… Converted {len(instances)} instances to JSON")
    print(f"ðŸ“ Output: data/swe_bench/swe_bench_lite.json")
    
    # Print sample repos
    repos = df['repo'].unique()
    print(f"\nðŸ“¦ Repositories ({len(repos)}):")
    for repo in repos[:10]:
        count = len(df[df['repo'] == repo])
        print(f"   - {repo}: {count} instances")
        
except ImportError:
    print("âš ï¸  pandas/pyarrow not installed, skipping JSON conversion")
    print("   Install with: pip install pandas pyarrow")
except Exception as e:
    print(f"âŒ Error: {e}")
    sys.exit(1)
EOF
fi

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "                         DOWNLOAD COMPLETE"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Next steps:"
echo "  1. Run benchmark: vibee bench run --dataset lite --limit 5"
echo "  2. View results:  vibee bench report"
echo ""
echo "Ï†Â² + 1/Ï†Â² = 3 | PHOENIX = 999"
