// ═══════════════════════════════════════════════════════════════
// GRADIENT COMPRESSION - For Federated Learning
// Based on: Lin et al. "Deep Gradient Compression" (ICLR 2018)
// 100-1000x communication reduction
// ═══════════════════════════════════════════════════════════════

Ⲯ ⲕⲟⲣⲉ
Ⲯ ⲧⲣⲓⲛⲓⲧⲩ

⬢ CompressionMethod { TOPK, RANDOM_K, TERNARY, QSGD }

Ⲏ GradientCompressor {
    Ⲃ method: CompressionMethod
    Ⲃ ratio: Ⲫⲗⲟⲁⲧ
    Ⲃ error_feedback: [Ⲫⲗⲟⲁⲧ]
    
    Ⲫ new(Ⲁ method: CompressionMethod, Ⲁ ratio: Ⲫⲗⲟⲁⲧ) → GradientCompressor {
        Ⲣ GradientCompressor { method: method, ratio: ratio, error_feedback: [] }
    }
    
    Ⲫ compress(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → CompressedGradient {
        Ⲉ Ⲥ.method == CompressionMethod.TOPK {
            Ⲣ Ⲥ.topk_compress(grad)
        } Ⲱ Ⲉ Ⲥ.method == CompressionMethod.TERNARY {
            Ⲣ Ⲥ.ternary_compress(grad)
        } Ⲱ Ⲉ Ⲥ.method == CompressionMethod.QSGD {
            Ⲣ Ⲥ.qsgd_compress(grad)
        }
        Ⲣ Ⲥ.topk_compress(grad)
    }
    
    Ⲫ topk_compress(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → CompressedGradient {
        Ⲃ k = (grad.len() * Ⲥ.ratio).floor()
        Ⲃ indexed: [(Ⲓⲛⲧ, Ⲫⲗⲟⲁⲧ)] = []
        Ⲝ i, g ∈ grad.enumerate() { indexed.push((i, abs(g))) }
        indexed = indexed.sort_by(Ⲫⲛ(a, b) { Ⲣ b.1 - a.1 })
        
        Ⲃ indices: [Ⲓⲛⲧ] = []
        Ⲃ values: [Ⲫⲗⲟⲁⲧ] = []
        Ⲝ i ∈ 0..k {
            indices.push(indexed[i].0)
            values.push(grad[indexed[i].0])
        }
        
        Ⲣ CompressedGradient { indices: indices, values: values, size: grad.len() }
    }
    
    Ⲫ ternary_compress(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → CompressedGradient {
        Ⲃ threshold = Ⲥ.compute_threshold(grad)
        Ⲃ scale = Ⲥ.compute_scale(grad, threshold)
        
        Ⲃ indices: [Ⲓⲛⲧ] = []
        Ⲃ signs: [Trit] = []
        
        Ⲝ i, g ∈ grad.enumerate() {
            Ⲉ g > threshold {
                indices.push(i)
                signs.push(△)
            } Ⲱ Ⲉ g < -threshold {
                indices.push(i)
                signs.push(▽)
            }
        }
        
        Ⲣ CompressedGradient {
            indices: indices,
            ternary_values: signs,
            scale: scale,
            size: grad.len()
        }
    }
    
    Ⲫ qsgd_compress(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → CompressedGradient {
        Ⲃ norm = 0.0
        Ⲝ g ∈ grad { norm += g * g }
        norm = sqrt(norm)
        
        Ⲃ levels = 256
        Ⲃ quantized: [Ⲓⲛⲧ] = []
        
        Ⲝ g ∈ grad {
            Ⲃ normalized = abs(g) / norm
            Ⲃ level = (normalized * levels).floor()
            Ⲃ sign = g >= 0 ? 1 : -1
            quantized.push(sign * level)
        }
        
        Ⲣ CompressedGradient { quantized_values: quantized, norm: norm, size: grad.len() }
    }
    
    Ⲫ compute_threshold(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → Ⲫⲗⲟⲁⲧ {
        Ⲃ abs_grad: [Ⲫⲗⲟⲁⲧ] = grad.map(Ⲫⲛ(g) { Ⲣ abs(g) })
        abs_grad = abs_grad.sort()
        Ⲃ k = ((1.0 - Ⲥ.ratio) * grad.len()).floor()
        Ⲣ abs_grad[k]
    }
    
    Ⲫ compute_scale(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ], Ⲁ threshold: Ⲫⲗⲟⲁⲧ) → Ⲫⲗⲟⲁⲧ {
        Ⲃ sum = 0.0
        Ⲃ count = 0
        Ⲝ g ∈ grad {
            Ⲉ abs(g) > threshold { sum += abs(g); count += 1 }
        }
        Ⲣ count > 0 ? sum / count : 1.0
    }
}

Ⲏ CompressedGradient {
    Ⲃ indices: [Ⲓⲛⲧ] = []
    Ⲃ values: [Ⲫⲗⲟⲁⲧ] = []
    Ⲃ ternary_values: [Trit] = []
    Ⲃ quantized_values: [Ⲓⲛⲧ] = []
    Ⲃ scale: Ⲫⲗⲟⲁⲧ = 1.0
    Ⲃ norm: Ⲫⲗⲟⲁⲧ = 1.0
    Ⲃ size: Ⲓⲛⲧ
    
    Ⲫ decompress(Ⲥ) → [Ⲫⲗⲟⲁⲧ] {
        Ⲃ result: [Ⲫⲗⲟⲁⲧ] = [0.0; Ⲥ.size]
        
        Ⲉ Ⲥ.values.len() > 0 {
            Ⲝ i, idx ∈ Ⲥ.indices.enumerate() {
                result[idx] = Ⲥ.values[i]
            }
        } Ⲱ Ⲉ Ⲥ.ternary_values.len() > 0 {
            Ⲝ i, idx ∈ Ⲥ.indices.enumerate() {
                Ⲃ t = Ⲥ.ternary_values[i]
                result[idx] = t == △ ? Ⲥ.scale : (t == ▽ ? -Ⲥ.scale : 0.0)
            }
        } Ⲱ Ⲉ Ⲥ.quantized_values.len() > 0 {
            Ⲝ i, q ∈ Ⲥ.quantized_values.enumerate() {
                result[i] = (q / 256.0) * Ⲥ.norm
            }
        }
        
        Ⲣ result
    }
    
    Ⲫ compression_ratio(Ⲥ) → Ⲫⲗⲟⲁⲧ {
        Ⲃ original_bits = Ⲥ.size * 32
        Ⲃ compressed_bits = Ⲥ.indices.len() * 32 + Ⲥ.values.len() * 32
        Ⲉ Ⲥ.ternary_values.len() > 0 {
            compressed_bits = Ⲥ.indices.len() * 32 + Ⲥ.ternary_values.len() * 2 + 32
        }
        Ⲣ original_bits / compressed_bits
    }
}

Ⲏ ErrorFeedback {
    Ⲃ accumulated: [Ⲫⲗⲟⲁⲧ]
    
    Ⲫ new(Ⲁ size: Ⲓⲛⲧ) → ErrorFeedback {
        Ⲣ ErrorFeedback { accumulated: [0.0; size] }
    }
    
    Ⲫ apply(Ⲥ, Ⲁ grad: [Ⲫⲗⲟⲁⲧ]) → [Ⲫⲗⲟⲁⲧ] {
        Ⲃ result: [Ⲫⲗⲟⲁⲧ] = []
        Ⲝ i, g ∈ grad.enumerate() {
            result.push(g + Ⲥ.accumulated[i])
        }
        Ⲣ result
    }
    
    Ⲫ update(Ⲥ, Ⲁ original: [Ⲫⲗⲟⲁⲧ], Ⲁ compressed: CompressedGradient) {
        Ⲃ decompressed = compressed.decompress()
        Ⲝ i ∈ 0..original.len() {
            Ⲥ.accumulated[i] = original[i] - decompressed[i]
        }
    }
}

⊡ test "topk_compression" {
    Ⲃ compressor = GradientCompressor.new(CompressionMethod.TOPK, 0.1)
    Ⲃ grad = [0.1, 0.5, 0.01, 0.8, 0.02, 0.3, 0.001, 0.9, 0.05, 0.4]
    Ⲃ compressed = compressor.compress(grad)
    ⊜! compressed.indices.len() == 1
}

⊡ test "ternary_compression" {
    Ⲃ compressor = GradientCompressor.new(CompressionMethod.TERNARY, 0.1)
    Ⲃ grad = [0.1, -0.5, 0.01, 0.8, -0.02]
    Ⲃ compressed = compressor.compress(grad)
    ⊜! compressed.compression_ratio() > 1.0
}
