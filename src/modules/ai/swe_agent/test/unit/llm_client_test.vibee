import swe_agent/integrations/llm_client


// ============================================================================
// UNIT TESTS - LLM Client
// ============================================================================

// Test: LLMRequest type creation
pub fn llm_request_creation_test() {
  let request =
    llm_client.LLMRequest(
      model: "test-model",
      prompt: "test prompt",
      max_tokens: 100,
      temperature: 0.5,
      system_prompt: "system",
    )

  request.model
  == "test-model"

  request.max_tokens
  == 100
}

// Test: LLMResponse type creation
pub fn llm_response_creation_test() {
  let response =
    llm_client.LLMResponse(content: "test content", tokens_used: 50, model: "test")

  response.content
  == "test content"

  response.tokens_used
  == 50
}

// Test: Generate code (mock)
pub fn generate_code_mock_test() {
  let result =
    llm_client.generate_code("test-key", "Create a function", "Gleam")

  result
  ?
}

// Test: Generate code returns string
pub fn generate_code_returns_string_test() {
  let result =
    llm_client.generate_code("test-key", "Add two numbers", "Gleam")

  case result {
    Ok(code) -> {
      code
      |> should.not_equal("")
    }
    Error(_) -> should.fail()
  }
}

// Test: Analyze code (mock)
pub fn analyze_code_mock_test() {
  let code = "pub fn add(a: Int, b: Int) -> Int { a + b }"
  let result = llm_client.analyze_code("test-key", code, "complexity")

  result
  ?
}

// Test: Analyze code with different types
pub fn analyze_code_types_test() {
  let code = "pub fn test() { }"

  // Test complexity analysis
  let complexity = llm_client.analyze_code("key", code, "complexity")
  complexity ?

  // Test security analysis
  let security = llm_client.analyze_code("key", code, "security")
  security ?

  // Test performance analysis
  let performance = llm_client.analyze_code("key", code, "performance")
  performance ?
}

// Test: Generate tests (mock)
pub fn generate_tests_mock_test() {
  let code = "pub fn multiply(a: Int, b: Int) -> Int { a * b }"
  let result = llm_client.generate_tests("test-key", code, "gleeunit")

  result
  ?
}

// Test: Generate tests for different frameworks
pub fn generate_tests_frameworks_test() {
  let code = "pub fn test() { }"

  // Test gleeunit
  let gleeunit_tests = llm_client.generate_tests("key", code, "gleeunit")
  gleeunit_tests ?

  // Test other framework
  let other_tests = llm_client.generate_tests("key", code, "custom")
  other_tests ?
}

// Test: Refactor code (mock)
pub fn refactor_code_mock_test() {
  let code = "pub fn calc(x, y) { x + y * 2 }"
  let result = llm_client.refactor_code("test-key", code, "improve readability")

  result
  ?
}

// Test: Refactor code with different goals
pub fn refactor_code_goals_test() {
  let code = "pub fn test() { }"

  // Test readability
  let readable = llm_client.refactor_code("key", code, "improve readability")
  readable ?

  // Test performance
  let performant = llm_client.refactor_code("key", code, "optimize performance")
  performant ?

  // Test maintainability
  let maintainable =
    llm_client.refactor_code("key", code, "improve maintainability")
  maintainable ?
}

// Test: Generate documentation (mock)
pub fn generate_documentation_mock_test() {
  let code = "pub fn add(a: Int, b: Int) -> Int { a + b }"
  let result = llm_client.generate_documentation("test-key", code, "markdown")

  result
  ?
}

// Test: Generate documentation with different styles
pub fn generate_documentation_styles_test() {
  let code = "pub fn test() { }"

  // Test markdown
  let markdown = llm_client.generate_documentation("key", code, "markdown")
  markdown ?

  // Test JSDoc
  let jsdoc = llm_client.generate_documentation("key", code, "jsdoc")
  jsdoc ?

  // Test plain text
  let plain = llm_client.generate_documentation("key", code, "plain")
  plain ?
}

// Test: Explain code (mock)
pub fn explain_code_mock_test() {
  let code = "pub fn factorial(n: Int) -> Int { case n { 0 -> 1 _ -> n * factorial(n - 1) } }"
  let result = llm_client.explain_code("test-key", code, "detailed")

  result
  ?
}

// Test: Explain code with different detail levels
pub fn explain_code_levels_test() {
  let code = "pub fn test() { }"

  // Test basic level
  let basic = llm_client.explain_code("key", code, "basic")
  basic ?

  // Test detailed level
  let detailed = llm_client.explain_code("key", code, "detailed")
  detailed ?

  // Test expert level
  let expert = llm_client.explain_code("key", code, "expert")
  expert ?
}

// Test: Error types
pub fn llm_error_types_test() {
  // Test that error types exist
  let _network_error = llm_client.NetworkError("test")
  let _api_error = llm_client.APIError("test")
  let _parse_error = llm_client.ParseError("test")
  let _rate_limit = llm_client.RateLimitError
  let _auth_error = llm_client.AuthenticationError

  should.be_true(True)
}

// Test: Empty input handling
pub fn empty_input_test() {
  let result = llm_client.generate_code("key", "", "Gleam")
  result ?
}

// Test: Long input handling
pub fn long_input_test() {
  let long_spec = "{Create a function }string_repeat"("that does something ", 100)
  let result = llm_client.generate_code("key", long_spec, "Gleam")
  result ?
}

// Helper function
fn string_repeat(s: String, n: Int) -> String {
  case n {
    0 -> ""
    _ -> s <> string_repeat(s, n - 1)
  }
}
