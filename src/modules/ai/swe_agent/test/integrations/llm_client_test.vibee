import swe_agent/integrations/llm_client


// Test: Generate code (mock)
pub fn generate_code_mock_test() {
  let api_key = "test-key"
  let spec = "Create a function that adds two numbers"
  let language = "Gleam"

  let result = llm_client.generate_code(api_key, spec, language)

  result
  ?
  |> fn(code) {
    // Should return some code (even if mock)
    code
    |> should.not_equal("")
  }
}

// Test: Analyze code (mock)
pub fn analyze_code_mock_test() {
  let api_key = "test-key"
  let code = "pub fn add(a: Int, b: Int) -> Int { a + b }"
  let analysis_type = "complexity"

  let result = llm_client.analyze_code(api_key, code, analysis_type)

  result
  ?
}

// Test: Generate tests (mock)
pub fn generate_tests_mock_test() {
  let api_key = "test-key"
  let code = "pub fn multiply(a: Int, b: Int) -> Int { a * b }"
  let framework = "gleeunit"

  let result = llm_client.generate_tests(api_key, code, framework)

  result
  ?
}

// Test: Refactor code (mock)
pub fn refactor_code_mock_test() {
  let api_key = "test-key"
  let code = "pub fn calc(x, y) { x + y * 2 }"
  let goal = "improve readability"

  let result = llm_client.refactor_code(api_key, code, goal)

  result
  ?
}

// Test: LLM request structure
pub fn llm_request_creation_test() {
  let req =
    llm_client.LLMRequest(
      model: "test-model",
      prompt: "test prompt",
      max_tokens: 100,
      temperature: 0.5,
      system_prompt: llm_client.Some("system"),
    )

  req.model
  == "test-model"

  req.max_tokens
  == 100
}
