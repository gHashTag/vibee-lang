{
  "name": "llm",
  "version": "1.0.0",
  "description": "LLM provider integration (OpenAI, Anthropic, local models)",
  "category": "ai",
  "depends_on": ["event", "context"],
  "exports": [
    "complete",
    "stream_complete",
    "embed",
    "count_tokens",
    "create_chat",
    "LLMConfig",
    "ChatMessage",
    "CompletionResult"
  ],
  "commands": ["llm.complete", "llm.embed", "llm.stream"],
  "events": {
    "emits": ["llm.response", "llm.error"],
    "listens": []
  }
}