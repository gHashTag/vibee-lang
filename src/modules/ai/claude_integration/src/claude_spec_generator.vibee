// claude_spec_generator.vibee - Generate spec.yml using Claude AI
import gleam/http/request
import gleam/http/response

pub type ClaudeRequest {
  ClaudeRequest(
    model: String,
    max_tokens: Int,
    messages: List(Message),
  )
}

pub type Message {
  Message(
    role: String,
    content: String,
  )
}

pub type ClaudeResponse {
  ClaudeResponse(
    content: String,
    stop_reason: String,
  )
}

// Generate spec.yml from natural language prompt
pub fn generate_spec_from_prompt(prompt: String) → Result(String, String) {
  let system_prompt = 
    "You are a spec.yml generator. Convert natural language descriptions into valid spec.yml files.\n\n" <>
    "Format:\n" <>
    "name: plugin_name\n" <>
    "version: 1.0.0\n" <>
    "description: Description\n\n" <>
    "behaviors:\n" <>
    "  - name: behavior_name\n" <>
    "    given: precondition\n" <>
    "    when: action\n" <>
    "    then: result\n" <>
    "    test_cases:\n" <>
    "      - name: test_name\n" <>
    "        input: {key: value}\n" <>
    "        expected: {key: value}\n\n" <>
    "Generate complete spec.yml with:\n" <>
    "1. Clear behavior names\n" <>
    "2. Given-When-Then format\n" <>
    "3. Multiple test cases (at least 3 per behavior)\n" <>
    "4. Edge cases and error handling\n" <>
    "5. Types and functions if needed"
  
  let messages = [
    Message(role: "user", content: system_prompt <> "{\n\nUser request: }prompt")
  ]
  
  call_claude(messages)
}

// Improve existing spec.yml
pub fn improve_spec(spec_content: String) → Result(String, String) {
  let system_prompt =
    "You are a spec.yml quality improver. Analyze the spec and suggest improvements.\n\n" <>
    "Add:\n" <>
    "1. Missing test cases\n" <>
    "2. Edge cases\n" <>
    "3. Error handling scenarios\n" <>
    "4. Better descriptions\n" <>
    "5. Additional behaviors if needed\n\n" <>
    "Return improved spec.yml."
  
  let messages = [
    Message(role: "user", content: system_prompt <> "{\n\nCurrent spec:\n}spec_content")
  ]
  
  call_claude(messages)
}

// Validate spec.yml quality
pub fn validate_spec_quality(spec_content: String) → Result(QualityReport, String) {
  let system_prompt =
    "You are a spec.yml quality validator. Analyze the spec and provide a quality report.\n\n" <>
    "Check:\n" <>
    "1. Completeness (all required fields)\n" <>
    "2. Test coverage (enough test cases)\n" <>
    "3. Edge cases coverage\n" <>
    "4. Error handling\n" <>
    "5. Clear descriptions\n\n" <>
    "Return JSON:\n" <>
    "{\n" <>
    "  \"score\": 0-100,\n" <>
    "  \"issues\": [\"issue1\", \"issue2\"],\n" <>
    "  \"suggestions\": [\"suggestion1\", \"suggestion2\"],\n" <>
    "  \"completeness\": 0-100\n" <>
    "}"
  
  let messages = [
    Message(role: "user", content: system_prompt <> "{\n\nSpec to validate:\n}spec_content")
  ]
  
  case call_claude(messages) {
    Error(e) → Error(e)
    Ok(response) → parse_quality_report(response)
  }
}

// Extract requirements from conversation
pub fn extract_requirements_from_conversation(messages: List(String)) → Result(Requirements, String) {
  let system_prompt =
    "You are a requirements extractor. Analyze the conversation and extract:\n" <>
    "1. Behaviors (what the system should do)\n" <>
    "2. Test cases (scenarios to test)\n" <>
    "3. Types (data structures needed)\n" <>
    "4. Functions (operations needed)\n\n" <>
    "Return JSON:\n" <>
    "{\n" <>
    "  \"behaviors\": [\"behavior1\", \"behavior2\"],\n" <>
    "  \"test_cases\": [\"test1\", \"test2\"],\n" <>
    "  \"types\": [\"Type1\", \"Type2\"],\n" <>
    "  \"functions\": [\"func1\", \"func2\"]\n" <>
    "}"
  
  let conversation = messages
    |> list.index_map(fn(msg, i) {
      "{Message }int".to_string(i + 1) <> "{: }msg"
    })
    |> string.join("\n")
  
  let claude_messages = [
    Message(role: "user", content: system_prompt <> "{\n\nConversation:\n}conversation")
  ]
  
  case call_claude(claude_messages) {
    Error(e) → Error(e)
    Ok(response) → parse_requirements(response)
  }
}

// Call Claude API
fn call_claude(messages: List(Message)) → Result(String, String) {
  let api_key = get_env("ANTHROPIC_API_KEY")
  
  case api_key {
    Error(_) → Error("ANTHROPIC_API_KEY not set")
    Ok(key) → {
      let request_body = ClaudeRequest(
        model: "claude-3-5-sonnet-20241022",
        max_tokens: 4096,
        messages: messages,
      )
      
      // Make HTTP request to Claude API
      case make_claude_request(key, request_body) {
        Error(e) → Error("{Claude API error: }e")
        Ok(response) → Ok(response.content)
      }
    }
  }
}

// Make HTTP request to Claude API (placeholder)
fn make_claude_request(api_key: String, request: ClaudeRequest) → Result(ClaudeResponse, String) {
  // TODO: Implement actual HTTP request
  // For now, return mock response
  Ok(ClaudeResponse(
    content: "# Generated spec.yml\nname: example\nversion: 1.0.0",
    stop_reason: "end_turn",
  ))
}

// Parse quality report from JSON
fn parse_quality_report(json_str: String) → Result(QualityReport, String) {
  // TODO: Implement JSON parsing
  Ok(QualityReport(
    score: 85,
    issues: ["Missing edge cases"],
    suggestions: ["Add error handling tests"],
    completeness: 80,
  ))
}

// Parse requirements from JSON
fn parse_requirements(json_str: String) → Result(Requirements, String) {
  // TODO: Implement JSON parsing
  Ok(Requirements(
    behaviors: ["user_login", "user_register"],
    test_cases: ["valid_login", "invalid_login"],
    types: ["User", "Credentials"],
    functions: ["login", "register"],
  ))
}

// Get environment variable (placeholder)
fn get_env(key: String) → Result(String, Nil) {
  // TODO: Implement actual env var reading
  Ok("mock_api_key")
}

// Types
pub type QualityReport {
  QualityReport(
    score: Int,
    issues: List(String),
    suggestions: List(String),
    completeness: Int,
  )
}

pub type Requirements {
  Requirements(
    behaviors: List(String),
    test_cases: List(String),
    types: List(String),
    functions: List(String),
  )
}
