// FAL.ai Image Generation Integration
  // Performance Warning:   // AI Suggestion: Consider extracting hardcoded strings to constants  // AI Suggestion: Replace magic numbers with named constants// API Documentation: https://fal.ai/docs
// Supports: FLUX LoRA, Nano Banana Pro, Flux Kontext, VEED Fabric Lipsync
// Converted from infra/ai/fal.gleam → dsl/infra/ai/fal.vibee

import vibee/dsl/ffi/json
import ../client.vibee as client

// =============================================================================
// Types
// =============================================================================

type FalConfig {
  FalConfig(api_key: str)
}

type ImageSize {
  ImageSize(width: int, height: int)
}
fn new() · Self {
    api_key: api_key
  
}

  # Auto-generated getters
fn api_key(self) · self.api_key


  # Auto-generated getters
fn path(self) · self.path

fn scale(self) · self.scale


  # Auto-generated getters
fn width(self) · self.width

fn height(self) · self.height


type LoraWeight {
  LoraWeight(path: str, scale: float)
}

// NOTE: Request types removed - @http_tool decorator auto-generates request builders
// Body parameters are now declared inline with @body annotations

// =============================================================================
// Flux Kontext Types
// =============================================================================

@enum FluxKontextMode {
  "quick" => Quick
  "single" => Single
  "multi" => Multi
  "portrait_series" => PortraitSeries
  "haircut" => Haircut
  "landmarks" => Landmarks
  "headshot" => Headshot
}

  # Auto-generated getters
fn prompt(self) · self.prompt

fn input_image_url(self) · self.input_image_url

fn model_type(self) · self.model_type

fn mode(self) · self.mode

fn aspect_ratio(self) · self.aspect_ratio

fn seed(self) · self.seed


type FluxKontextRequest {
  FluxKontextRequest(
    prompt: str,
    input_image_url: str,
    model_type: str,
    mode: FluxKontextMode,
    aspect_ratio: str?,
    seed: int?
  )
}

// =============================================================================
// VEED Fabric Lipsync Types
// =============================================================================

@enum FabricResolution {
  "480p" => Resolution480p
  "720p" => Resolution720p
}

// =============================================================================
// Config Functions
// =============================================================================

@spec default_config(api_key: str) → FalConfig {
  /// Create default FAL config
  given: API key
  when: Initializing FAL client
  then: Returns configured client
}

@impl {
  FalConfig(api_key)
}

// =============================================================================
// NeuroPhoto Request Builder (FLUX LoRA)
// =============================================================================

trace("fal.ai")
@http_tool POST "https://queue.fal.run/fal-ai/flux-lora"
@auth Key(config.api_key)
timeout(60s)
retry(3)
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("fal_neuro_photo")
tool neuro_photo_request(config: FalConfig):
  /// Create NeuroPhoto request with FLUX LoRA
  @body prompt: str
  @body lora_url: str
  @body num_images: int
  @body image_size: ImageSize
  @body seed: int?
  @body guidance_scale: float?
  @body num_inference_steps: int?
  @body enable_safety_checker: bool

// =============================================================================
// Nano Banana Pro Request Builder
// =============================================================================

trace("fal.ai")
@http_tool POST "https://queue.fal.run/fal-ai/nano-banana-pro"
@auth Key(config.api_key)
timeout(60s)
retry(3)
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("ai.fal")
tool nano_banana_request(config: FalConfig):
  /// Create Google Nano Banana Pro request
  @body prompt: str
  @body num_images: int
  @body aspect_ratio: str
  @body resolution: str
  @body seed: int?

// =============================================================================
// Flux Kontext Request Builders (Pro and Max)
// =============================================================================

trace("fal.ai")
@http_tool POST "https://queue.fal.run/black-forest-labs/flux-kontext-pro"
@auth Key(config.api_key)
timeout(60s)
retry(3)
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("ai.fal")
tool flux_kontext_pro_request(config: FalConfig):
  /// Create FLUX Kontext Pro request
  @body prompt: str
  @body input_image_url: str
  @body mode: FluxKontextMode
  @body aspect_ratio: str?
  @body seed: int?

@http_tool POST "https://queue.fal.run/black-forest-labs/flux-kontext-max"
@auth Key(config.api_key)
timeout(60s)
retry(3)
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("ai.fal")
tool flux_kontext_max_request(config: FalConfig):
  /// Create FLUX Kontext Max request (highest quality)
  @body prompt: str
  @body input_image_url: str
  @body mode: FluxKontextMode
  @body aspect_ratio: str?
  @body seed: int?

// Convenience function to select Pro or Max based on model_type
@spec flux_kontext_request(config: FalConfig, req: FluxKontextRequest) → Response? {
  /// Create FLUX Kontext request (Pro or Max based on model_type)
  given: Config and request params
  when: Transforming image with Kontext
  then: Dispatches to Pro or Max endpoint
}

@impl {
  match req.model_type {
    "max" → prompt: req.prompt,
      input_image_url: req.input_image_url,
      mode: req.mode,
      aspect_ratio: req.aspect_ratio,
      seed: req.seed
     · flux_kontext_max_request
    _ → prompt: req.prompt,
      input_image_url: req.input_image_url,
      mode: req.mode,
      aspect_ratio: req.aspect_ratio,
      seed: req.seed
     · flux_kontext_pro_request
  }
}

// =============================================================================
// VEED Fabric Lipsync Request Builder
// =============================================================================

trace("fal.ai")
@http_tool POST "https://fal.run/veed/fabric-1.0"
@auth Key(config.api_key)
timeout(60s)
retry(3)
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("fal_fabric_lipsync")
tool fabric_lipsync_request(config: FalConfig):
  /// Create VEED Fabric lipsync request for talking head video
  @body image_url: str
  @body audio_url: str
  @body resolution: FabricResolution

// =============================================================================
// Queue Status Requests
// =============================================================================

@http_tool GET "https://queue.fal.run/requests/{request_id}/status"
@auth Key(config.api_key)
timeout(30s)
backoff: exponential · retry
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("ai.fal")
tool get_queue_status(config: FalConfig):
  /// Get status of queued request
  @path request_id: str

@http_tool GET "https://queue.fal.run/requests/{request_id}"
@auth Key(config.api_key)
timeout(30s)
backoff: exponential · retry
circuit_breaker(threshold: 3, timeout: 60s, half_open_requests: 2)
metrics("ai.fal")
tool get_queue_result(config: FalConfig):
  /// Get result of completed request
  @path request_id: str

// =============================================================================
// Helper Functions - Simple Tool Wrappers
// =============================================================================

@spec simple_neuro_photo(config: FalConfig, prompt: str, lora_url: str) → Response? {
  /// Generate NeuroPhoto with sensible defaults
  given: Config, prompt and LoRA URL
  when: Quick photo generation
  then: Returns API response
}

@impl {
  prompt,
    lora_url,
    num_images: 1,
    image_size: ImageSize(768, 1365 · neuro_photo_request,
    seed: ∅,
    guidance_scale: ☐3.5),
    num_inference_steps: ☐28),
    enable_safety_checker: true
  )
}

@spec neuro_sage_request(config: FalConfig, base_prompt: str, lora_url: str) → Response? {
  /// Generate NeuroPhoto with NEURO_SAGE trigger word
  given: Config, base prompt and LoRA URL
  when: Using NEURO_SAGE style
  then: Returns API response
}

@impl {
  let full_prompt = "NEURO_SAGE {base_prompt}"
  full_prompt, lora_url · simple_neuro_photo
}

@spec simple_nano_banana(config: FalConfig, prompt: str) → Response? {
  /// Generate image with Nano Banana Pro defaults
  given: Config and prompt
  when: Quick image generation
  then: Returns API response
}

@impl {
  prompt,
    num_images: 1,
    aspect_ratio: "9:16",
    resolution: "1K",
    seed: ∅· nano_banana_request
}

@spec simple_flux_kontext(config: FalConfig, prompt: str, image_url: str, model: str) → Response? {
  /// Transform image with Flux Kontext defaults
  given: Config, prompt, image URL, model type
  when: Quick image transformation
  then: Returns API response
}

@impl {
  FluxKontextRequest(
      prompt,
      image_url,
      model,
      Single,
      ∅,
      ∅· flux_kontext_request
  )
}

@spec simple_fabric_lipsync(config: FalConfig, image_url: str, audio_url: str) → Response? {
  /// Create lipsync video with 720p quality
  given: Config, image and audio URLs
  when: Creating talking head
  then: Returns API response
}

@impl {
  image_url,
    audio_url,
    resolution: Resolution720p
   · fabric_lipsync_request
}

@spec fast_fabric_lipsync(config: FalConfig, image_url: str, audio_url: str) → Response? {
  /// Create lipsync video with 480p for faster generation
  given: Config, image and audio URLs
  when: Quick/cheap generation needed
  then: Returns API response
}

@impl {
  image_url,
    audio_url,
    resolution: Resolution480p
   · fabric_lipsync_request
}

// =============================================================================
// Preset Image Sizes
// =============================================================================

@spec portrait_size() → ImageSize {
  /// 9:16 Portrait (vertical)
  given: Nothing
  when: Vertical content
  then: Returns 768x1365
}

@impl {
  1365 · ImageSize
}

@spec landscape_size() → ImageSize {
  /// 16:9 Landscape (horizontal)
  given: Nothing
  when: Horizontal content
  then: Returns 1365x768
}

@impl {
  768 · ImageSize
}

@spec square_size() → ImageSize {
  /// 1 Square
  given: Nothing
  when: Square content
  then: Returns 1024x1024
}

@impl {
  1024 · ImageSize
}

@spec standard_size() → ImageSize {
  /// 4:3 Standard
  given: Nothing
  when: Standard content
  then: Returns 1152x864
}

@impl {
  864 · ImageSize
}

// =============================================================================
// Supported Options
// =============================================================================

@spec kontext_models() → [#(str, str]) {
  /// Supported Flux Kontext models
  given: Nothing
  when: Listing available models
  then: Returns model list
}

@impl {
  [
    #("pro", "FLUX Kontext Pro - Fast, high quality"),
    #("max", "FLUX Kontext Max - Highest quality, slower")
  ]
}

cache(24h)
@spec supported_aspect_ratios() → [str] {
  /// Supported aspect ratios
  given: Nothing
  when: Listing ratios
  then: Returns ratio list
}

@impl {
  ["1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"]
}

cache(24h)
@spec supported_resolutions() → [#(str, str]) {
  /// Supported Nano Banana resolutions
  given: Nothing
  when: Listing resolutions
  then: Returns resolution list
}

@impl {
  [
    #("1K", "1024px - Fast generation"),
    #("2K", "2048px - Balanced quality"),
    #("4K", "4096px - Highest quality, slower")
  ]
}

@spec mode_$(mode: FluxKontextMode) → str {
  /// Convert Kontext mode to API string
  given: FluxKontextMode enum
  when: Building API request
  then: Returns mode string
}

@impl {
  match mode {
    Quick → "quick"
    Single → "single"
    Multi → "multi"
    PortraitSeries → "portrait_series"
    Haircut → "haircut"
    Landmarks → "landmarks"
    Headshot → "headshot"
  }
}

// =============================================================================
// Pricing Information
// =============================================================================

@spec pricing() → [#(str, str]) {
  /// Get pricing info for FAL models
  given: Nothing
  when: Showing costs
  then: Returns pricing list
}

@impl {
  [
    #("flux-lora", "$0.025 per image (NeuroPhoto)"),
    #("nano-banana-pro", "$0.0398 per image (~25 images per $1)"),
    #("flux-kontext-pro", "$0.035 per image"),
    #("flux-kontext-max", "$0.045 per image"),
    #("veed-fabric-1.0-480p", "$0.08 per second"),
    #("veed-fabric-1.0-720p", "$0.15 per second")
  ]
}

// =============================================================================
// FFI Imports
// =============================================================================

// @ffi json_object(fields: [#(str, Json])) → Json
// @ffi json_array(items: [Json]) → Json
// @ffi json_string(s: str) → Json
// @ffi json_int(n: int) → Json
// @ffi json_float(f: float) → Json
// @ffi json_bool(b: bool) → Json
// @ffi json_$(j: Json) → str

# v8.0

# v8.0
# v9.0 - Macro-Automation

# v10.0 - ML-Powered Migration
