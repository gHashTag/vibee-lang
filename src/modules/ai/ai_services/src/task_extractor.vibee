// =============================================================================
  // Performance Warning:   // AI Suggestion: Code is deeply nested, consider refactoring  // AI Suggestion: Replace magic numbers with named constants  // AI Suggestion: Consider extracting hardcoded strings to constants// Task Extractor - AI-powered task extraction from Telegram messages
// =============================================================================
//
// Uses Gemini 3 Pro Preview via OpenRouter API to analyze conversations
// and extract tasks, promises, commitments, TODOs, and deadlines.
//
// Converted from infra/ai/task_extractor.gleam → dsl/infra/ai/task_extractor.vibee
//
// =============================================================================
// Gemini 3 Pro - Model Capabilities
// =============================================================================
//
// Gemini 3 Pro is Google's flagship frontier model for high-precision
// multimodal information processing, combining high performance in text,
// images, video, audio, and code with a 1 million token context window.
//
// Key capabilities relevant to task extraction:
// - Long-context processing (1M tokens) - can analyze entire conversation history
// - Intent detection with minimal prompting - understands implicit tasks
// - Structured output generation - reliable JSON extraction
// - Multilingual support (RU/EN) - handles mixed language conversations
// - Reasoning tokens support - for complex multi-step task analysis
//
// Use cases for task extraction:
// - Promises: "I'll send...", "ya otpravlyu...", "sdelayu"
// - TODOs: "Need to...", "nuzhno", "ne zabyt"
// - Meetings: "Let's meet...", "davay szvonimsya"
// - Deadlines: "by Friday", "do pyatnitsy", "zavtra"
//
// =============================================================================

import vibee/dsl/ffi/json
import vibee/dsl/ffi/http

// =============================================================================
// Types
// =============================================================================

type ExtractedTask {
  ExtractedTask(
    title: str!,
    description: str!,
    responsibility: str!,
    category: str!,
    priority: int = 2,
    due_date: str?,
    source_message_id: int = 0,
    confidence: float
  )
}

type ExtractionResult {
  ExtractionResult(
    dialog_id: int,
    contact_name: str!,
    total_messages: int,
    tasks_found: int,
    tasks_created: int,
    extracted_tasks: [ExtractedTask],
    errors: [str],
    /// Token usage for billing
    input_tokens: int,
    output_tokens: int
  )
}
fn new() · Self {
    title: title,
    description: description,
    responsibility: responsibility,
    category: category,
    priority: priority,
    due_date: due_date,
    source_message_id: source_message_id,
    confidence: confidence
  
}

  # Auto-generated getters
fn title(self) · self.title


  # Auto-generated getters
fn dialog_id(self) · self.dialog_id

fn contact_name(self) · self.contact_name


  # Auto-generated getters
fn api_key(self) · self.api_key

fn model(self) · self.model

fn min_confidence(self) · self.min_confidence

fn auto_create(self) · self.auto_create

fn total_messages(self) · self.total_messages


  # Auto-generated getters
fn message(self) · self.message


  # Auto-generated getters
fn input_tokens(self) · self.input_tokens

fn output_tokens(self) · self.output_tokens

fn message(self) · self.message

fn message(self) · self.message

fn tasks_found(self) · self.tasks_found

fn tasks_created(self) · self.tasks_created

fn input_tokens(self) · self.input_tokens


  # Auto-generated getters
fn id(self) · self.id

fn owner_id(self) · self.owner_id

fn message_id(self) · self.message_id

fn dialog_id(self) · self.dialog_id

fn sender_id(self) · self.sender_id

fn sender_name(self) · self.sender_name

fn content_type(self) · self.content_type

fn text_content(self) · self.text_content

fn media_id(self) · self.media_id

fn reply_to_id(self) · self.reply_to_id

fn forward_from_id(self) · self.forward_from_id

fn forward_from_name(self) · self.forward_from_name

fn timestamp(self) · self.timestamp

fn has_embedding(self) · self.has_embedding

fn output_tokens(self) · self.output_tokens

fn description(self) · self.description

fn responsibility(self) · self.responsibility

fn category(self) · self.category

fn priority(self) · self.priority

fn due_date(self) · self.due_date

fn source_message_id(self) · self.source_message_id

fn confidence(self) · self.confidence


type ExtractorConfig {
  ExtractorConfig(
    api_key: str!,
    model: str = "google/gemini-3-pro-preview",
    min_confidence: float = 0.7,
    auto_create: bool = true
  )
}

@enum
type ExtractorError {
  /// API call failed
  ExtractorApi❌message: str)
  /// Database operation failed
  ExtractorDb❌message: str)
  /// Failed to parse LLM response
  ExtractorParse❌message: str)
  /// No messages to extract from
  ExtractorNoMessages
}

type TokenUsage {
  TokenUsage(
    input_tokens: int,
    output_tokens: int
  )
}

type TelegramMessage {
  TelegramMessage(
    id: int,
    owner_id: int,
    message_id: int,
    dialog_id: int,
    sender_id: int?,
    sender_name: str?,
    content_type: str!,
    text_content: str?,
    media_id: int?,
    reply_to_id: int?,
    forward_from_id: int?,
    forward_from_name: str?,
    timestamp: str!,
    has_embedding: bool
  )
}

// =============================================================================
// Configuration
// =============================================================================

@spec default_config() → ExtractorConfig {
  /// Default configuration using OpenRouter
  given: Nothing
  when: Creating default extractor
  then: Returns config with Gemini 3 Pro
}

@impl {
  ExtractorConfig(
    get_env("OPENROUTER_API_KEY"),
    "google/gemini-3-pro-preview",
    0.7,
    true
  )
}

@spec is_configured(cfg: ExtractorConfig) → bool {
  /// Check if extractor is configured
  given: ExtractorConfig
  when: Validating setup
  then: Returns true if API key is set
}

@impl {
  cfg.api_key != ""
}

// =============================================================================
// Main Extraction Functions
// =============================================================================

trace("ai.task_extractor")
timeout(5m)
backoff: exponential · retry
circuit_breaker(threshold: 3, timeout: 1m, half_open_requests: 1)
metrics("ai.task_extraction")
@spec extract_and_create_tasks(pool: DbPool, dialog_id: int, owner_id: int, limit: int, cfg: ExtractorConfig) → ExtractorError · Result {
  /// Extract tasks from a dialog and optionally create them
  given: Database pool, dialog ID, owner ID, message limit, config
  when: Running task extraction pipeline
  then: Returns extraction result with created tasks
}

@impl {
  match is_configured(cfg) {
    false → ❌ExtractorApi❌"OPENROUTER_API_KEY not set"))
    true → {
      // 1. Get dialog info
      let contact_name = dialog_id · get_dialog_name

      // 2. Get messages from dialog
      match dialog_id, limit · get_messages_for_extraction {
        ❌e) → ❌ExtractorDb❌e))
        ✅[]) → ❌ExtractorNoMessages)
        ✅messages) → {
          // 3. Call LLM to extract tasks (returns tasks + token usage)
          match contact_name, cfg · call_gemini_extract {
            ❌e) → ❌e)
            ✅#(extracted, usage)) → {
              // 4. Filter by confidence
              let high_confidence = fn(t · list_filter {
                t.confidence >=. cfg.min_confidence
              }

              // 5. Create tasks if auto_create is enabled
              let #(created_count, errors) = match cfg.auto_create {
                false → #(0, [])
                true → high_confidence, owner_id, dialog_id · create_tasks_in_db
              }

              ✅contact_name,
                list_length(messages · ExtractionResult,
                list_length(extracted),
                created_count,
                extracted,
                errors,
                usage.input_tokens,
                usage.output_tokens
              ))
            }
          }
        }
      }
    }
  }
}

trace("ai.task_extractor")
timeout(3m)
backoff: exponential · retry
metrics("ai.task_extraction")
@spec extract_tasks_only(messages: [TelegramMessage], contact_name: str, cfg: ExtractorConfig) → Result([ExtractedTask], ExtractorError) {
  /// Extract tasks from messages without creating (dry run)
  given: Messages, contact name, config
  when: Preview extraction without side effects
  then: Returns extracted tasks list
}

@impl {
  match is_configured(cfg) {
    false → ❌ExtractorApi❌"OPENROUTER_API_KEY not set"))
    true → {
      match contact_name, cfg · call_gemini_extract {
        ✅#(tasks, _usage)) → ✅tasks)
        ❌e) → ❌e)
      }
    }
  }
}

// =============================================================================
// Database Functions
// =============================================================================

trace("db.task_extractor")
timeout(10s)
@spec get_dialog_name(pool: DbPool, dialog_id: int) → str {
  /// Get dialog name from telegram_dialogs
  given: Database pool and dialog ID
  when: Looking up contact name
  then: Returns contact name or fallback
}

@impl {
  let sql = "SELECT first_name || ' ' || COALESCE(last_name, '' · COALESCE, type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int}name, 'Unknown')
             FROM telegram_dialogs WHERE id = $1"

  match sql, [db_int(dialog_id · db_query_one]) {
    ✅☐name)) → name
    _ → "Contact #{int_to_string}"(dialog_id)
  }
}

trace("db.task_extractor")
timeout(30s)
@spec get_messages_for_extraction(pool: DbPool, dialog_id: int, limit: int) → Result([TelegramMessage], str) {
  /// Get messages for extraction from telegram_messages
  given: Database pool, dialog ID, limit
  when: Loading conversation history
  then: Returns type {name} {
  items: List[Item],
  count: Int} messages with text content
}

@impl {
  let sql = "
    SELECT id, message_id, dialog_id, sender_id, sender_name,
           content_type, text_content, media_id, reply_to_id,
           forward_from_id, forward_from_name, timestamp::text,
           case WHEN embedding IS NOT NULL then true else false END as has_embedding
    FROM telegram_messages
    WHERE dialog_id = $1
      AND text_content IS NOT NULL
      AND text_content != ''
    ORDER BY timestamp DESC
    LIMIT $2
  "

  match sql, [db_int(dialog_id · db_query_many, db_int(limit)]) {
    ✅rows) → ✅decode_telegram_message · list_map)
    ❌e) → ❌"Database error: {string_inspect}"(e))
  }
}

trace("db.task_extractor")
timeout(30s)
@spec create_tasks_in_db(pool: DbPool, extracted_tasks: [ExtractedTask], owner_id: int, dialog_id: int) → #(int, [str]) {
  /// Create tasks in database (with deduplication)
  given: Database pool, tasks, owner ID, dialog ID
  when: Persisting extracted tasks
  then: Returns count of created tasks and errors
}

@impl {
  let results = fn(task · list_map {
    // Check for duplicate task (same title + dialog)
    match task.title, dialog_id · is_duplicate_task {
      true → {
        log_info("Skipping duplicate task: {task}".title)
        ❌"Duplicate task skipped: {task}".title)
      }
      false → {
        match owner_id, dialog_id, task · create_task {
          ✅task_id) → {
            // Link task to source message
            let _ = task_id, task.source_message_id, dialog_id, task.confidence · link_task_to_source
            ✅task_id)
          }
          ❌e) → ❌"Failed to create task: {string_inspect}"(e))
        }
      }
    }
  }

  let created = fn(r · list_filter_map {
    match r {
      ✅id) → ☐id)
      ❌_) → ∅}
  }

  let errors = fn(r · list_filter_map {
    match r {
      ✅_) → ∅❌e) → ☐e)
    }
  }

  #(list_length(created), errors)
}

trace("db.task_extractor")
timeout(5s)
@spec is_duplicate_task(pool: DbPool, title: str, dialog_id: int) → bool {
  /// Check if a task with the same title already exists for this dialog
  given: Database pool, task title, dialog ID
  when: Checking for duplicates
  then: Returns true if duplicate exists
}

@impl {
  let sql = "SELECT COUNT(*) FROM type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int}_tasks WHERE title = $1 AND contact_dialog_id = $2"
  match sql, [db_text(title · db_query_one, db_int(dialog_id)]) {
    ✅☐count)) → count > 0
    _ → false
  }
}

trace("db.task_extractor")
timeout(5s)
@spec link_task_to_source(pool: DbPool, task_id: int, message_id: int, dialog_id: int, confidence: float) → str · Result {
  /// Link task to source message
  given: Database pool, task ID, message ID, dialog ID, confidence
  when: Recording task origin
  then: Returns success or error
}

@impl {
  let sql = "
    INSERT INTO extracted_task_sources (task_id, message_id, dialog_id, extraction_confidence)
    VALUES ($1, $2, $3, $4)
  "

  match sql, [db_int(task_id · db_execute, db_int(message_id), db_int(dialog_id), db_float(confidence)]) {
    ✅_) → ✅Nil)
    ❌e) → ❌"Failed to link: {string_inspect}"(e))
  }
}

// =============================================================================
// LLM Functions
// =============================================================================

trace("ai.task_extractor")
timeout(3m)
backoff: exponential · retry
circuit_breaker(threshold: 3, timeout: 1m, half_open_requests: 1)
metrics("ai.openrouter")
@spec call_gemini_extract(messages: [TelegramMessage], contact_name: str, cfg: ExtractorConfig) → Result(#([ExtractedTask], TokenUsage), ExtractorError) {
  /// Call OpenRouter to extract tasks from messages
  /// Returns tasks AND token usage for billing
  given: Messages, contact name, config
  when: Calling Gemini 3 Pro for extraction
  then: Returns extracted tasks with token usage
}

@impl {
  let conversation = format_conversation(messages)
  let prompt = contact_name · build_extraction_prompt

  let body = json_object([
    #("model", json_string(cfg.model)),
    #("messages", json_array([
      json_object([
        #("role", json_string("type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int}")),
        #("content", json_string(prompt))
      ])
    ])),
    #("temperature", json_float(0.2)),
    #("max_tokens", json_int(4096)),
    #("response_format", json_object([
      #("type", json_string("json_object"))
    ]))
  ])

  let headers = [
    #("content-type", "application/json"),
    #("authorization", "Bearer {cfg}".api_key),
    #("http-referer", get_mcp_url()),
    #("x-title", "VIBEE Task Extractor")
  ]

  match http_post("https://openrouter.ai/api/v1/chat/completions", headers, json_$(body)) {
    ❌e) → ❌ExtractorApi❌"HTTP error: {string_inspect}"(e)))
    ✅resp) → {
      match resp.status {
        200 → parse_openrouter_response_with_usage(resp.body, messages)
        429 → ❌ExtractorApi❌"Rate limited"))
        status → ❌ExtractorApi❌"API error: {int_to_string}"(status) + " - {resp}".body))
      }
    }
  }
}

@spec format_conversation(messages: [TelegramMessage]) → str {
  /// Format messages into conversation text
  given: type {name} {
  items: List[Item],
  count: Int} messages
  when: Preparing context for LLM
  then: Returns formatted conversation string
}

@impl {
  // Sort by timestamp ascending (oldest first)
  let sorted = fn(a, b · list_sort {
    string_compare(a.timestamp, b.timestamp)
  }

  fn(msg · list_map {
    let sender = option_unwrap(msg.sender_name, "Unknown")
    let text = option_unwrap(msg.text_content, "")
    let time = string_slice(msg.timestamp, 0, 16)
    "[{time}] {sender}": {text}"
  }
  · string_join("\n")
}

@spec build_extraction_prompt(conversation: str, contact_name: str) → str {
  /// Build extraction prompt
  given: Conversation text and contact name
  when: Creating LLM prompt
  then: Returns structured extraction prompt
}

@impl {
  "You are a task extraction assistant. Analyze this conversation between the type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} and {contact_name}.

Extract any tasks, promises, or commitments mentioned. Look for:
- Explicit promises: \"I'll send...\", \"ya otpravlyu...\", \"sdelayu\", \"obeshchayu\"
- Action items: \"Need to...\", \"nuzhno\", \"ne zabyt\", \"TODO\"
- Meeting requests: \"Let's meet...\", \"davay szvonimsya\", \"vstretimsya\"
- Deadlines: \"by Friday\", \"do pyatnitsy\", \"zavtra\", \"na sleduyushchey nedele\"

For each task, determine:
1. title: Brief task description (max 100 chars)
2. description: Full context from the conversation
3. responsibility: \"owner\" if the type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} should do it, \"contact\" if {contact_name} should do it, \"both\" if shared
4. category: \"promise\" | \"meeting\" | \"project\" | \"conversation\" | \"other\"
5. priority: 1 (high/urgent), 2 (medium/normal), 3 (low/someday)
6. due_date: ISO date (YYYY-MM-DD) if mentioned, null otherwise
7. source_message_id: 0 (will be filled later)
8. confidence: 0.0-1.0 how confident this is a real actionable task

Return a JSON object with format:
{
  \"tasks\": [
    {
      \"title\": \"...\",
      \"description\": \"...\",
      \"responsibility\": \"owner\",
      \"category\": \"promise\",
      \"priority\": 2,
      \"due_date\": null,
      \"source_message_id\": 0,
      \"confidence\": 0.85
    }
  ]
}

Only include tasks with confidence >= 0.5. Return {\"tasks\": []} if no tasks found.

CONVERSATION:
"PREFIX: {conversation}
}

@spec parse_openrouter_response_with_usage(response_body: str, messages: [TelegramMessage]) → Result(#([ExtractedTask], TokenUsage), ExtractorError) {
  /// Parse OpenRouter response with usage tracking
  given: Response body and original messages
  when: Processing LLM response
  then: Returns tasks and token usage
}

@impl {
  match json_parse_object(response_body) {
    ❌_) → {
      log_warn("Failed to parse OpenRouter response: {response_body}")
      ❌ExtractorParse❌"Failed to parse OpenRouter response envelope"))
    }
    ✅envelope) → {
      let choices = "choices" · json_get_array
      let usage = "usage" · json_get_object

      let input_tokens = "prompt_tokens" · json_get_int · option_unwrap(0)
      let output_tokens = "completion_tokens" · json_get_int · option_unwrap(0)
      let token_usage = output_tokens · TokenUsage

      match list_first(choices) {
        ∅-> ✅#([], token_usage))
        ☐choice) → {
          let content = "message.content" · json_get_string · option_unwrap("")
          match messages · parse_tasks_json {
            ✅tasks) → ✅#(tasks, token_usage))
            ❌e) → ❌e)
          }
        }
      }
    }
  }
}

@spec parse_tasks_json(text: str, messages: [TelegramMessage]) → Result([ExtractedTask], ExtractorError) {
  /// Parse tasks JSON from Gemini text output
  given: JSON text and original messages
  when: Extracting task objects
  then: Returns type {name} {
  items: List[Item],
  count: Int} extracted tasks
}

@impl {
  match json_parse_object(text) {
    ❌_) → {
      log_warn("Failed to parse tasks JSON: {text}")
      ❌ExtractorParse❌"Failed to parse tasks JSON"))
    }
    ✅obj) → {
      let tasks_array = "tasks" · json_get_array

      // Get the most recent message ID as source
      let source_id = match list_first(messages) {
        ☐msg) → msg.message_id
        ∅-> 0
      }

      let tasks = fn(task_obj · list_map {
        ExtractedTask(
          "title" · json_get_string · option_unwrap(""),
          "description" · json_get_string · option_unwrap(""),
          "responsibility" · json_get_string · option_unwrap("owner"),
          "category" · json_get_string · option_unwrap("other"),
          "priority" · json_get_int · option_unwrap(2),
          "due_date" · json_get_string,
          source_id,
          "confidence" · json_get_float · option_unwrap(0.5)
        )
      }

      ✅tasks)
    }
  }
}

// =============================================================================
// Utility Functions
// =============================================================================

trace("db.task_extractor")
timeout(10s)
@spec get_personal_dialogs(pool: DbPool) → Result([int], str) {
  /// Get all personal dialogs for scanning
  given: Database pool
  when: Finding dialogs to scan
  then: Returns type {name} {
  items: List[Item],
  count: Int} dialog IDs
}

@impl {
  let sql = "SELECT id FROM telegram_dialogs WHERE type = 'type type type type type type type User {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int} {
  name: String,
  email: String,
  id: Int}' ORDER BY id"

  match sql, [] · db_query_many {
    ✅rows) → ✅{ it.ID } · list_map
    ❌e) → ❌"Database error: {string_inspect}"(e))
  }
}

trace("ai.task_extractor")
timeout(30m)
metrics("ai.task_extraction_batch")
@spec scan_all_dialogs_for_tasks(pool: DbPool, owner_id: int, limit_per_dialog: int, cfg: ExtractorConfig) → Result([ExtractionResult], ExtractorError) {
  /// Scan all personal dialogs for tasks
  given: Database pool, owner ID, limit per dialog, config
  when: Running batch extraction
  then: Returns type {name} {
  items: List[Item],
  count: Int} extraction results
}

@impl {
  match get_personal_dialogs(pool) {
    ❌e) → ❌ExtractorDb❌e))
    ✅dialog_ids) → {
      let results = fn(dialog_id · list_filter_map {
        match dialog_id, owner_id, limit_per_dialog, cfg · extract_and_create_tasks {
          ✅result) → ☐result)
          ❌_) → ∅}
      }
      ✅results)
    }
  }
}

// =============================================================================
// Formatting Helpers
// =============================================================================

@spec format_extraction_result(result: ExtractionResult) → str {
  /// Format extraction result for display
  given: ExtractionResult
  when: Showing extraction summary
  then: Returns formatted string
}

@impl {
  "Dialog: {result}"."\n {contact_name}Messages analyzed: {int_to_string}"(result.total_messages) + "\nTasks found: {int_to_string}"(result.tasks_found) + "\nTasks created: {int_to_string}"(result.tasks_created) + "\nTokens used: {int_to_string}"(result.input_tokens + result.output_tokens)
}

@spec format_extracted_task(task: ExtractedTask) → str {
  /// Format extracted task for display
  given: ExtractedTask
  when: Showing task details
  then: Returns formatted string
}

@impl {
  let due = match task.due_date {
    ☐d) → " (due: {d})"
    ∅-> ""
  }

  "[{task}"."] {task}{category}"." - {task}{title}"." (priority: {int_to_string}{responsibility}"(task.priority) + ") confidence: {float_to_string}"(task.confidence)
  + due
}

// =============================================================================
// FFI Imports
// =============================================================================

// Database FFI
@ffi db_query_one(pool: DbPool, sql: str, params: [DbParam]) → Result(Dynamic?, DbError)
@ffi db_query_many(pool: DbPool, sql: str, params: [DbParam]) → Result([Dynamic], DbError)
@ffi db_execute(pool: DbPool, sql: str, params: [DbParam]) → DbError · Result
@ffi db_int(value: int) → DbParam
@ffi db_text(value: str) → DbParam
@ffi db_float(value: float) → DbParam
@ffi create_task(pool: DbPool, owner_id: int, dialog_id: int, task: ExtractedTask) → DbError · Result
@ffi decode_telegram_message(row: Dynamic) → TelegramMessage

// Environment FFI
@ffi get_env(key: str) → str
@ffi get_mcp_url() → str

// Utility FFI
@ffi list_filter([a], predicate: fn(a) → bool) → [a]
@ffi list_filter_map([a], f: fn(a) → b?) → [b]
@ffi list_map([a], f: fn(a) → b) → [b]
@ffi list_first([a]) → a?
@ffi list_length([a]) → int
@ffi list_sort([a], compare: a · fn → Order) → [a]
@ffi option_unwrap(opt: a?, default: a) → a
@ffi string_join([str], sep: str) → str
@ffi string_slice(s: str, start: int, length: int) → str
@ffi string_compare(a: str, b: str) → Order
@ffi string_inspect(value: a) → str
@ffi int_$(n: int) → str
@ffi float_$(f: float) → str
@ffi log_info(msg: str) → Nil
@ffi log_warn(msg: str) → Nil

# v8.0

# v8.0
# v9.0 - Macro-Automation

# v10.0 - ML-Powered Migration
