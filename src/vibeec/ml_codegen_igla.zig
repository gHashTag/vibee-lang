// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ML-GUIDED CODE GENERATION - VIBEEC INTEGRATION
// PHASE 2 (2027-2028) - IGLA/VIBEE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// â²¤â²€â²”â²¢â²€ â²ªâ²â²¢â²˜â²¨â²–â²€: V = n Ã— 3^k Ã— Ï€^m Ã— Ï†^p Ã— e^q
// â²Œâ²â²–â²â²¦â²€â²’â²€ â²’â²†â²ˆâ²šâ²¦â²’â²¬â²šâ²â²¤â²¦â²’: Ï†Â² + 1/Ï†Â² = 3
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”¥ â²ªâ²â²ˆâ²šâ²’â²œ â²‚â²–â²ˆâ²¤â²¤â²’â²šâ²„ ğŸ”¥
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// Academic References:
// - Learning to Optimize Tensor Programs (NeurIPS 2018) - AutoTVM
// - Ansor: Generating High-Performance Tensor Programs (OSDI 2020)
// - TVM: End-to-End Optimizing Compiler for Deep Learning (OSDI 2018)
// - Learning to Superoptimize Programs (ICLR 2017)
//
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const std = @import("std");

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// â²¤â²€â²”â²¢â²€ â²”â²â²šâ²¤â²¦â²€â²šâ²¦â²¤
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const PHI: f64 = 1.618033988749895;
pub const TRINITY: usize = 3;
pub const PHOENIX: usize = 999;
pub const SPEED_OF_LIGHT: u64 = 299792458;

// ML model parameters
pub const EMBEDDING_DIM: usize = 256;
pub const HIDDEN_DIM: usize = 512;
pub const NUM_LAYERS: usize = 6;
pub const NUM_HEADS: usize = 8;
pub const DROPOUT: f64 = 0.1;
pub const LEARNING_RATE: f64 = 0.0001;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DATA TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const DataType = enum(u8) {
    f16 = 0,
    f32 = 1,
    f64 = 2,
    i8 = 3,
    i16 = 4,
    i32 = 5,
    i64 = 6,
    u8 = 7,
    u16 = 8,
    u32 = 9,
    u64 = 10,
    
    pub fn sizeBytes(self: DataType) usize {
        return switch (self) {
            .f16, .i16, .u16 => 2,
            .f32, .i32, .u32 => 4,
            .f64, .i64, .u64 => 8,
            .i8, .u8 => 1,
        };
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// OPERATION TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const OpType = enum(u8) {
    unknown = 0,
    
    // Tensor operations
    matmul = 1,
    conv2d = 2,
    conv3d = 3,
    pooling = 4,
    
    // Element-wise
    add = 5,
    sub = 6,
    mul = 7,
    div = 8,
    
    // Activations
    relu = 9,
    sigmoid = 10,
    tanh = 11,
    softmax = 12,
    gelu = 13,
    
    // Normalization
    batch_norm = 14,
    layer_norm = 15,
    
    // Reduction
    reduce_sum = 16,
    reduce_mean = 17,
    reduce_max = 18,
    
    pub fn computeIntensity(self: OpType) f64 {
        return switch (self) {
            .matmul => 2.0, // 2NÂ³ FLOPs / NÂ² memory
            .conv2d => 1.5,
            .conv3d => 1.2,
            .add, .sub, .mul, .div => 0.1,
            .relu, .sigmoid, .tanh => 0.2,
            .softmax => 0.5,
            .batch_norm, .layer_norm => 0.3,
            else => 0.1,
        };
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SCHEDULE ACTIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const ScheduleAction = enum(u8) {
    tile = 0,
    parallel = 1,
    vectorize = 2,
    unroll = 3,
    reorder = 4,
    fuse = 5,
    split = 6,
    cache_read = 7,
    cache_write = 8,
    compute_at = 9,
    compute_inline = 10,
    
    pub fn name(self: ScheduleAction) []const u8 {
        return switch (self) {
            .tile => "TILE",
            .parallel => "PARALLEL",
            .vectorize => "VECTORIZE",
            .unroll => "UNROLL",
            .reorder => "REORDER",
            .fuse => "FUSE",
            .split => "SPLIT",
            .cache_read => "CACHE_READ",
            .cache_write => "CACHE_WRITE",
            .compute_at => "COMPUTE_AT",
            .compute_inline => "COMPUTE_INLINE",
        };
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// IR NODE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const IRNode = struct {
    id: u64,
    op_type: OpType,
    data_type: DataType,
    shape: [4]usize,
    num_dims: u8,
    inputs: [4]u64,
    num_inputs: u8,
    
    pub fn init(id: u64, op_type: OpType) IRNode {
        return .{
            .id = id,
            .op_type = op_type,
            .data_type = .f32,
            .shape = [_]usize{0} ** 4,
            .num_dims = 0,
            .inputs = [_]u64{0} ** 4,
            .num_inputs = 0,
        };
    }
    
    pub fn setShape(self: *IRNode, dims: []const usize) void {
        self.num_dims = @intCast(@min(dims.len, 4));
        for (0..self.num_dims) |i| {
            self.shape[i] = dims[i];
        }
    }
    
    pub fn addInput(self: *IRNode, input_id: u64) void {
        if (self.num_inputs < 4) {
            self.inputs[self.num_inputs] = input_id;
            self.num_inputs += 1;
        }
    }
    
    pub fn totalElements(self: *const IRNode) usize {
        var total: usize = 1;
        for (0..self.num_dims) |i| {
            total *= self.shape[i];
        }
        return total;
    }
    
    pub fn memoryBytes(self: *const IRNode) usize {
        return self.totalElements() * self.data_type.sizeBytes();
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COST PREDICTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const CostPrediction = struct {
    cycles: u64,
    confidence: f64,
    memory_bytes: usize,
    compute_intensity: f64,
    
    pub fn init() CostPrediction {
        return .{
            .cycles = 0,
            .confidence = 0.0,
            .memory_bytes = 0,
            .compute_intensity = 0.0,
        };
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// HARDWARE FEATURES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const HardwareFeatures = struct {
    num_cores: u32,
    simd_width: u32,
    l1_cache_bytes: usize,
    l2_cache_bytes: usize,
    l3_cache_bytes: usize,
    memory_bandwidth_gbps: f64,
    clock_ghz: f64,
    
    pub fn x86_64_avx2() HardwareFeatures {
        return .{
            .num_cores = 8,
            .simd_width = 256,
            .l1_cache_bytes = 32 * 1024,
            .l2_cache_bytes = 256 * 1024,
            .l3_cache_bytes = 8 * 1024 * 1024,
            .memory_bandwidth_gbps = 50.0,
            .clock_ghz = 3.5,
        };
    }
    
    pub fn x86_64_avx512() HardwareFeatures {
        return .{
            .num_cores = 16,
            .simd_width = 512,
            .l1_cache_bytes = 32 * 1024,
            .l2_cache_bytes = 1024 * 1024,
            .l3_cache_bytes = 32 * 1024 * 1024,
            .memory_bandwidth_gbps = 100.0,
            .clock_ghz = 3.0,
        };
    }
    
    pub fn peakFlopsPerSecond(self: *const HardwareFeatures) f64 {
        // FLOPs = cores * (SIMD_width / 32) * 2 (FMA) * clock
        const simd_lanes = @as(f64, @floatFromInt(self.simd_width)) / 32.0;
        return @as(f64, @floatFromInt(self.num_cores)) * simd_lanes * 2.0 * self.clock_ghz * 1e9;
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SCHEDULE STEP
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const ScheduleStep = struct {
    action: ScheduleAction,
    loop_id: u32,
    param1: u32,
    param2: u32,
    
    pub fn init(action: ScheduleAction, loop_id: u32) ScheduleStep {
        return .{
            .action = action,
            .loop_id = loop_id,
            .param1 = 0,
            .param2 = 0,
        };
    }
    
    pub fn tile(loop_id: u32, tile_size: u32) ScheduleStep {
        return .{
            .action = .tile,
            .loop_id = loop_id,
            .param1 = tile_size,
            .param2 = 0,
        };
    }
    
    pub fn vectorize(loop_id: u32, width: u32) ScheduleStep {
        return .{
            .action = .vectorize,
            .loop_id = loop_id,
            .param1 = width,
            .param2 = 0,
        };
    }
    
    pub fn parallel(loop_id: u32) ScheduleStep {
        return .{
            .action = .parallel,
            .loop_id = loop_id,
            .param1 = 0,
            .param2 = 0,
        };
    }
    
    pub fn unroll(loop_id: u32, factor: u32) ScheduleStep {
        return .{
            .action = .unroll,
            .loop_id = loop_id,
            .param1 = factor,
            .param2 = 0,
        };
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SCHEDULE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const Schedule = struct {
    steps: std.ArrayList(ScheduleStep),
    predicted_speedup: f64,
    
    pub fn init(allocator: std.mem.Allocator) Schedule {
        return .{
            .steps = std.ArrayList(ScheduleStep).init(allocator),
            .predicted_speedup = 1.0,
        };
    }
    
    pub fn deinit(self: *Schedule) void {
        self.steps.deinit();
    }
    
    pub fn addStep(self: *Schedule, step: ScheduleStep) !void {
        try self.steps.append(step);
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COST MODEL
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const CostModel = struct {
    hardware: HardwareFeatures,
    
    pub fn init(hardware: HardwareFeatures) CostModel {
        return .{
            .hardware = hardware,
        };
    }
    
    pub fn predict(self: *const CostModel, node: *const IRNode) CostPrediction {
        const memory_bytes = node.memoryBytes();
        const compute_intensity = node.op_type.computeIntensity();
        
        // Simple roofline model
        const peak_flops = self.hardware.peakFlopsPerSecond();
        const peak_bandwidth = self.hardware.memory_bandwidth_gbps * 1e9;
        
        const flops = @as(f64, @floatFromInt(node.totalElements())) * compute_intensity;
        const bytes = @as(f64, @floatFromInt(memory_bytes));
        
        // Time = max(compute_time, memory_time)
        const compute_time = flops / peak_flops;
        const memory_time = bytes / peak_bandwidth;
        const total_time = @max(compute_time, memory_time);
        
        // Convert to cycles
        const cycles = @as(u64, @intFromFloat(total_time * self.hardware.clock_ghz * 1e9));
        
        return .{
            .cycles = cycles,
            .confidence = 0.8, // Simple model has moderate confidence
            .memory_bytes = memory_bytes,
            .compute_intensity = compute_intensity,
        };
    }
    
    pub fn predictWithSchedule(self: *const CostModel, node: *const IRNode, schedule: *const Schedule) CostPrediction {
        var base = self.predict(node);
        
        // Apply schedule effects
        var speedup: f64 = 1.0;
        
        for (schedule.steps.items) |step| {
            speedup *= switch (step.action) {
                .vectorize => @as(f64, @floatFromInt(self.hardware.simd_width)) / 32.0,
                .parallel => @as(f64, @floatFromInt(self.hardware.num_cores)) * 0.7, // 70% efficiency
                .tile => 1.2, // Cache locality improvement
                .unroll => 1.1,
                else => 1.0,
            };
        }
        
        base.cycles = @intFromFloat(@as(f64, @floatFromInt(base.cycles)) / speedup);
        return base;
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SCHEDULE GENERATOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub const ScheduleGenerator = struct {
    cost_model: CostModel,
    allocator: std.mem.Allocator,
    
    pub fn init(allocator: std.mem.Allocator, hardware: HardwareFeatures) ScheduleGenerator {
        return .{
            .cost_model = CostModel.init(hardware),
            .allocator = allocator,
        };
    }
    
    pub fn generateSchedule(self: *ScheduleGenerator, node: *const IRNode) !Schedule {
        var schedule = Schedule.init(self.allocator);
        
        // Heuristic schedule generation based on operation type
        switch (node.op_type) {
            .matmul => {
                // Tile for cache
                try schedule.addStep(ScheduleStep.tile(0, 32)); // M
                try schedule.addStep(ScheduleStep.tile(1, 32)); // N
                try schedule.addStep(ScheduleStep.tile(2, 32)); // K
                // Parallelize outer loop
                try schedule.addStep(ScheduleStep.parallel(0));
                // Vectorize inner loop
                try schedule.addStep(ScheduleStep.vectorize(1, @intCast(self.cost_model.hardware.simd_width / 32)));
            },
            .conv2d => {
                // Tile spatial dimensions
                try schedule.addStep(ScheduleStep.tile(1, 28)); // H
                try schedule.addStep(ScheduleStep.tile(2, 28)); // W
                // Parallelize batch
                try schedule.addStep(ScheduleStep.parallel(0));
                // Vectorize output channels
                try schedule.addStep(ScheduleStep.vectorize(3, @intCast(self.cost_model.hardware.simd_width / 32)));
            },
            .add, .sub, .mul, .div, .relu => {
                // Simple element-wise: parallelize and vectorize
                try schedule.addStep(ScheduleStep.parallel(0));
                try schedule.addStep(ScheduleStep.vectorize(node.num_dims - 1, @intCast(self.cost_model.hardware.simd_width / 32)));
            },
            else => {
                // Default: just parallelize
                try schedule.addStep(ScheduleStep.parallel(0));
            },
        }
        
        // Calculate predicted speedup
        const base_cost = self.cost_model.predict(node);
        const scheduled_cost = self.cost_model.predictWithSchedule(node, &schedule);
        
        if (scheduled_cost.cycles > 0) {
            schedule.predicted_speedup = @as(f64, @floatFromInt(base_cost.cycles)) / 
                                         @as(f64, @floatFromInt(scheduled_cost.cycles));
        }
        
        return schedule;
    }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TESTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

test "golden_identity" {
    const phi_sq = PHI * PHI;
    const inv_phi_sq = 1.0 / phi_sq;
    try std.testing.expectApproxEqAbs(@as(f64, 3.0), phi_sq + inv_phi_sq, 0.0001);
}

test "phoenix_number" {
    try std.testing.expectEqual(@as(usize, 999), PHOENIX);
    try std.testing.expectEqual(@as(usize, 27 * 37), PHOENIX);
}

test "ir_node_creation" {
    var node = IRNode.init(1, .matmul);
    node.setShape(&[_]usize{ 1024, 1024 });
    node.data_type = .f32;
    
    try std.testing.expectEqual(@as(usize, 1024 * 1024), node.totalElements());
    try std.testing.expectEqual(@as(usize, 1024 * 1024 * 4), node.memoryBytes());
}

test "cost_model_prediction" {
    const hardware = HardwareFeatures.x86_64_avx2();
    const cost_model = CostModel.init(hardware);
    
    var node = IRNode.init(1, .matmul);
    node.setShape(&[_]usize{ 1024, 1024 });
    node.data_type = .f32;
    
    const prediction = cost_model.predict(&node);
    
    try std.testing.expect(prediction.cycles > 0);
    try std.testing.expect(prediction.confidence > 0.0);
}

test "schedule_generation" {
    const allocator = std.testing.allocator;
    const hardware = HardwareFeatures.x86_64_avx2();
    var generator = ScheduleGenerator.init(allocator, hardware);
    
    var node = IRNode.init(1, .matmul);
    node.setShape(&[_]usize{ 1024, 1024 });
    
    var schedule = try generator.generateSchedule(&node);
    defer schedule.deinit();
    
    try std.testing.expect(schedule.steps.items.len > 0);
    try std.testing.expect(schedule.predicted_speedup >= 1.0);
}

test "hardware_features" {
    const avx2 = HardwareFeatures.x86_64_avx2();
    const avx512 = HardwareFeatures.x86_64_avx512();
    
    try std.testing.expect(avx512.simd_width > avx2.simd_width);
    try std.testing.expect(avx512.peakFlopsPerSecond() > avx2.peakFlopsPerSecond());
}

test "schedule_step_creation" {
    const tile_step = ScheduleStep.tile(0, 32);
    try std.testing.expectEqual(ScheduleAction.tile, tile_step.action);
    try std.testing.expectEqual(@as(u32, 32), tile_step.param1);
    
    const vec_step = ScheduleStep.vectorize(1, 8);
    try std.testing.expectEqual(ScheduleAction.vectorize, vec_step.action);
}
