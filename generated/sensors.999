// ═══════════════════════════════════════════════════════════════
// SENSORS.999
// Generated from: specs/sensors.vibee
// DO NOT EDIT MANUALLY - Regenerate from specification
// ═══════════════════════════════════════════════════════════════

module sensors

// ═══════════════════════════════════════════════════════════════
// RECORDS
// ═══════════════════════════════════════════════════════════════

record MouseData {
  x: float := 0
  y: float := 0
  vx: float := 0
  vy: float := 0
  vel: float := 0
  down: bool := false
}

record AudioData {
  vol: float := 0      // 0-1
  freq: float := 0     // Hz
  fft: [float] := []   // 64 bins
  beat: bool := false
}

record MotionData {
  a: float := 0        // alpha (z rotation)
  b: float := 0        // beta (x rotation)
  g: float := 0        // gamma (y rotation)
}

record TimeData {
  h: int := 0          // hour 0-23
  m: int := 0          // minute 0-59
  s: int := 0          // second 0-59
  p: float := 0        // day progress 0-1
}

record ScreenData {
  w: float := 0
  h: float := 0
}

record SensorState {
  mouse: MouseData
  audio: AudioData
  motion: MotionData
  light: float := 0.5
  time: TimeData
  screen: ScreenData
}

// ═══════════════════════════════════════════════════════════════
// SENSORS ATOM
// 9 channels (3²)
// ═══════════════════════════════════════════════════════════════

atom Sensors {
  state := SensorState {
    mouse: MouseData {},
    audio: AudioData { fft: array(64, 0) },
    motion: MotionData {},
    light: 0.5,
    time: TimeData {},
    screen: ScreenData {}
  }
  
  // Previous mouse position for velocity
  prev_x := 0
  prev_y := 0
  
  // Audio context
  audio_ctx := null
  analyser := null
  fft_data := null
  
  on :init(window, document) ->
    setup_mouse(document)
    setup_touch(document)
    setup_keyboard(document)
    setup_audio()
    setup_motion(window)
    setup_light(window)
    setup_screen(window)
    log("Sensors initialized: 9 channels")
  
  // ═══════════════════════════════════════════════════════════════
  // MOUSE (Channel 0)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_mouse(document) := {
    document.addEventListener("mousemove", fn(e) {
      state.mouse.vx = e.clientX - prev_x
      state.mouse.vy = e.clientY - prev_y
      state.mouse.vel = sqrt(state.mouse.vx^2 + state.mouse.vy^2)
      state.mouse.x = e.clientX
      state.mouse.y = e.clientY
      prev_x = e.clientX
      prev_y = e.clientY
    })
    
    document.addEventListener("mousedown", fn(e) {
      state.mouse.down = true
    })
    
    document.addEventListener("mouseup", fn(e) {
      state.mouse.down = false
    })
  }
  
  // ═══════════════════════════════════════════════════════════════
  // TOUCH (Channel 1)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_touch(document) := {
    document.addEventListener("touchmove", fn(e) {
      e.preventDefault()
      t := e.touches[0]
      state.mouse.x = t.clientX
      state.mouse.y = t.clientY
      state.mouse.vel = 10
    }, { passive: false })
  }
  
  // ═══════════════════════════════════════════════════════════════
  // KEYBOARD (Channel 2)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_keyboard(document) := {
    // Keyboard events handled separately if needed
  }
  
  // ═══════════════════════════════════════════════════════════════
  // AUDIO (Channel 3)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_audio() := {
    navigator.mediaDevices?.getUserMedia({ audio: true })
      .then(fn(stream) {
        audio_ctx = new AudioContext()
        analyser = audio_ctx.createAnalyser()
        analyser.fftSize = 128
        fft_data = new Uint8Array(64)
        audio_ctx.createMediaStreamSource(stream).connect(analyser)
      })
      .catch(fn(e) {
        log("Audio not available")
      })
  }
  
  fn read_audio() := {
    if analyser == null { return }
    
    analyser.getByteFrequencyData(fft_data)
    
    sum := 0
    max_val := 0
    max_idx := 0
    
    for i in 0..64 {
      sum = sum + fft_data[i]^2
      if fft_data[i] > max_val {
        max_val = fft_data[i]
        max_idx = i
      }
    }
    
    state.audio.vol = sqrt(sum / 64) / 255
    state.audio.freq = max_idx * audio_ctx.sampleRate / 128
    state.audio.beat = state.audio.vol > 0.6
    
    for i in 0..64 {
      state.audio.fft[i] = fft_data[i] / 255
    }
  }
  
  // ═══════════════════════════════════════════════════════════════
  // MOTION (Channel 5)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_motion(window) := {
    window.addEventListener("deviceorientation", fn(e) {
      state.motion.a = e.alpha || 0
      state.motion.b = e.beta || 0
      state.motion.g = e.gamma || 0
    })
  }
  
  // ═══════════════════════════════════════════════════════════════
  // LIGHT (Channel 6)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_light(window) := {
    if window.matchMedia {
      dark := window.matchMedia("(prefers-color-scheme: dark)")
      state.light = dark.matches ? 0.2 : 0.8
    }
  }
  
  // ═══════════════════════════════════════════════════════════════
  // SCREEN (Channel 8 - part of time/screen)
  // ═══════════════════════════════════════════════════════════════
  
  fn setup_screen(window) := {
    update := fn() {
      state.screen.w = window.innerWidth
      state.screen.h = window.innerHeight
    }
    window.addEventListener("resize", update)
    update()
  }
  
  // ═══════════════════════════════════════════════════════════════
  // TIME (Channel 8)
  // ═══════════════════════════════════════════════════════════════
  
  fn read_time() := {
    d := new Date()
    state.time.h = d.getHours()
    state.time.m = d.getMinutes()
    state.time.s = d.getSeconds()
    state.time.p = (state.time.h * 3600 + state.time.m * 60 + state.time.s) / 86400
  }
  
  // ═══════════════════════════════════════════════════════════════
  // READ ALL
  // ═══════════════════════════════════════════════════════════════
  
  on :read() ->
    read_time()
    read_audio()
    state
  
  on :get(channel) ->
    match channel {
      "mouse" -> state.mouse
      "audio" -> state.audio
      "motion" -> state.motion
      "light" -> state.light
      "time" -> state.time
      "screen" -> state.screen
      _ -> null
    }
}

// ═══════════════════════════════════════════════════════════════
// NEURAL ENCODING
// 9 inputs for Neural999
// ═══════════════════════════════════════════════════════════════

fn encode_for_neural(state: SensorState) -> [float] := [
  state.mouse.x / state.screen.w,           // 0: position_x
  state.mouse.y / state.screen.h,           // 1: position_y
  min(state.mouse.vel / 100, 1),            // 2: velocity
  state.audio.vol,                          // 3: audio_volume
  state.audio.freq / 1000,                  // 4: audio_frequency
  state.light,                              // 5: light_level
  (state.motion.b + 180) / 360,             // 6: tilt_x
  (state.motion.g + 90) / 180,              // 7: tilt_y
  state.time.p                              // 8: time_progress
]

// ═══════════════════════════════════════════════════════════════
// EXPORTS
// ═══════════════════════════════════════════════════════════════

export { Sensors, SensorState, MouseData, AudioData, TimeData, encode_for_neural }
