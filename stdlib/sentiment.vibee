// =============================================================================
// Vibee OS â€” Sentiment Analysis Module
// Text sentiment and emotion analysis for NLP
// =============================================================================

use nlp_tokenizer::{Token, WordTokenizer, Tokenizer, tokenize}

// =============================================================================
// Sentiment Types
// =============================================================================

/// Sentiment polarity
enum Sentiment {
    Positive
    Negative
    Neutral
    Mixed
}

impl Display for Sentiment {
    fn fmt(f: Formatter) {
        match self {
            Positive => f.write("POSITIVE"),
            Negative => f.write("NEGATIVE"),
            Neutral => f.write("NEUTRAL"),
            Mixed => f.write("MIXED")
        }
    }
}

/// Detailed sentiment result
struct SentimentResult {
    sentiment: Sentiment
    score: Float           // -1.0 to 1.0
    confidence: Float      // 0.0 to 1.0
    positive_score: Float
    negative_score: Float
    neutral_score: Float
    
    fn new(score: Float) -> Self {
        let sentiment = if score > 0.1 { Sentiment.Positive }
                       else if score < -0.1 { Sentiment.Negative }
                       else { Sentiment.Neutral }
        
        SentimentResult {
            sentiment: sentiment,
            score: score,
            confidence: score.abs(),
            positive_score: if score > 0.0 { score } else { 0.0 },
            negative_score: if score < 0.0 { -score } else { 0.0 },
            neutral_score: 1.0 - score.abs()
        }
    }
    
    fn is_positive() -> Bool { matches!(self.sentiment, Sentiment.Positive) }
    fn is_negative() -> Bool { matches!(self.sentiment, Sentiment.Negative) }
    fn is_neutral() -> Bool { matches!(self.sentiment, Sentiment.Neutral) }
}

impl Display for SentimentResult {
    fn fmt(f: Formatter) {
        f.write(format!("SentimentResult({}, score={:.3}, conf={:.3})", 
            self.sentiment, self.score, self.confidence))
    }
}

// =============================================================================
// Emotion Types
// =============================================================================

/// Basic emotions (Ekman's model)
enum Emotion {
    Joy
    Sadness
    Anger
    Fear
    Surprise
    Disgust
    Trust
    Anticipation
    Neutral
}

impl Display for Emotion {
    fn fmt(f: Formatter) {
        match self {
            Joy => f.write("JOY"),
            Sadness => f.write("SADNESS"),
            Anger => f.write("ANGER"),
            Fear => f.write("FEAR"),
            Surprise => f.write("SURPRISE"),
            Disgust => f.write("DISGUST"),
            Trust => f.write("TRUST"),
            Anticipation => f.write("ANTICIPATION"),
            Neutral => f.write("NEUTRAL")
        }
    }
}

/// Emotion analysis result
struct EmotionResult {
    primary_emotion: Emotion
    emotions: Map<Emotion, Float>
    confidence: Float
    
    fn new(emotions: Map<Emotion, Float>) -> Self {
        let (primary, score) = emotions.iter()
            .max_by_key(|(_, v)| v)
            .unwrap_or((Emotion.Neutral, 0.0))
        
        EmotionResult {
            primary_emotion: primary,
            emotions: emotions,
            confidence: score
        }
    }
    
    fn get_score(emotion: Emotion) -> Float {
        self.emotions.get(emotion).unwrap_or(0.0)
    }
}

// =============================================================================
// Sentiment Analyzer Trait
// =============================================================================

/// Base trait for sentiment analyzers
trait SentimentAnalyzer {
    fn analyze(text: String) -> SentimentResult
    fn analyze_batch(texts: [String]) -> [SentimentResult] {
        texts.map(|t| self.analyze(t))
    }
}

// =============================================================================
// Lexicon-Based Sentiment Analyzer
// =============================================================================

/// Lexicon-based sentiment analyzer
struct LexiconAnalyzer {
    positive_words: Map<String, Float>
    negative_words: Map<String, Float>
    intensifiers: Map<String, Float>
    negators: Set<String>
    
    fn new() -> Self {
        LexiconAnalyzer {
            positive_words: default_positive_lexicon(),
            negative_words: default_negative_lexicon(),
            intensifiers: default_intensifiers(),
            negators: default_negators()
        }
    }
    
    fn with_lexicons(positive: Map<String, Float>, negative: Map<String, Float>) -> Self {
        LexiconAnalyzer {
            positive_words: positive,
            negative_words: negative,
            intensifiers: default_intensifiers(),
            negators: default_negators()
        }
    }
    
    fn add_positive(word: String, score: Float) -> Self {
        self.positive_words.insert(word.to_lowercase(), score)
        self
    }
    
    fn add_negative(word: String, score: Float) -> Self {
        self.negative_words.insert(word.to_lowercase(), score)
        self
    }
}

impl SentimentAnalyzer for LexiconAnalyzer {
    fn analyze(text: String) -> SentimentResult {
        let tokens = tokenize(text)
        var total_score = 0.0
        var word_count = 0
        var negation_active = false
        var intensifier_mult = 1.0
        
        for i in 0..tokens.len() {
            let word = tokens[i].to_lowercase()
            
            // Check for negators
            if self.negators.contains(word) {
                negation_active = true
                continue
            }
            
            // Check for intensifiers
            if let Some(mult) = self.intensifiers.get(word) {
                intensifier_mult = mult
                continue
            }
            
            // Calculate word score
            var word_score = 0.0
            if let Some(score) = self.positive_words.get(word) {
                word_score = score
            } else if let Some(score) = self.negative_words.get(word) {
                word_score = -score
            }
            
            if word_score != 0.0 {
                // Apply negation
                if negation_active {
                    word_score = -word_score * 0.5
                    negation_active = false
                }
                
                // Apply intensifier
                word_score *= intensifier_mult
                intensifier_mult = 1.0
                
                total_score += word_score
                word_count += 1
            }
        }
        
        let final_score = if word_count > 0 { total_score / word_count as Float } else { 0.0 }
        SentimentResult.new(final_score.clamp(-1.0, 1.0))
    }
}

// =============================================================================
// VADER-like Sentiment Analyzer
// =============================================================================

/// VADER-inspired sentiment analyzer
struct VADERAnalyzer {
    lexicon: Map<String, Float>
    
    fn new() -> Self {
        VADERAnalyzer { lexicon: vader_lexicon() }
    }
}

impl SentimentAnalyzer for VADERAnalyzer {
    fn analyze(text: String) -> SentimentResult {
        let tokens = tokenize(text)
        var sentiments: [Float] = []
        
        for i in 0..tokens.len() {
            let word = tokens[i].to_lowercase()
            
            if let Some(score) = self.lexicon.get(word) {
                var adjusted_score = score
                
                // Check for negation in previous 3 words
                for j in (i.saturating_sub(3))..i {
                    if is_negator(tokens[j]) {
                        adjusted_score *= -0.5
                        break
                    }
                }
                
                // Check for intensifiers
                if i > 0 && is_intensifier(tokens[i - 1]) {
                    adjusted_score *= 1.5
                }
                
                // Check for ALL CAPS (emphasis)
                if tokens[i].chars().all(|c| c.is_uppercase()) && tokens[i].len() > 1 {
                    adjusted_score *= 1.2
                }
                
                sentiments.push(adjusted_score)
            }
        }
        
        // Check for exclamation marks (amplify)
        let exclamation_count = text.chars().filter(|c| c == '!').count()
        let exclamation_boost = (exclamation_count as Float * 0.1).min(0.5)
        
        // Check for question marks (reduce confidence)
        let question_count = text.chars().filter(|c| c == '?').count()
        
        let raw_score = if sentiments.is_empty() { 0.0 } 
                       else { sentiments.iter().sum() / sentiments.len() as Float }
        
        let final_score = (raw_score + exclamation_boost * raw_score.signum()).clamp(-1.0, 1.0)
        
        var result = SentimentResult.new(final_score)
        if question_count > 0 {
            result.confidence *= 0.8
        }
        result
    }
}

// =============================================================================
// Aspect-Based Sentiment
// =============================================================================

/// Aspect-based sentiment result
struct AspectSentiment {
    aspect: String
    sentiment: SentimentResult
    mentions: [String]
    
    fn new(aspect: String, sentiment: SentimentResult) -> Self {
        AspectSentiment {
            aspect: aspect,
            sentiment: sentiment,
            mentions: []
        }
    }
}

/// Aspect-based sentiment analyzer
struct AspectAnalyzer {
    aspects: Map<String, [String]>  // aspect -> keywords
    base_analyzer: LexiconAnalyzer
    
    fn new() -> Self {
        AspectAnalyzer {
            aspects: Map.empty(),
            base_analyzer: LexiconAnalyzer.new()
        }
    }
    
    fn add_aspect(name: String, keywords: [String]) -> Self {
        self.aspects.insert(name, keywords)
        self
    }
    
    fn analyze_aspects(text: String) -> [AspectSentiment] {
        var results: [AspectSentiment] = []
        let sentences = split_sentences(text)
        
        for (aspect, keywords) in self.aspects {
            var aspect_sentences: [String] = []
            
            for sentence in sentences {
                let lower = sentence.to_lowercase()
                if keywords.iter().any(|k| lower.contains(k)) {
                    aspect_sentences.push(sentence)
                }
            }
            
            if !aspect_sentences.is_empty() {
                let combined = aspect_sentences.join(" ")
                let sentiment = self.base_analyzer.analyze(combined)
                var result = AspectSentiment.new(aspect, sentiment)
                result.mentions = aspect_sentences
                results.push(result)
            }
        }
        
        results
    }
}

// =============================================================================
// Emotion Analyzer
// =============================================================================

/// Emotion analyzer using lexicon
struct EmotionAnalyzer {
    emotion_lexicon: Map<String, Map<Emotion, Float>>
    
    fn new() -> Self {
        EmotionAnalyzer { emotion_lexicon: default_emotion_lexicon() }
    }
    
    fn analyze(text: String) -> EmotionResult {
        let tokens = tokenize(text)
        var emotion_scores: Map<Emotion, Float> = Map.from_iter([
            (Emotion.Joy, 0.0), (Emotion.Sadness, 0.0), (Emotion.Anger, 0.0),
            (Emotion.Fear, 0.0), (Emotion.Surprise, 0.0), (Emotion.Disgust, 0.0),
            (Emotion.Trust, 0.0), (Emotion.Anticipation, 0.0)
        ])
        
        var word_count = 0
        for word in tokens {
            let lower = word.to_lowercase()
            if let Some(emotions) = self.emotion_lexicon.get(lower) {
                for (emotion, score) in emotions {
                    *emotion_scores.entry(emotion).or_insert(0.0) += score
                }
                word_count += 1
            }
        }
        
        // Normalize scores
        if word_count > 0 {
            for (_, score) in emotion_scores.iter_mut() {
                *score /= word_count as Float
            }
        }
        
        EmotionResult.new(emotion_scores)
    }
}

// =============================================================================
// Subjectivity Analyzer
// =============================================================================

/// Subjectivity analysis result
struct SubjectivityResult {
    subjectivity: Float  // 0.0 (objective) to 1.0 (subjective)
    polarity: Float      // -1.0 to 1.0
    
    fn is_objective() -> Bool { self.subjectivity < 0.4 }
    fn is_subjective() -> Bool { self.subjectivity > 0.6 }
}

/// Analyzes text subjectivity
struct SubjectivityAnalyzer {
    subjective_words: Set<String>
    objective_indicators: Set<String>
    
    fn new() -> Self {
        SubjectivityAnalyzer {
            subjective_words: default_subjective_words(),
            objective_indicators: default_objective_indicators()
        }
    }
    
    fn analyze(text: String) -> SubjectivityResult {
        let tokens = tokenize(text)
        var subjective_count = 0
        var objective_count = 0
        
        for word in tokens {
            let lower = word.to_lowercase()
            if self.subjective_words.contains(lower) {
                subjective_count += 1
            }
            if self.objective_indicators.contains(lower) {
                objective_count += 1
            }
        }
        
        let total = (subjective_count + objective_count) as Float
        let subjectivity = if total > 0.0 { subjective_count as Float / total } else { 0.5 }
        
        let sentiment = LexiconAnalyzer.new().analyze(text)
        
        SubjectivityResult {
            subjectivity: subjectivity,
            polarity: sentiment.score
        }
    }
}

// =============================================================================
// Sentiment Pipeline
// =============================================================================

/// Sentiment analysis pipeline
actor SentimentPipeline {
    state analyzers: [Box<dyn SentimentAnalyzer>]
    state aggregation: AggregationMethod
    
    fn new() -> Self {
        SentimentPipeline {
            analyzers: [Box.new(LexiconAnalyzer.new())],
            aggregation: AggregationMethod.Average
        }
    }
    
    fn add_analyzer(analyzer: impl SentimentAnalyzer) -> Self {
        self.analyzers.push(Box.new(analyzer))
        self
    }
    
    fn with_aggregation(method: AggregationMethod) -> Self {
        self.aggregation = method
        self
    }
    
    fn analyze(text: String) -> SentimentResult {
        let results: [SentimentResult] = self.analyzers.iter()
            .map(|a| a.analyze(text))
            .collect()
        
        aggregate_results(results, self.aggregation)
    }
}

enum AggregationMethod {
    Average
    Weighted
    Voting
    Max
}

fn aggregate_results(results: [SentimentResult], method: AggregationMethod) -> SentimentResult {
    if results.is_empty() { return SentimentResult.new(0.0) }
    
    match method {
        AggregationMethod.Average => {
            let avg_score = results.iter().map(|r| r.score).sum() / results.len() as Float
            SentimentResult.new(avg_score)
        }
        AggregationMethod.Max => {
            let max_result = results.iter().max_by_key(|r| r.confidence).unwrap()
            max_result
        }
        AggregationMethod.Voting => {
            var positive = 0
            var negative = 0
            var neutral = 0
            for r in results {
                match r.sentiment {
                    Sentiment.Positive => positive += 1,
                    Sentiment.Negative => negative += 1,
                    _ => neutral += 1
                }
            }
            let score = (positive - negative) as Float / results.len() as Float
            SentimentResult.new(score)
        }
        _ => SentimentResult.new(results[0].score)
    }
}

// =============================================================================
// Helper Functions
// =============================================================================

fn split_sentences(text: String) -> [String] {
    text.split(|c| c == '.' || c == '!' || c == '?')
        .map(|s| s.trim())
        .filter(|s| !s.is_empty())
        .collect()
}

fn is_negator(word: String) -> Bool {
    let negators = ["not", "no", "never", "neither", "nobody", "nothing", "nowhere", 
                   "hardly", "barely", "scarcely", "don't", "doesn't", "didn't", 
                   "won't", "wouldn't", "couldn't", "shouldn't", "can't", "isn't", "aren't"]
    negators.contains(word.to_lowercase().as_str())
}

fn is_intensifier(word: String) -> Bool {
    let intensifiers = ["very", "really", "extremely", "absolutely", "completely", 
                       "totally", "utterly", "highly", "incredibly", "remarkably"]
    intensifiers.contains(word.to_lowercase().as_str())
}

fn default_positive_lexicon() -> Map<String, Float> {
    Map.from_iter([
        ("good", 0.7), ("great", 0.9), ("excellent", 1.0), ("amazing", 0.95),
        ("wonderful", 0.9), ("fantastic", 0.95), ("awesome", 0.9), ("love", 0.9),
        ("like", 0.5), ("happy", 0.8), ("joy", 0.9), ("beautiful", 0.8),
        ("best", 1.0), ("perfect", 1.0), ("brilliant", 0.9), ("outstanding", 0.95),
        ("superb", 0.9), ("nice", 0.6), ("pleasant", 0.6), ("delightful", 0.8),
        ("positive", 0.7), ("recommend", 0.7), ("enjoy", 0.7), ("impressed", 0.8),
        ("satisfied", 0.7), ("helpful", 0.6), ("friendly", 0.6), ("easy", 0.5),
        ("fast", 0.5), ("reliable", 0.6), ("quality", 0.6), ("value", 0.5)
    ].iter().map(|(k, v)| (k.to_string(), *v)))
}

fn default_negative_lexicon() -> Map<String, Float> {
    Map.from_iter([
        ("bad", 0.7), ("terrible", 1.0), ("awful", 0.95), ("horrible", 0.95),
        ("poor", 0.7), ("worst", 1.0), ("hate", 0.9), ("dislike", 0.6),
        ("disappointing", 0.8), ("disappointed", 0.8), ("sad", 0.7), ("angry", 0.8),
        ("frustrating", 0.8), ("frustrated", 0.8), ("annoying", 0.7), ("annoyed", 0.7),
        ("useless", 0.8), ("waste", 0.7), ("broken", 0.8), ("fail", 0.8),
        ("failed", 0.8), ("failure", 0.9), ("problem", 0.6), ("issue", 0.5),
        ("bug", 0.6), ("error", 0.6), ("slow", 0.5), ("difficult", 0.5),
        ("confusing", 0.6), ("complicated", 0.5), ("expensive", 0.5), ("overpriced", 0.7),
        ("rude", 0.8), ("unhelpful", 0.7), ("unreliable", 0.7), ("negative", 0.7)
    ].iter().map(|(k, v)| (k.to_string(), *v)))
}

fn default_intensifiers() -> Map<String, Float> {
    Map.from_iter([
        ("very", 1.5), ("really", 1.4), ("extremely", 1.8), ("absolutely", 1.7),
        ("completely", 1.6), ("totally", 1.5), ("utterly", 1.7), ("highly", 1.4),
        ("incredibly", 1.6), ("remarkably", 1.5), ("quite", 1.2), ("rather", 1.1),
        ("somewhat", 0.8), ("slightly", 0.6), ("barely", 0.4), ("hardly", 0.3)
    ].iter().map(|(k, v)| (k.to_string(), *v)))
}

fn default_negators() -> Set<String> {
    Set.from_iter([
        "not", "no", "never", "neither", "nobody", "nothing", "nowhere",
        "hardly", "barely", "scarcely", "don't", "doesn't", "didn't",
        "won't", "wouldn't", "couldn't", "shouldn't", "can't", "isn't", "aren't",
        "wasn't", "weren't", "haven't", "hasn't", "hadn't"
    ].iter().map(|s| s.to_string()))
}

fn vader_lexicon() -> Map<String, Float> {
    var lexicon = default_positive_lexicon()
    for (word, score) in default_negative_lexicon() {
        lexicon.insert(word, -score)
    }
    lexicon
}

fn default_emotion_lexicon() -> Map<String, Map<Emotion, Float>> {
    Map.from_iter([
        ("happy", Map.from_iter([(Emotion.Joy, 0.9)])),
        ("sad", Map.from_iter([(Emotion.Sadness, 0.9)])),
        ("angry", Map.from_iter([(Emotion.Anger, 0.9)])),
        ("afraid", Map.from_iter([(Emotion.Fear, 0.9)])),
        ("surprised", Map.from_iter([(Emotion.Surprise, 0.9)])),
        ("disgusted", Map.from_iter([(Emotion.Disgust, 0.9)])),
        ("trust", Map.from_iter([(Emotion.Trust, 0.8)])),
        ("anticipate", Map.from_iter([(Emotion.Anticipation, 0.8)])),
        ("love", Map.from_iter([(Emotion.Joy, 0.8), (Emotion.Trust, 0.6)])),
        ("hate", Map.from_iter([(Emotion.Anger, 0.8), (Emotion.Disgust, 0.5)])),
        ("fear", Map.from_iter([(Emotion.Fear, 1.0)])),
        ("joy", Map.from_iter([(Emotion.Joy, 1.0)])),
        ("excitement", Map.from_iter([(Emotion.Joy, 0.7), (Emotion.Anticipation, 0.7)])),
        ("worry", Map.from_iter([(Emotion.Fear, 0.6), (Emotion.Anticipation, 0.4)])),
        ("hope", Map.from_iter([(Emotion.Anticipation, 0.8), (Emotion.Trust, 0.5)]))
    ].iter().map(|(k, v)| (k.to_string(), v.clone())))
}

fn default_subjective_words() -> Set<String> {
    Set.from_iter([
        "think", "believe", "feel", "opinion", "seems", "appears",
        "probably", "maybe", "perhaps", "might", "could", "should",
        "best", "worst", "better", "worse", "good", "bad", "great", "terrible",
        "love", "hate", "like", "dislike", "prefer", "favorite"
    ].iter().map(|s| s.to_string()))
}

fn default_objective_indicators() -> Set<String> {
    Set.from_iter([
        "is", "are", "was", "were", "has", "have", "had",
        "according", "reported", "stated", "announced", "confirmed",
        "percent", "number", "data", "study", "research", "found"
    ].iter().map(|s| s.to_string()))
}

// =============================================================================
// Convenience Functions
// =============================================================================

/// Analyze sentiment of text
fn analyze(text: String) -> SentimentResult {
    LexiconAnalyzer.new().analyze(text)
}

/// Quick sentiment check
fn is_positive(text: String) -> Bool {
    analyze(text).is_positive()
}

fn is_negative(text: String) -> Bool {
    analyze(text).is_negative()
}

fn is_neutral(text: String) -> Bool {
    analyze(text).is_neutral()
}

/// Get sentiment score (-1.0 to 1.0)
fn sentiment_score(text: String) -> Float {
    analyze(text).score
}

/// Analyze emotions
fn analyze_emotions(text: String) -> EmotionResult {
    EmotionAnalyzer.new().analyze(text)
}

/// Get primary emotion
fn primary_emotion(text: String) -> Emotion {
    analyze_emotions(text).primary_emotion
}

// =============================================================================
// Tests
// =============================================================================

test "positive sentiment" {
    let result = analyze("This is a great and wonderful product!")
    assert(result.is_positive())?
    assert(result.score > 0.5)?
}

test "negative sentiment" {
    let result = analyze("This is terrible and awful")
    assert(result.is_negative())?
    assert(result.score < -0.5)?
}

test "neutral sentiment" {
    let result = analyze("The product is available in stores")
    assert(result.score.abs() < 0.3)?
}

test "negation handling" {
    let result = analyze("This is not good")
    assert(result.score < 0.0)?
}

test "intensifier handling" {
    let strong = analyze("This is very good")
    let weak = analyze("This is good")
    assert(strong.score > weak.score)?
}

test "vader analyzer" {
    let analyzer = VADERAnalyzer.new()
    let result = analyzer.analyze("I LOVE this! Amazing!")
    assert(result.is_positive())?
    assert(result.score > 0.7)?
}

test "emotion analysis" {
    let result = analyze_emotions("I am so happy and excited!")
    assert(matches!(result.primary_emotion, Emotion.Joy))?
}

test "aspect sentiment" {
    let analyzer = AspectAnalyzer.new()
        .add_aspect("price", ["price", "cost", "expensive", "cheap"])
        .add_aspect("quality", ["quality", "durable", "broken"])
    
    let results = analyzer.analyze_aspects("The price is too expensive but the quality is excellent")
    assert_eq(results.len(), 2)?
}

test "subjectivity" {
    let analyzer = SubjectivityAnalyzer.new()
    
    let subjective = analyzer.analyze("I think this is the best product ever")
    assert(subjective.is_subjective())?
    
    let objective = analyzer.analyze("The study found that 50 percent of users reported improvements")
    assert(objective.subjectivity < subjective.subjectivity)?
}

test "sentiment pipeline" {
    let pipeline = SentimentPipeline.new()
        .add_analyzer(VADERAnalyzer.new())
        .with_aggregation(AggregationMethod.Average)
    
    let result = pipeline.analyze("Great product, highly recommended!")
    assert(result.is_positive())?
}
