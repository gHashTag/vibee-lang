// =============================================================================
// Vibee OS â€” Profiler Module
// Performance profiling and analysis
// =============================================================================

// -----------------------------------------------------------------------------
// Profiler Configuration
// -----------------------------------------------------------------------------

/// Profiler configuration
struct ProfilerConfig {
    sample_rate_hz: Int
    stack_depth: Int
    track_allocations: Bool
    track_io: Bool
    track_locks: Bool
    output_format: OutputFormat
    
    fn default() -> Self {
        ProfilerConfig {
            sample_rate_hz: 1000,
            stack_depth: 64,
            track_allocations: true,
            track_io: true,
            track_locks: true,
            output_format: OutputFormat.Text
        }
    }
    
    fn high_frequency() -> Self {
        ProfilerConfig {
            sample_rate_hz: 10000,
            stack_depth: 128,
            track_allocations: true,
            track_io: true,
            track_locks: true,
            output_format: OutputFormat.Text
        }
    }
    
    fn low_overhead() -> Self {
        ProfilerConfig {
            sample_rate_hz: 100,
            stack_depth: 32,
            track_allocations: false,
            track_io: false,
            track_locks: false,
            output_format: OutputFormat.Text
        }
    }
}

enum OutputFormat {
    Text
    Json
    Flamegraph
    Callgrind
    Chrome
}

// -----------------------------------------------------------------------------
// Main Profiler
// -----------------------------------------------------------------------------

/// CPU profiler
actor Profiler {
    state config: ProfilerConfig
    state running: Bool
    state samples: [Sample]
    state start_time: Option<Instant>
    state functions: Map<String, FunctionStats>
    state call_graph: CallGraph
    state allocations: [AllocationSample]
    state io_events: [IoEvent]
    state lock_events: [LockEvent]
    
    fn new() -> Self {
        Self.with_config(ProfilerConfig.default())
    }
    
    fn with_config(config: ProfilerConfig) -> Self {
        Profiler {
            config: config,
            running: false,
            samples: [],
            start_time: None,
            functions: Map.new(),
            call_graph: CallGraph.new(),
            allocations: [],
            io_events: [],
            lock_events: []
        }
    }
    
    /// Start profiling
    on start() {
        if self.running { return }
        
        self.running = true
        self.start_time = Some(Instant.now())
        self.samples.clear()
        self.functions.clear()
        self.call_graph = CallGraph.new()
        self.allocations.clear()
        self.io_events.clear()
        self.lock_events.clear()
        
        // Start sampling thread
        spawn { self.sample_loop() }
        
        // Register hooks
        if self.config.track_allocations {
            @native("profiler_hook_allocations", self)
        }
        if self.config.track_io {
            @native("profiler_hook_io", self)
        }
        if self.config.track_locks {
            @native("profiler_hook_locks", self)
        }
    }
    
    /// Stop profiling
    on stop() -> ProfileResult {
        if !self.running { return ProfileResult.empty() }
        
        self.running = false
        
        // Unhook
        @native("profiler_unhook_all")
        
        let duration = self.start_time.map(|s| s.elapsed()).unwrap_or(Duration.zero())
        
        ProfileResult {
            duration: duration,
            sample_count: self.samples.len(),
            functions: self.functions.clone(),
            call_graph: self.call_graph.clone(),
            allocations: self.allocations.clone(),
            io_events: self.io_events.clone(),
            lock_events: self.lock_events.clone()
        }
    }
    
    fn sample_loop() {
        let interval = Duration.micros(1_000_000 / self.config.sample_rate_hz)
        
        while self.running {
            let sample = self.capture_sample()
            self.samples.push(sample)
            self.process_sample(sample)
            
            @native("sleep", interval)
        }
    }
    
    fn capture_sample() -> Sample {
        let stack = @native("capture_stack", self.config.stack_depth)
        let timestamp = Instant.now()
        let thread_id = @native("current_thread_id")
        
        Sample {
            timestamp: timestamp,
            thread_id: thread_id,
            stack: stack,
            cpu_time: @native("thread_cpu_time", thread_id)
        }
    }
    
    fn process_sample(sample: Sample) {
        // Update function stats
        for frame in sample.stack {
            let stats = self.functions.entry(frame.function)
                .or_insert(FunctionStats.new(frame.function))
            stats.samples += 1
            stats.total_time += sample.cpu_time
        }
        
        // Update call graph
        if sample.stack.len() >= 2 {
            for i in 0..(sample.stack.len() - 1) {
                let caller = sample.stack[i + 1].function
                let callee = sample.stack[i].function
                self.call_graph.add_edge(caller, callee)
            }
        }
    }
    
    /// Record allocation
    on record_allocation(size: Int, ptr: Int) {
        if !self.config.track_allocations { return }
        
        self.allocations.push(AllocationSample {
            timestamp: Instant.now(),
            size: size,
            address: ptr,
            stack: @native("capture_stack", 16),
            freed: false
        })
    }
    
    /// Record deallocation
    on record_deallocation(ptr: Int) {
        if !self.config.track_allocations { return }
        
        for alloc in self.allocations {
            if alloc.address == ptr {
                alloc.freed = true
                break
            }
        }
    }
    
    /// Record IO event
    on record_io(op: IoOp, bytes: Int, duration: Duration) {
        if !self.config.track_io { return }
        
        self.io_events.push(IoEvent {
            timestamp: Instant.now(),
            operation: op,
            bytes: bytes,
            duration: duration,
            stack: @native("capture_stack", 8)
        })
    }
    
    /// Record lock event
    on record_lock(op: LockOp, duration: Duration) {
        if !self.config.track_locks { return }
        
        self.lock_events.push(LockEvent {
            timestamp: Instant.now(),
            operation: op,
            duration: duration,
            stack: @native("capture_stack", 8)
        })
    }
    
    fn is_running() -> Bool { self.running }
}

// -----------------------------------------------------------------------------
// Data Structures
// -----------------------------------------------------------------------------

struct Sample {
    timestamp: Instant
    thread_id: Int
    stack: [StackFrame]
    cpu_time: Duration
}

struct StackFrame {
    function: String
    file: String
    line: Int
    module: String
}

struct FunctionStats {
    name: String
    samples: Int
    total_time: Duration
    self_time: Duration
    calls: Int
    
    fn new(name: String) -> Self {
        FunctionStats {
            name: name,
            samples: 0,
            total_time: Duration.zero(),
            self_time: Duration.zero(),
            calls: 0
        }
    }
    
    fn avg_time() -> Duration {
        if self.calls == 0 { Duration.zero() }
        else { Duration.nanos(self.total_time.as_nanos() / self.calls) }
    }
}

struct AllocationSample {
    timestamp: Instant
    size: Int
    address: Int
    stack: [StackFrame]
    freed: Bool
}

struct IoEvent {
    timestamp: Instant
    operation: IoOp
    bytes: Int
    duration: Duration
    stack: [StackFrame]
}

enum IoOp {
    Read
    Write
    Open
    Close
    Seek
    Sync
}

struct LockEvent {
    timestamp: Instant
    operation: LockOp
    duration: Duration
    stack: [StackFrame]
}

enum LockOp {
    Acquire
    Release
    Wait
    Contention
}

// -----------------------------------------------------------------------------
// Call Graph
// -----------------------------------------------------------------------------

struct CallGraph {
    nodes: Map<String, CallNode>
    edges: [(String, String, Int)]
    
    fn new() -> Self {
        CallGraph { nodes: Map.new(), edges: [] }
    }
    
    fn add_edge(caller: String, callee: String) {
        // Update or add edge
        var found = false
        for (c1, c2, count) in self.edges {
            if c1 == caller && c2 == callee {
                *count += 1
                found = true
                break
            }
        }
        
        if !found {
            self.edges.push((caller, callee, 1))
        }
        
        // Update nodes
        self.nodes.entry(caller).or_insert(CallNode.new(caller)).calls_out += 1
        self.nodes.entry(callee).or_insert(CallNode.new(callee)).calls_in += 1
    }
    
    fn hot_paths() -> [CallPath] {
        // Find paths with highest call counts
        var paths = []
        
        for (caller, callee, count) in self.edges.sorted_by(|(_, _, c)| -c) {
            paths.push(CallPath {
                frames: [caller, callee],
                count: count
            })
            
            if paths.len() >= 10 { break }
        }
        
        paths
    }
}

struct CallNode {
    name: String
    calls_in: Int
    calls_out: Int
    
    fn new(name: String) -> Self {
        CallNode { name: name, calls_in: 0, calls_out: 0 }
    }
}

struct CallPath {
    frames: [String]
    count: Int
}

// -----------------------------------------------------------------------------
// Profile Result
// -----------------------------------------------------------------------------

struct ProfileResult {
    duration: Duration
    sample_count: Int
    functions: Map<String, FunctionStats>
    call_graph: CallGraph
    allocations: [AllocationSample]
    io_events: [IoEvent]
    lock_events: [LockEvent]
    
    fn empty() -> Self {
        ProfileResult {
            duration: Duration.zero(),
            sample_count: 0,
            functions: Map.new(),
            call_graph: CallGraph.new(),
            allocations: [],
            io_events: [],
            lock_events: []
        }
    }
    
    /// Get top functions by sample count
    fn top_functions(n: Int) -> [FunctionStats] {
        self.functions.values()
            .sorted_by(|f| -f.samples)
            .take(n)
            .collect()
    }
    
    /// Get hot paths
    fn hot_paths() -> [CallPath] {
        self.call_graph.hot_paths()
    }
    
    /// Get memory leaks
    fn memory_leaks() -> [AllocationSample] {
        self.allocations.filter(|a| !a.freed).collect()
    }
    
    /// Get total allocated bytes
    fn total_allocated() -> Int {
        self.allocations.iter().map(|a| a.size).sum()
    }
    
    /// Get IO statistics
    fn io_stats() -> IoStats {
        var reads = 0
        var writes = 0
        var read_bytes = 0
        var write_bytes = 0
        var read_time = Duration.zero()
        var write_time = Duration.zero()
        
        for event in self.io_events {
            match event.operation {
                IoOp.Read => {
                    reads += 1
                    read_bytes += event.bytes
                    read_time += event.duration
                }
                IoOp.Write => {
                    writes += 1
                    write_bytes += event.bytes
                    write_time += event.duration
                }
                _ => {}
            }
        }
        
        IoStats {
            reads: reads,
            writes: writes,
            read_bytes: read_bytes,
            write_bytes: write_bytes,
            read_time: read_time,
            write_time: write_time
        }
    }
    
    /// Print summary report
    fn print_summary() {
        println("=== Profile Summary ===")
        println("Duration:    \(self.duration)")
        println("Samples:     \(self.sample_count)")
        println()
        
        println("Top Functions:")
        for (i, func) in self.top_functions(10).enumerate() {
            let percent = (func.samples as Float / self.sample_count as Float * 100.0).round(2)
            println("  \(i + 1). \(func.name): \(func.samples) samples (\(percent)%)")
        }
        println()
        
        if !self.allocations.is_empty() {
            println("Memory:")
            println("  Total allocated: \(format_bytes(self.total_allocated()))")
            println("  Allocations:     \(self.allocations.len())")
            println("  Leaks:           \(self.memory_leaks().len())")
            println()
        }
        
        if !self.io_events.is_empty() {
            let io = self.io_stats()
            println("I/O:")
            println("  Reads:  \(io.reads) (\(format_bytes(io.read_bytes)))")
            println("  Writes: \(io.writes) (\(format_bytes(io.write_bytes)))")
            println()
        }
        
        println("=======================")
    }
    
    /// Export to flamegraph format
    fn to_flamegraph() -> String {
        var lines = []
        
        for sample in self.samples {
            let stack = sample.stack.iter()
                .map(|f| f.function)
                .rev()
                .join(";")
            lines.push("\(stack) 1")
        }
        
        lines.join("\n")
    }
    
    /// Export to Chrome trace format
    fn to_chrome_trace() -> String {
        var events = []
        
        for (i, sample) in self.samples.enumerate() {
            for (j, frame) in sample.stack.enumerate() {
                events.push(format!(
                    r#"{{"name":"{}","cat":"cpu","ph":"X","ts":{},"dur":1000,"pid":1,"tid":{}}}"#,
                    frame.function,
                    sample.timestamp.as_micros(),
                    sample.thread_id
                ))
            }
        }
        
        "[\(events.join(",\n"))]"
    }
}

struct IoStats {
    reads: Int
    writes: Int
    read_bytes: Int
    write_bytes: Int
    read_time: Duration
    write_time: Duration
}

// -----------------------------------------------------------------------------
// Function Profiler
// -----------------------------------------------------------------------------

/// Profile specific function
macro profile_fn(name, body) {
    let __profiler_start = Instant.now()
    let __profiler_result = body
    let __profiler_elapsed = __profiler_start.elapsed()
    FUNCTION_PROFILER.record(name, __profiler_elapsed)
    __profiler_result
}

/// Function-level profiler
actor FunctionProfiler {
    state functions: Map<String, FunctionProfile>
    
    fn new() -> Self {
        FunctionProfiler { functions: Map.new() }
    }
    
    on record(name: String, duration: Duration) {
        let profile = self.functions.entry(name)
            .or_insert(FunctionProfile.new(name))
        profile.record(duration)
    }
    
    fn get(name: String) -> Option<FunctionProfile> {
        self.functions.get(name).cloned()
    }
    
    fn all() -> [FunctionProfile] {
        self.functions.values().collect()
    }
    
    fn print_report() {
        println("=== Function Profile ===")
        for profile in self.all().sorted_by(|p| -p.total_time.as_nanos()) {
            println("\(profile.name):")
            println("  Calls:    \(profile.calls)")
            println("  Total:    \(profile.total_time)")
            println("  Avg:      \(profile.avg_time())")
            println("  Min:      \(profile.min_time)")
            println("  Max:      \(profile.max_time)")
            println()
        }
        println("========================")
    }
    
    on reset() {
        self.functions.clear()
    }
}

struct FunctionProfile {
    name: String
    calls: Int
    total_time: Duration
    min_time: Duration
    max_time: Duration
    
    fn new(name: String) -> Self {
        FunctionProfile {
            name: name,
            calls: 0,
            total_time: Duration.zero(),
            min_time: Duration.max(),
            max_time: Duration.zero()
        }
    }
    
    fn record(duration: Duration) {
        self.calls += 1
        self.total_time += duration
        self.min_time = self.min_time.min(duration)
        self.max_time = self.max_time.max(duration)
    }
    
    fn avg_time() -> Duration {
        if self.calls == 0 { Duration.zero() }
        else { Duration.nanos(self.total_time.as_nanos() / self.calls) }
    }
}

var FUNCTION_PROFILER = FunctionProfiler.new()

// -----------------------------------------------------------------------------
// Scope Profiler
// -----------------------------------------------------------------------------

/// Profile a scope
struct ScopeProfiler {
    name: String
    start: Instant
    
    fn new(name: String) -> Self {
        ScopeProfiler { name: name, start: Instant.now() }
    }
}

impl Drop for ScopeProfiler {
    fn drop() {
        let elapsed = self.start.elapsed()
        FUNCTION_PROFILER.record(self.name, elapsed)
    }
}

macro profile_scope(name) {
    let __scope_profiler = ScopeProfiler.new(name)
}

// -----------------------------------------------------------------------------
// Memory Profiler
// -----------------------------------------------------------------------------

/// Memory profiler
actor MemoryProfiler {
    state snapshots: [MemorySnapshot]
    state tracking: Bool
    
    fn new() -> Self {
        MemoryProfiler { snapshots: [], tracking: false }
    }
    
    on start() {
        self.tracking = true
        self.take_snapshot("start")
    }
    
    on stop() {
        self.take_snapshot("stop")
        self.tracking = false
    }
    
    on take_snapshot(name: String) {
        let stats = @native("memory_stats")
        self.snapshots.push(MemorySnapshot {
            name: name,
            timestamp: Instant.now(),
            heap_used: stats.heap_used,
            heap_total: stats.heap_total,
            stack_used: stats.stack_used,
            allocations: stats.allocations
        })
    }
    
    fn diff(from: String, to: String) -> Option<MemoryDiff> {
        let s1 = self.snapshots.find(|s| s.name == from)?
        let s2 = self.snapshots.find(|s| s.name == to)?
        
        Some(MemoryDiff {
            heap_delta: s2.heap_used - s1.heap_used,
            allocation_delta: s2.allocations - s1.allocations,
            duration: s2.timestamp.duration_since(s1.timestamp)
        })
    }
    
    fn print_report() {
        println("=== Memory Profile ===")
        for snapshot in self.snapshots {
            println("\(snapshot.name) (\(snapshot.timestamp)):")
            println("  Heap used:    \(format_bytes(snapshot.heap_used))")
            println("  Heap total:   \(format_bytes(snapshot.heap_total))")
            println("  Allocations:  \(snapshot.allocations)")
            println()
        }
        
        if self.snapshots.len() >= 2 {
            let first = self.snapshots.first().unwrap()
            let last = self.snapshots.last().unwrap()
            println("Delta (\(first.name) -> \(last.name)):")
            println("  Heap:        \(format_bytes(last.heap_used - first.heap_used))")
            println("  Allocations: \(last.allocations - first.allocations)")
        }
        println("======================")
    }
}

struct MemorySnapshot {
    name: String
    timestamp: Instant
    heap_used: Int
    heap_total: Int
    stack_used: Int
    allocations: Int
}

struct MemoryDiff {
    heap_delta: Int
    allocation_delta: Int
    duration: Duration
}

// -----------------------------------------------------------------------------
// Helpers
// -----------------------------------------------------------------------------

fn format_bytes(bytes: Int) -> String {
    if bytes < 1024 { "\(bytes) B" }
    else if bytes < 1024 * 1024 { "\((bytes as Float / 1024.0).round(2)) KB" }
    else if bytes < 1024 * 1024 * 1024 { "\((bytes as Float / (1024.0 * 1024.0)).round(2)) MB" }
    else { "\((bytes as Float / (1024.0 * 1024.0 * 1024.0)).round(2)) GB" }
}

// -----------------------------------------------------------------------------
// Convenience Functions
// -----------------------------------------------------------------------------

/// Profile a block of code
fn profile<T>(name: String, f: () -> T) -> (T, Duration) {
    let start = Instant.now()
    let result = f()
    let elapsed = start.elapsed()
    FUNCTION_PROFILER.record(name, elapsed)
    (result, elapsed)
}

/// Profile with automatic reporting
fn profile_and_report<T>(name: String, f: () -> T) -> T {
    let (result, elapsed) = profile(name, f)
    println("[\(name)] \(elapsed)")
    result
}

/// Global profiler instance
var GLOBAL_PROFILER: Option<Profiler> = None

fn start_profiling() {
    if GLOBAL_PROFILER.is_none() {
        GLOBAL_PROFILER = Some(Profiler.new())
    }
    GLOBAL_PROFILER.unwrap().start()
}

fn stop_profiling() -> ProfileResult {
    match GLOBAL_PROFILER {
        Some(p) => p.stop(),
        None => ProfileResult.empty()
    }
}

// -----------------------------------------------------------------------------
// Tests
// -----------------------------------------------------------------------------

test "function profiler" {
    let profiler = FunctionProfiler.new()
    
    profiler.record("test_fn", Duration.millis(10))
    profiler.record("test_fn", Duration.millis(20))
    profiler.record("test_fn", Duration.millis(30))
    
    let profile = profiler.get("test_fn").unwrap()
    assert_eq(profile.calls, 3)?
    assert_eq(profile.avg_time(), Duration.millis(20))?
}

test "scope profiler" {
    FUNCTION_PROFILER.reset()
    
    {
        let _p = ScopeProfiler.new("test_scope")
        // Do some work
        for i in 0..1000 { let _ = i * i }
    }
    
    let profile = FUNCTION_PROFILER.get("test_scope")
    assert(profile.is_some())?
    assert_eq(profile.unwrap().calls, 1)?
}

test "profile macro" {
    FUNCTION_PROFILER.reset()
    
    let result = profile_fn!("compute", {
        var sum = 0
        for i in 0..100 { sum += i }
        sum
    })
    
    assert_eq(result, 4950)?
    assert(FUNCTION_PROFILER.get("compute").is_some())?
}

test "memory profiler" {
    let mp = MemoryProfiler.new()
    
    mp.take_snapshot("before")
    let data = Vec::<Int>.with_capacity(1000)
    mp.take_snapshot("after")
    
    assert_eq(mp.snapshots.len(), 2)?
}
