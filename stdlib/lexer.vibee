// =============================================================================
// Vibee OS â€” Lexer Module
// Lexical Analyzer for Vibee Language
// =============================================================================

use ast::{Span, Identifier}

// =============================================================================
// Token Types
// =============================================================================

/// Token with span information
struct Token {
    kind: TokenKind
    span: Span
}

impl Token {
    fn new(kind: TokenKind, span: Span) -> Self { Token { kind: kind, span: span } }
    fn is_keyword() -> Bool { self.kind.is_keyword() }
    fn is_operator() -> Bool { self.kind.is_operator() }
    fn is_literal() -> Bool { self.kind.is_literal() }
}

impl Display for Token {
    fn fmt(f: Formatter) { f.write(format!("{:?} at {}", self.kind, self.span)) }
}

/// Token kinds
enum TokenKind {
    // Literals
    IntLit(Int64)
    FloatLit(Float64)
    StringLit(String)
    CharLit(Char)
    BoolLit(Bool)
    
    // Identifiers
    Ident(String)
    
    // Keywords
    Fn, Let, Var, Const, Static
    If, Else, Match, Loop, While, For, In
    Return, Break, Continue
    Struct, Enum, Trait, Impl, Actor
    Type, Where, As
    Pub, Crate, Super, Self_, SelfType
    Use, Mod
    True, False
    Async, Await, Spawn
    Mut, Ref
    Test
    
    // Operators
    Plus, Minus, Star, Slash, Percent
    Ampersand, Pipe, Caret, Tilde
    Shl, Shr
    And, Or, Not
    Eq, Ne, Lt, Le, Gt, Ge
    Assign, PlusAssign, MinusAssign, StarAssign, SlashAssign
    Arrow, FatArrow, DoubleColon
    Dot, DotDot, DotDotEq
    Question, Bang
    
    // Delimiters
    LParen, RParen
    LBracket, RBracket
    LBrace, RBrace
    
    // Punctuation
    Comma, Colon, Semicolon
    At, Hash, Dollar
    
    // Special
    Newline
    Comment(String)
    DocComment(String)
    Eof
    Error(String)
}

impl TokenKind {
    fn is_keyword() -> Bool {
        match self {
            Fn | Let | Var | Const | Static | If | Else | Match | Loop | While | For | In |
            Return | Break | Continue | Struct | Enum | Trait | Impl | Actor | Type | Where |
            As | Pub | Crate | Super | Self_ | SelfType | Use | Mod | True | False |
            Async | Await | Spawn | Mut | Ref | Test => true
            _ => false
        }
    }
    
    fn is_operator() -> Bool {
        match self {
            Plus | Minus | Star | Slash | Percent | Ampersand | Pipe | Caret | Tilde |
            Shl | Shr | And | Or | Not | Eq | Ne | Lt | Le | Gt | Ge | Assign |
            PlusAssign | MinusAssign | StarAssign | SlashAssign | Arrow | FatArrow |
            DoubleColon | Dot | DotDot | DotDotEq | Question | Bang => true
            _ => false
        }
    }
    
    fn is_literal() -> Bool {
        match self { IntLit(_) | FloatLit(_) | StringLit(_) | CharLit(_) | BoolLit(_) => true, _ => false }
    }
    
    fn precedence() -> Int {
        match self {
            Assign | PlusAssign | MinusAssign | StarAssign | SlashAssign => 1
            Or => 2
            And => 3
            Eq | Ne => 4
            Lt | Le | Gt | Ge => 5
            Pipe => 6
            Caret => 7
            Ampersand => 8
            Shl | Shr => 9
            Plus | Minus => 10
            Star | Slash | Percent => 11
            As => 12
            _ => 0
        }
    }
}

// =============================================================================
// Lexer
// =============================================================================

/// Lexer state
struct Lexer {
    source: String
    file: String
    pos: Int
    line: Int
    col: Int
    tokens: [Token]
    errors: [LexerError]
}

/// Lexer error
struct LexerError {
    message: String
    span: Span
}

impl Display for LexerError {
    fn fmt(f: Formatter) { f.write(format!("Lexer error at {}: {}", self.span, self.message)) }
}

impl Lexer {
    /// Create new lexer
    fn new(source: String, file: String) -> Self {
        Lexer {
            source: source,
            file: file,
            pos: 0,
            line: 1,
            col: 1,
            tokens: [],
            errors: []
        }
    }
    
    /// Tokenize entire source
    fn tokenize() -> Result<[Token], [LexerError]> {
        while !self.is_eof() {
            self.skip_whitespace()
            if self.is_eof() { break }
            
            let token = self.next_token()
            match token.kind {
                TokenKind.Error(msg) => self.errors.push(LexerError { message: msg, span: token.span })
                TokenKind.Comment(_) => {}  // Skip regular comments
                _ => self.tokens.push(token)
            }
        }
        
        self.tokens.push(Token.new(TokenKind.Eof, self.current_span()))
        
        if self.errors.is_empty() { Ok(self.tokens) } else { Err(self.errors) }
    }
    
    /// Get next token
    fn next_token() -> Token {
        let start_pos = self.pos
        let start_line = self.line
        let start_col = self.col
        
        let c = self.peek()
        
        let kind = match c {
            // Identifiers and keywords
            'a'..='z' | 'A'..='Z' | '_' => self.scan_identifier()
            
            // Numbers
            '0'..='9' => self.scan_number()
            
            // Strings
            '"' => self.scan_string()
            
            // Characters
            '\'' => self.scan_char()
            
            // Raw strings
            'r' if self.peek_next() == '"' || self.peek_next() == '#' => self.scan_raw_string()
            
            // Operators and punctuation
            '+' => self.scan_plus()
            '-' => self.scan_minus()
            '*' => self.scan_star()
            '/' => self.scan_slash()
            '%' => { self.advance(); TokenKind.Percent }
            '&' => self.scan_ampersand()
            '|' => self.scan_pipe()
            '^' => { self.advance(); TokenKind.Caret }
            '~' => { self.advance(); TokenKind.Tilde }
            '!' => self.scan_bang()
            '=' => self.scan_eq()
            '<' => self.scan_lt()
            '>' => self.scan_gt()
            '.' => self.scan_dot()
            ':' => self.scan_colon()
            '?' => { self.advance(); TokenKind.Question }
            '@' => { self.advance(); TokenKind.At }
            '#' => { self.advance(); TokenKind.Hash }
            '$' => { self.advance(); TokenKind.Dollar }
            
            // Delimiters
            '(' => { self.advance(); TokenKind.LParen }
            ')' => { self.advance(); TokenKind.RParen }
            '[' => { self.advance(); TokenKind.LBracket }
            ']' => { self.advance(); TokenKind.RBracket }
            '{' => { self.advance(); TokenKind.LBrace }
            '}' => { self.advance(); TokenKind.RBrace }
            
            // Punctuation
            ',' => { self.advance(); TokenKind.Comma }
            ';' => { self.advance(); TokenKind.Semicolon }
            
            // Newline
            '\n' => { self.advance(); self.line += 1; self.col = 1; TokenKind.Newline }
            
            _ => { self.advance(); TokenKind.Error(format!("Unexpected character: {}", c)) }
        }
        
        let span = Span.new(self.file, start_line, start_col, self.line, self.col)
        Token.new(kind, span)
    }
    
    // -------------------------------------------------------------------------
    // Scanning helpers
    // -------------------------------------------------------------------------
    
    fn scan_identifier() -> TokenKind {
        var ident = ""
        while !self.is_eof() && self.is_ident_char(self.peek()) {
            ident.push(self.advance())
        }
        
        // Check for keywords
        match ident.as_str() {
            "fn" => TokenKind.Fn
            "let" => TokenKind.Let
            "var" => TokenKind.Var
            "const" => TokenKind.Const
            "static" => TokenKind.Static
            "if" => TokenKind.If
            "else" => TokenKind.Else
            "match" => TokenKind.Match
            "loop" => TokenKind.Loop
            "while" => TokenKind.While
            "for" => TokenKind.For
            "in" => TokenKind.In
            "return" => TokenKind.Return
            "break" => TokenKind.Break
            "continue" => TokenKind.Continue
            "struct" => TokenKind.Struct
            "enum" => TokenKind.Enum
            "trait" => TokenKind.Trait
            "impl" => TokenKind.Impl
            "actor" => TokenKind.Actor
            "type" => TokenKind.Type
            "where" => TokenKind.Where
            "as" => TokenKind.As
            "pub" => TokenKind.Pub
            "crate" => TokenKind.Crate
            "super" => TokenKind.Super
            "self" => TokenKind.Self_
            "Self" => TokenKind.SelfType
            "use" => TokenKind.Use
            "mod" => TokenKind.Mod
            "true" => TokenKind.BoolLit(true)
            "false" => TokenKind.BoolLit(false)
            "async" => TokenKind.Async
            "await" => TokenKind.Await
            "spawn" => TokenKind.Spawn
            "mut" => TokenKind.Mut
            "ref" => TokenKind.Ref
            "test" => TokenKind.Test
            _ => TokenKind.Ident(ident)
        }
    }
    
    fn scan_number() -> TokenKind {
        var num = ""
        var is_float = false
        
        // Check for hex, octal, binary
        if self.peek() == '0' {
            num.push(self.advance())
            match self.peek() {
                'x' | 'X' => { num.push(self.advance()); return self.scan_hex() }
                'o' | 'O' => { num.push(self.advance()); return self.scan_octal() }
                'b' | 'B' => { num.push(self.advance()); return self.scan_binary() }
                _ => {}
            }
        }
        
        // Integer part
        while !self.is_eof() && (self.peek().is_digit() || self.peek() == '_') {
            if self.peek() != '_' { num.push(self.advance()) } else { self.advance() }
        }
        
        // Decimal part
        if self.peek() == '.' && self.peek_next().is_digit() {
            is_float = true
            num.push(self.advance())  // '.'
            while !self.is_eof() && (self.peek().is_digit() || self.peek() == '_') {
                if self.peek() != '_' { num.push(self.advance()) } else { self.advance() }
            }
        }
        
        // Exponent
        if self.peek() == 'e' || self.peek() == 'E' {
            is_float = true
            num.push(self.advance())
            if self.peek() == '+' || self.peek() == '-' { num.push(self.advance()) }
            while !self.is_eof() && self.peek().is_digit() { num.push(self.advance()) }
        }
        
        if is_float {
            match num.parse::<Float64>() {
                Ok(f) => TokenKind.FloatLit(f)
                Err(_) => TokenKind.Error(format!("Invalid float: {}", num))
            }
        } else {
            match num.parse::<Int64>() {
                Ok(i) => TokenKind.IntLit(i)
                Err(_) => TokenKind.Error(format!("Invalid integer: {}", num))
            }
        }
    }
    
    fn scan_hex() -> TokenKind {
        var num = ""
        while !self.is_eof() && (self.peek().is_hex_digit() || self.peek() == '_') {
            if self.peek() != '_' { num.push(self.advance()) } else { self.advance() }
        }
        match Int64.from_str_radix(num, 16) {
            Ok(i) => TokenKind.IntLit(i)
            Err(_) => TokenKind.Error(format!("Invalid hex: 0x{}", num))
        }
    }
    
    fn scan_octal() -> TokenKind {
        var num = ""
        while !self.is_eof() && self.peek() >= '0' && self.peek() <= '7' {
            num.push(self.advance())
        }
        match Int64.from_str_radix(num, 8) {
            Ok(i) => TokenKind.IntLit(i)
            Err(_) => TokenKind.Error(format!("Invalid octal: 0o{}", num))
        }
    }
    
    fn scan_binary() -> TokenKind {
        var num = ""
        while !self.is_eof() && (self.peek() == '0' || self.peek() == '1' || self.peek() == '_') {
            if self.peek() != '_' { num.push(self.advance()) } else { self.advance() }
        }
        match Int64.from_str_radix(num, 2) {
            Ok(i) => TokenKind.IntLit(i)
            Err(_) => TokenKind.Error(format!("Invalid binary: 0b{}", num))
        }
    }
    
    fn scan_string() -> TokenKind {
        self.advance()  // Opening quote
        var s = ""
        
        while !self.is_eof() && self.peek() != '"' {
            if self.peek() == '\\' {
                self.advance()
                match self.peek() {
                    'n' => { self.advance(); s.push('\n') }
                    'r' => { self.advance(); s.push('\r') }
                    't' => { self.advance(); s.push('\t') }
                    '\\' => { self.advance(); s.push('\\') }
                    '"' => { self.advance(); s.push('"') }
                    '0' => { self.advance(); s.push('\0') }
                    'x' => { self.advance(); s.push(self.scan_hex_escape()) }
                    'u' => { self.advance(); s.push(self.scan_unicode_escape()) }
                    _ => return TokenKind.Error(format!("Invalid escape: \\{}", self.peek()))
                }
            } else if self.peek() == '\n' {
                self.line += 1
                self.col = 1
                s.push(self.advance())
            } else {
                s.push(self.advance())
            }
        }
        
        if self.is_eof() { return TokenKind.Error("Unterminated string") }
        self.advance()  // Closing quote
        TokenKind.StringLit(s)
    }
    
    fn scan_raw_string() -> TokenKind {
        self.advance()  // 'r'
        var hashes = 0
        while self.peek() == '#' { self.advance(); hashes += 1 }
        
        if self.peek() != '"' { return TokenKind.Error("Expected '\"' after r#") }
        self.advance()
        
        var s = ""
        loop {
            if self.is_eof() { return TokenKind.Error("Unterminated raw string") }
            if self.peek() == '"' {
                self.advance()
                var closing_hashes = 0
                while self.peek() == '#' && closing_hashes < hashes {
                    self.advance()
                    closing_hashes += 1
                }
                if closing_hashes == hashes { break }
                s.push('"')
                for _ in 0..closing_hashes { s.push('#') }
            } else {
                if self.peek() == '\n' { self.line += 1; self.col = 1 }
                s.push(self.advance())
            }
        }
        TokenKind.StringLit(s)
    }
    
    fn scan_char() -> TokenKind {
        self.advance()  // Opening quote
        
        let c = if self.peek() == '\\' {
            self.advance()
            match self.peek() {
                'n' => { self.advance(); '\n' }
                'r' => { self.advance(); '\r' }
                't' => { self.advance(); '\t' }
                '\\' => { self.advance(); '\\' }
                '\'' => { self.advance(); '\'' }
                '0' => { self.advance(); '\0' }
                _ => return TokenKind.Error(format!("Invalid escape: \\{}", self.peek()))
            }
        } else {
            self.advance()
        }
        
        if self.peek() != '\'' { return TokenKind.Error("Unterminated char literal") }
        self.advance()
        TokenKind.CharLit(c)
    }
    
    fn scan_hex_escape() -> Char {
        var hex = ""
        for _ in 0..2 {
            if self.peek().is_hex_digit() { hex.push(self.advance()) }
        }
        Char.from_u32(Int.from_str_radix(hex, 16).unwrap_or(0) as u32).unwrap_or('?')
    }
    
    fn scan_unicode_escape() -> Char {
        if self.peek() != '{' { return '?' }
        self.advance()
        var hex = ""
        while self.peek().is_hex_digit() && hex.len() < 6 { hex.push(self.advance()) }
        if self.peek() != '}' { return '?' }
        self.advance()
        Char.from_u32(Int.from_str_radix(hex, 16).unwrap_or(0) as u32).unwrap_or('?')
    }
    
    fn scan_plus() -> TokenKind {
        self.advance()
        if self.peek() == '=' { self.advance(); TokenKind.PlusAssign }
        else { TokenKind.Plus }
    }
    
    fn scan_minus() -> TokenKind {
        self.advance()
        match self.peek() {
            '=' => { self.advance(); TokenKind.MinusAssign }
            '>' => { self.advance(); TokenKind.Arrow }
            _ => TokenKind.Minus
        }
    }
    
    fn scan_star() -> TokenKind {
        self.advance()
        if self.peek() == '=' { self.advance(); TokenKind.StarAssign }
        else { TokenKind.Star }
    }
    
    fn scan_slash() -> TokenKind {
        self.advance()
        match self.peek() {
            '=' => { self.advance(); TokenKind.SlashAssign }
            '/' => self.scan_line_comment()
            '*' => self.scan_block_comment()
            _ => TokenKind.Slash
        }
    }
    
    fn scan_line_comment() -> TokenKind {
        self.advance()  // Second '/'
        var is_doc = self.peek() == '/'
        if is_doc { self.advance() }
        
        var comment = ""
        while !self.is_eof() && self.peek() != '\n' {
            comment.push(self.advance())
        }
        
        if is_doc { TokenKind.DocComment(comment.trim()) }
        else { TokenKind.Comment(comment.trim()) }
    }
    
    fn scan_block_comment() -> TokenKind {
        self.advance()  // '*'
        var is_doc = self.peek() == '*'
        if is_doc { self.advance() }
        
        var comment = ""
        var depth = 1
        
        while !self.is_eof() && depth > 0 {
            if self.peek() == '/' && self.peek_next() == '*' {
                self.advance(); self.advance()
                depth += 1
                comment.push_str("/*")
            } else if self.peek() == '*' && self.peek_next() == '/' {
                self.advance(); self.advance()
                depth -= 1
                if depth > 0 { comment.push_str("*/") }
            } else {
                if self.peek() == '\n' { self.line += 1; self.col = 1 }
                comment.push(self.advance())
            }
        }
        
        if depth > 0 { return TokenKind.Error("Unterminated block comment") }
        
        if is_doc { TokenKind.DocComment(comment.trim()) }
        else { TokenKind.Comment(comment.trim()) }
    }
    
    fn scan_ampersand() -> TokenKind {
        self.advance()
        if self.peek() == '&' { self.advance(); TokenKind.And }
        else { TokenKind.Ampersand }
    }
    
    fn scan_pipe() -> TokenKind {
        self.advance()
        if self.peek() == '|' { self.advance(); TokenKind.Or }
        else { TokenKind.Pipe }
    }
    
    fn scan_bang() -> TokenKind {
        self.advance()
        if self.peek() == '=' { self.advance(); TokenKind.Ne }
        else { TokenKind.Bang }
    }
    
    fn scan_eq() -> TokenKind {
        self.advance()
        match self.peek() {
            '=' => { self.advance(); TokenKind.Eq }
            '>' => { self.advance(); TokenKind.FatArrow }
            _ => TokenKind.Assign
        }
    }
    
    fn scan_lt() -> TokenKind {
        self.advance()
        match self.peek() {
            '=' => { self.advance(); TokenKind.Le }
            '<' => { self.advance(); TokenKind.Shl }
            _ => TokenKind.Lt
        }
    }
    
    fn scan_gt() -> TokenKind {
        self.advance()
        match self.peek() {
            '=' => { self.advance(); TokenKind.Ge }
            '>' => { self.advance(); TokenKind.Shr }
            _ => TokenKind.Gt
        }
    }
    
    fn scan_dot() -> TokenKind {
        self.advance()
        match self.peek() {
            '.' => {
                self.advance()
                if self.peek() == '=' { self.advance(); TokenKind.DotDotEq }
                else { TokenKind.DotDot }
            }
            _ => TokenKind.Dot
        }
    }
    
    fn scan_colon() -> TokenKind {
        self.advance()
        if self.peek() == ':' { self.advance(); TokenKind.DoubleColon }
        else { TokenKind.Colon }
    }
    
    // -------------------------------------------------------------------------
    // Utility methods
    // -------------------------------------------------------------------------
    
    fn peek() -> Char { self.source.char_at(self.pos).unwrap_or('\0') }
    fn peek_next() -> Char { self.source.char_at(self.pos + 1).unwrap_or('\0') }
    fn is_eof() -> Bool { self.pos >= self.source.len() }
    
    fn advance() -> Char {
        let c = self.peek()
        self.pos += 1
        self.col += 1
        c
    }
    
    fn skip_whitespace() {
        while !self.is_eof() {
            match self.peek() {
                ' ' | '\t' | '\r' => { self.advance(); }
                '\n' => break  // Newlines are significant
                _ => break
            }
        }
    }
    
    fn is_ident_char(c: Char) -> Bool {
        c.is_alphanumeric() || c == '_'
    }
    
    fn current_span() -> Span {
        Span.new(self.file, self.line, self.col, self.line, self.col)
    }
}

// =============================================================================
// Utility Functions
// =============================================================================

/// Tokenize source code
fn tokenize(source: String, file: String) -> Result<[Token], [LexerError]> {
    Lexer.new(source, file).tokenize()
}

/// Check if string is a keyword
fn is_keyword(s: String) -> Bool {
    match s.as_str() {
        "fn" | "let" | "var" | "const" | "static" | "if" | "else" | "match" |
        "loop" | "while" | "for" | "in" | "return" | "break" | "continue" |
        "struct" | "enum" | "trait" | "impl" | "actor" | "type" | "where" |
        "as" | "pub" | "crate" | "super" | "self" | "Self" | "use" | "mod" |
        "true" | "false" | "async" | "await" | "spawn" | "mut" | "ref" | "test" => true
        _ => false
    }
}

/// Get all keywords
fn keywords() -> [String] {
    ["fn", "let", "var", "const", "static", "if", "else", "match", "loop",
     "while", "for", "in", "return", "break", "continue", "struct", "enum",
     "trait", "impl", "actor", "type", "where", "as", "pub", "crate", "super",
     "self", "Self", "use", "mod", "true", "false", "async", "await", "spawn",
     "mut", "ref", "test"]
}

// =============================================================================
// Tests
// =============================================================================

test "tokenize keywords" {
    let tokens = tokenize("fn struct enum trait impl actor", "test.vibee")?
    assert_eq(tokens[0].kind, TokenKind.Fn)?
    assert_eq(tokens[1].kind, TokenKind.Struct)?
    assert_eq(tokens[2].kind, TokenKind.Enum)?
    assert_eq(tokens[3].kind, TokenKind.Trait)?
    assert_eq(tokens[4].kind, TokenKind.Impl)?
    assert_eq(tokens[5].kind, TokenKind.Actor)?
}

test "tokenize numbers" {
    let tokens = tokenize("42 3.14 0xFF 0b1010 0o77", "test.vibee")?
    assert_eq(tokens[0].kind, TokenKind.IntLit(42))?
    assert_eq(tokens[1].kind, TokenKind.FloatLit(3.14))?
    assert_eq(tokens[2].kind, TokenKind.IntLit(255))?
    assert_eq(tokens[3].kind, TokenKind.IntLit(10))?
    assert_eq(tokens[4].kind, TokenKind.IntLit(63))?
}

test "tokenize strings" {
    let tokens = tokenize("\"hello\" 'c'", "test.vibee")?
    assert_eq(tokens[0].kind, TokenKind.StringLit("hello"))?
    assert_eq(tokens[1].kind, TokenKind.CharLit('c'))?
}

test "tokenize operators" {
    let tokens = tokenize("+ - * / == != -> =>", "test.vibee")?
    assert_eq(tokens[0].kind, TokenKind.Plus)?
    assert_eq(tokens[1].kind, TokenKind.Minus)?
    assert_eq(tokens[2].kind, TokenKind.Star)?
    assert_eq(tokens[3].kind, TokenKind.Slash)?
    assert_eq(tokens[4].kind, TokenKind.Eq)?
    assert_eq(tokens[5].kind, TokenKind.Ne)?
    assert_eq(tokens[6].kind, TokenKind.Arrow)?
    assert_eq(tokens[7].kind, TokenKind.FatArrow)?
}

test "tokenize identifiers" {
    let tokens = tokenize("foo bar_baz _private", "test.vibee")?
    assert_eq(tokens[0].kind, TokenKind.Ident("foo"))?
    assert_eq(tokens[1].kind, TokenKind.Ident("bar_baz"))?
    assert_eq(tokens[2].kind, TokenKind.Ident("_private"))?
}

test "is_keyword" {
    assert(is_keyword("fn"))?
    assert(is_keyword("struct"))?
    assert(!is_keyword("foo"))?
}
