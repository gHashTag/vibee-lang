// =============================================================================
// Vibee OS â€” AR Session Module
// Augmented Reality session management and lifecycle
// =============================================================================

use geometry::{Point3D, Box3D}
use transform::{Transform3D, Matrix4x4}
use image::{Image, PixelFormat}

// -----------------------------------------------------------------------------
// Constants
// -----------------------------------------------------------------------------

const AR_SESSION_TIMEOUT_MS: Int = 30000
const AR_FRAME_RATE_DEFAULT: Int = 60
const AR_TRACKING_QUALITY_THRESHOLD: Float = 0.7

// -----------------------------------------------------------------------------
// AR Session State
// -----------------------------------------------------------------------------

/// AR session state
enum ARSessionState {
    NotStarted
    Initializing
    Running
    Paused
    Interrupted
    Failed(ARSessionError)
    
    fn is_active() -> Bool {
        match self {
            Running => true,
            _ => false
        }
    }
    
    fn is_ready() -> Bool {
        match self {
            Running | Paused => true,
            _ => false
        }
    }
    
    fn can_resume() -> Bool {
        match self {
            Paused | Interrupted => true,
            _ => false
        }
    }
}

/// AR session errors
enum ARSessionError {
    CameraAccessDenied
    SensorUnavailable
    UnsupportedDevice
    ConfigurationFailed(String)
    TrackingLost
    WorldTrackingFailed
    InsufficientFeatures
    ExcessiveMotion
    InternalError(String)
    
    fn message() -> String {
        match self {
            CameraAccessDenied => "Camera access denied",
            SensorUnavailable => "Required sensors unavailable",
            UnsupportedDevice => "Device does not support AR",
            ConfigurationFailed(msg) => format!("Configuration failed: {}", msg),
            TrackingLost => "Tracking lost",
            WorldTrackingFailed => "World tracking failed",
            InsufficientFeatures => "Insufficient visual features",
            ExcessiveMotion => "Excessive device motion",
            InternalError(msg) => format!("Internal error: {}", msg)
        }
    }
    
    fn is_recoverable() -> Bool {
        match self {
            TrackingLost | InsufficientFeatures | ExcessiveMotion => true,
            _ => false
        }
    }
}

// -----------------------------------------------------------------------------
// AR Configuration
// -----------------------------------------------------------------------------

/// World alignment mode
enum WorldAlignment {
    Gravity           // Y-axis aligned with gravity
    GravityAndHeading // Y-axis aligned with gravity, Z with compass
    Camera            // Aligned with camera orientation
}

/// Plane detection mode
enum PlaneDetection {
    None
    Horizontal
    Vertical
    Both
}

/// Scene reconstruction mode
enum SceneReconstruction {
    None
    Mesh
    MeshWithClassification
}

/// Environment texturing mode
enum EnvironmentTexturing {
    None
    Manual
    Automatic
}

/// AR session configuration
struct ARSessionConfig {
    world_alignment: WorldAlignment
    plane_detection: PlaneDetection
    scene_reconstruction: SceneReconstruction
    environment_texturing: EnvironmentTexturing
    light_estimation_enabled: Bool
    auto_focus_enabled: Bool
    frame_rate: Int
    provide_audio_data: Bool
    collaboration_enabled: Bool
    
    fn new() -> Self {
        ARSessionConfig {
            world_alignment: WorldAlignment.Gravity,
            plane_detection: PlaneDetection.Both,
            scene_reconstruction: SceneReconstruction.None,
            environment_texturing: EnvironmentTexturing.Automatic,
            light_estimation_enabled: true,
            auto_focus_enabled: true,
            frame_rate: AR_FRAME_RATE_DEFAULT,
            provide_audio_data: false,
            collaboration_enabled: false
        }
    }
    
    fn with_plane_detection(detection: PlaneDetection) -> Self {
        self.plane_detection = detection
        self
    }
    
    fn with_scene_reconstruction(mode: SceneReconstruction) -> Self {
        self.scene_reconstruction = mode
        self
    }
    
    fn with_world_alignment(alignment: WorldAlignment) -> Self {
        self.world_alignment = alignment
        self
    }
    
    fn with_light_estimation(enabled: Bool) -> Self {
        self.light_estimation_enabled = enabled
        self
    }
    
    fn with_collaboration(enabled: Bool) -> Self {
        self.collaboration_enabled = enabled
        self
    }
}

// -----------------------------------------------------------------------------
// AR Frame
// -----------------------------------------------------------------------------

/// Camera intrinsics
struct CameraIntrinsics {
    focal_length_x: Float
    focal_length_y: Float
    principal_point_x: Float
    principal_point_y: Float
    
    fn new(fx: Float, fy: Float, cx: Float, cy: Float) -> Self {
        CameraIntrinsics {
            focal_length_x: fx,
            focal_length_y: fy,
            principal_point_x: cx,
            principal_point_y: cy
        }
    }
    
    fn to_matrix() -> Matrix4x4 {
        Matrix4x4.from_values([
            [self.focal_length_x, 0.0, self.principal_point_x, 0.0],
            [0.0, self.focal_length_y, self.principal_point_y, 0.0],
            [0.0, 0.0, 1.0, 0.0],
            [0.0, 0.0, 0.0, 1.0]
        ])
    }
}

/// Tracking state
enum TrackingState {
    NotAvailable
    Limited(TrackingStateReason)
    Normal
    
    fn is_tracking() -> Bool {
        match self {
            Normal => true,
            _ => false
        }
    }
    
    fn quality() -> Float {
        match self {
            Normal => 1.0,
            Limited(_) => 0.5,
            NotAvailable => 0.0
        }
    }
}

/// Reason for limited tracking
enum TrackingStateReason {
    None
    Initializing
    ExcessiveMotion
    InsufficientFeatures
    Relocalizing
}

/// Light estimate
struct LightEstimate {
    ambient_intensity: Float      // 0-2000 lux
    ambient_color_temperature: Float  // Kelvin
    primary_light_direction: Option<Point3D>
    primary_light_intensity: Option<Float>
    
    fn new(intensity: Float, temperature: Float) -> Self {
        LightEstimate {
            ambient_intensity: intensity,
            ambient_color_temperature: temperature,
            primary_light_direction: None,
            primary_light_intensity: None
        }
    }
    
    fn is_bright() -> Bool { self.ambient_intensity > 500.0 }
    fn is_dim() -> Bool { self.ambient_intensity < 100.0 }
}

/// AR frame data
struct ARFrame {
    timestamp: Float64
    camera_transform: Transform3D
    camera_intrinsics: CameraIntrinsics
    tracking_state: TrackingState
    light_estimate: Option<LightEstimate>
    captured_image: Option<Image>
    depth_data: Option<DepthData>
    detected_planes: [DetectedPlane]
    world_mapping_status: WorldMappingStatus
    
    fn new(timestamp: Float64, transform: Transform3D, intrinsics: CameraIntrinsics) -> Self {
        ARFrame {
            timestamp: timestamp,
            camera_transform: transform,
            camera_intrinsics: intrinsics,
            tracking_state: TrackingState.NotAvailable,
            light_estimate: None,
            captured_image: None,
            depth_data: None,
            detected_planes: [],
            world_mapping_status: WorldMappingStatus.NotAvailable
        }
    }
    
    fn camera_position() -> Point3D {
        self.camera_transform.position()
    }
    
    fn camera_euler_angles() -> (Float, Float, Float) {
        self.camera_transform.euler_angles()
    }
    
    fn is_tracking() -> Bool {
        self.tracking_state.is_tracking()
    }
    
    fn project_point(world_point: Point3D, viewport_size: (Int, Int)) -> Option<(Float, Float)> {
        @native("ar_project_point", world_point, self.camera_transform, self.camera_intrinsics, viewport_size)
    }
    
    fn unproject_point(screen_point: (Float, Float), depth: Float) -> Option<Point3D> {
        @native("ar_unproject_point", screen_point, depth, self.camera_transform, self.camera_intrinsics)
    }
}

/// World mapping status
enum WorldMappingStatus {
    NotAvailable
    Limited
    Extending
    Mapped
    
    fn is_ready_for_sharing() -> Bool {
        match self {
            Mapped => true,
            _ => false
        }
    }
}

/// Depth data
struct DepthData {
    width: Int
    height: Int
    data: [Float]
    confidence_map: Option<[UInt8]>
    
    fn new(width: Int, height: Int, data: [Float]) -> Self {
        DepthData { width: width, height: height, data: data, confidence_map: None }
    }
    
    fn depth_at(x: Int, y: Int) -> Option<Float> {
        if x >= 0 && x < self.width && y >= 0 && y < self.height {
            Some(self.data[y * self.width + x])
        } else {
            None
        }
    }
    
    fn confidence_at(x: Int, y: Int) -> Option<UInt8> {
        self.confidence_map.and_then(|map| {
            if x >= 0 && x < self.width && y >= 0 && y < self.height {
                Some(map[y * self.width + x])
            } else {
                None
            }
        })
    }
}

/// Detected plane
struct DetectedPlane {
    id: String
    center: Point3D
    extent: (Float, Float)
    transform: Transform3D
    classification: PlaneClassification
    geometry: Option<PlaneGeometry>
    
    fn new(id: String, center: Point3D, extent: (Float, Float)) -> Self {
        DetectedPlane {
            id: id,
            center: center,
            extent: extent,
            transform: Transform3D.identity(),
            classification: PlaneClassification.Unknown,
            geometry: None
        }
    }
    
    fn area() -> Float {
        self.extent.0 * self.extent.1
    }
    
    fn is_horizontal() -> Bool {
        match self.classification {
            PlaneClassification.Floor | PlaneClassification.Ceiling | 
            PlaneClassification.Table => true,
            _ => false
        }
    }
    
    fn is_vertical() -> Bool {
        match self.classification {
            PlaneClassification.Wall | PlaneClassification.Door |
            PlaneClassification.Window => true,
            _ => false
        }
    }
}

/// Plane classification
enum PlaneClassification {
    Unknown
    Wall
    Floor
    Ceiling
    Table
    Seat
    Door
    Window
}

/// Plane geometry
struct PlaneGeometry {
    vertices: [Point3D]
    texture_coordinates: [(Float, Float)]
    triangle_indices: [Int]
    boundary_vertices: [Point3D]
    
    fn new(vertices: [Point3D], indices: [Int]) -> Self {
        PlaneGeometry {
            vertices: vertices,
            texture_coordinates: [],
            triangle_indices: indices,
            boundary_vertices: []
        }
    }
    
    fn vertex_count() -> Int { self.vertices.len() }
    fn triangle_count() -> Int { self.triangle_indices.len() / 3 }
}

// -----------------------------------------------------------------------------
// AR Session Actor
// -----------------------------------------------------------------------------

/// AR session delegate trait
trait ARSessionDelegate {
    fn on_frame_update(frame: ARFrame)
    fn on_tracking_state_changed(state: TrackingState)
    fn on_plane_detected(plane: DetectedPlane)
    fn on_plane_updated(plane: DetectedPlane)
    fn on_plane_removed(plane_id: String)
    fn on_session_interrupted()
    fn on_session_resumed()
    fn on_error(error: ARSessionError)
}

/// AR session actor
actor ARSession {
    state config: ARSessionConfig
    state state: ARSessionState
    state current_frame: Option<ARFrame>
    state delegates: [ARSessionDelegate]
    state detected_planes: Map<String, DetectedPlane>
    state start_time: Option<Float64>
    
    fn new() -> Self {
        ARSession {
            config: ARSessionConfig.new(),
            state: ARSessionState.NotStarted,
            current_frame: None,
            delegates: [],
            detected_planes: Map.new(),
            start_time: None
        }
    }
    
    fn with_config(config: ARSessionConfig) -> Self {
        ARSession {
            config: config,
            state: ARSessionState.NotStarted,
            current_frame: None,
            delegates: [],
            detected_planes: Map.new(),
            start_time: None
        }
    }
    
    fn run() -> Result<(), ARSessionError> {
        self.run_with_config(self.config)
    }
    
    fn run_with_config(config: ARSessionConfig) -> Result<(), ARSessionError> {
        self.config = config
        self.state = ARSessionState.Initializing
        
        // Check device capabilities
        if !self.check_device_support() {
            self.state = ARSessionState.Failed(ARSessionError.UnsupportedDevice)
            return Err(ARSessionError.UnsupportedDevice)
        }
        
        // Request camera access
        if !self.request_camera_access() {
            self.state = ARSessionState.Failed(ARSessionError.CameraAccessDenied)
            return Err(ARSessionError.CameraAccessDenied)
        }
        
        // Initialize native AR session
        @native("ar_session_start", config)?
        
        self.state = ARSessionState.Running
        self.start_time = Some(@native("time_now"))
        Ok(())
    }
    
    fn pause() {
        if self.state.is_active() {
            @native("ar_session_pause")
            self.state = ARSessionState.Paused
        }
    }
    
    fn resume() {
        if self.state.can_resume() {
            @native("ar_session_resume")
            self.state = ARSessionState.Running
            for delegate in self.delegates {
                delegate.on_session_resumed()
            }
        }
    }
    
    fn stop() {
        @native("ar_session_stop")
        self.state = ARSessionState.NotStarted
        self.current_frame = None
        self.detected_planes.clear()
    }
    
    fn add_delegate(delegate: ARSessionDelegate) {
        self.delegates.push(delegate)
    }
    
    fn remove_delegate(delegate: ARSessionDelegate) {
        self.delegates.retain(|d| d != delegate)
    }
    
    fn current_frame() -> Option<ARFrame> {
        self.current_frame.clone()
    }
    
    fn session_state() -> ARSessionState {
        self.state.clone()
    }
    
    fn is_running() -> Bool {
        self.state.is_active()
    }
    
    fn elapsed_time() -> Option<Float64> {
        self.start_time.map(|start| @native("time_now") - start)
    }
    
    fn get_planes() -> [DetectedPlane] {
        self.detected_planes.values().collect()
    }
    
    fn get_plane(id: String) -> Option<DetectedPlane> {
        self.detected_planes.get(id).cloned()
    }
    
    fn raycast(origin: Point3D, direction: Point3D, types: [RaycastTarget]) -> [RaycastResult] {
        if !self.state.is_active() { return [] }
        @native("ar_raycast", origin, direction, types)
    }
    
    fn raycast_from_screen(point: (Float, Float), types: [RaycastTarget]) -> [RaycastResult] {
        if !self.state.is_active() { return [] }
        @native("ar_raycast_screen", point, types)
    }
    
    fn create_world_map() -> Result<ARWorldMap, ARSessionError> {
        if !self.state.is_active() {
            return Err(ARSessionError.InternalError("Session not running"))
        }
        @native("ar_create_world_map")
    }
    
    fn relocalize_with_world_map(map: ARWorldMap) -> Result<(), ARSessionError> {
        @native("ar_relocalize", map)
    }
    
    // Internal methods
    fn check_device_support() -> Bool {
        @native("ar_check_support")
    }
    
    fn request_camera_access() -> Bool {
        @native("ar_request_camera")
    }
    
    fn process_frame(frame: ARFrame) {
        self.current_frame = Some(frame.clone())
        
        // Update tracking state
        let prev_tracking = self.current_frame.map(|f| f.tracking_state.clone());
        if prev_tracking != Some(frame.tracking_state.clone()) {
            for delegate in self.delegates {
                delegate.on_tracking_state_changed(frame.tracking_state.clone())
            }
        }
        
        // Notify delegates
        for delegate in self.delegates {
            delegate.on_frame_update(frame.clone())
        }
    }
    
    fn handle_plane_detected(plane: DetectedPlane) {
        self.detected_planes.insert(plane.id.clone(), plane.clone())
        for delegate in self.delegates {
            delegate.on_plane_detected(plane.clone())
        }
    }
    
    fn handle_plane_updated(plane: DetectedPlane) {
        self.detected_planes.insert(plane.id.clone(), plane.clone())
        for delegate in self.delegates {
            delegate.on_plane_updated(plane.clone())
        }
    }
    
    fn handle_plane_removed(plane_id: String) {
        self.detected_planes.remove(plane_id.clone())
        for delegate in self.delegates {
            delegate.on_plane_removed(plane_id.clone())
        }
    }
}

// -----------------------------------------------------------------------------
// Raycast
// -----------------------------------------------------------------------------

/// Raycast target types
enum RaycastTarget {
    ExistingPlaneGeometry
    ExistingPlaneInfinite
    EstimatedPlane
    FeaturePoint
}

/// Raycast result
struct RaycastResult {
    distance: Float
    world_transform: Transform3D
    target_type: RaycastTarget
    anchor_id: Option<String>
    
    fn new(distance: Float, transform: Transform3D, target: RaycastTarget) -> Self {
        RaycastResult {
            distance: distance,
            world_transform: transform,
            target_type: target,
            anchor_id: None
        }
    }
    
    fn position() -> Point3D {
        self.world_transform.position()
    }
}

// -----------------------------------------------------------------------------
// AR World Map
// -----------------------------------------------------------------------------

/// AR world map for persistence and sharing
struct ARWorldMap {
    data: [UInt8]
    center: Point3D
    extent: Point3D
    anchor_ids: [String]
    
    fn new(data: [UInt8]) -> Self {
        ARWorldMap {
            data: data,
            center: Point3D.origin(),
            extent: Point3D.origin(),
            anchor_ids: []
        }
    }
    
    fn serialize() -> [UInt8] {
        self.data.clone()
    }
    
    fn deserialize(data: [UInt8]) -> Result<Self, ARSessionError> {
        @native("ar_world_map_deserialize", data)
    }
    
    fn size_bytes() -> Int {
        self.data.len()
    }
}

// -----------------------------------------------------------------------------
// Convenience Functions
// -----------------------------------------------------------------------------

/// Create and start a new AR session
fn start_ar_session() -> Result<ARSession, ARSessionError> {
    let session = ARSession.new()
    session.run()?
    Ok(session)
}

/// Create AR session with custom configuration
fn start_ar_session_with_config(config: ARSessionConfig) -> Result<ARSession, ARSessionError> {
    let session = ARSession.with_config(config)
    session.run()?
    Ok(session)
}

/// Check if AR is supported on this device
fn is_ar_supported() -> Bool {
    @native("ar_check_support")
}

/// Get AR capabilities
fn get_ar_capabilities() -> ARCapabilities {
    @native("ar_get_capabilities")
}

/// AR device capabilities
struct ARCapabilities {
    world_tracking: Bool
    face_tracking: Bool
    image_tracking: Bool
    object_tracking: Bool
    body_tracking: Bool
    geo_tracking: Bool
    scene_reconstruction: Bool
    people_occlusion: Bool
    motion_capture: Bool
    collaboration: Bool
    
    fn supports_all_tracking() -> Bool {
        self.world_tracking && self.face_tracking && self.image_tracking
    }
}

// -----------------------------------------------------------------------------
// Tests
// -----------------------------------------------------------------------------

test "session_config_builder" {
    let config = ARSessionConfig.new()
        .with_plane_detection(PlaneDetection.Both)
        .with_light_estimation(true)
    
    assert_eq(config.plane_detection, PlaneDetection.Both)?
    assert(config.light_estimation_enabled)?
}

test "session_state_transitions" {
    assert(!ARSessionState.NotStarted.is_active())?
    assert(ARSessionState.Running.is_active())?
    assert(ARSessionState.Paused.can_resume())?
    assert(!ARSessionState.Failed(ARSessionError.CameraAccessDenied).can_resume())?
}

test "tracking_state_quality" {
    assert_eq(TrackingState.Normal.quality(), 1.0)?
    assert_eq(TrackingState.Limited(TrackingStateReason.Initializing).quality(), 0.5)?
    assert_eq(TrackingState.NotAvailable.quality(), 0.0)?
}

test "light_estimate" {
    let light = LightEstimate.new(1000.0, 6500.0)
    assert(light.is_bright())?
    assert(!light.is_dim())?
}

test "detected_plane_classification" {
    let mut plane = DetectedPlane.new("plane1", Point3D.origin(), (2.0, 3.0))
    plane.classification = PlaneClassification.Floor
    
    assert(plane.is_horizontal())?
    assert(!plane.is_vertical())?
    assert_eq(plane.area(), 6.0)?
}

test "world_mapping_status" {
    assert(!WorldMappingStatus.Limited.is_ready_for_sharing())?
    assert(WorldMappingStatus.Mapped.is_ready_for_sharing())?
}

test "error_recoverability" {
    assert(ARSessionError.TrackingLost.is_recoverable())?
    assert(!ARSessionError.CameraAccessDenied.is_recoverable())?
}
